\documentclass[11pt]{article}

% use packages
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
%\usepackage{amscd}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{natbib}
\usepackage{enumitem}
\usepackage{url}
\usepackage{authblk}
\usepackage{bm}
\usepackage[usenames]{color}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{caption}
\usepackage{float}
\usepackage[caption = false]{subfig}
\usepackage{tikz}
\usepackage{multirow}
\usepackage[linesnumbered, ruled,vlined]{algorithm2e}
% margin setup
\geometry{margin=0.8in}


% function definition
\newcommand{\R}{\mathbb{R}}
\newcommand{\w}{\textbf{w}}
\newcommand{\x}{\textbf{x}}
\newcommand{\X}{\textbf{X}}
\newcommand{\Y}{\textbf{Y}}
\newcommand{\Hist}{\mathcal{H}}
\def\mbf#1{\mathbf{#1}} % bold but not italic
\def\ind#1{\mathrm{1}(#1)} % indicator function
\newcommand{\simiid}{\stackrel{iid}{\sim}} %[] IID 
\def\where{\text{ where }} % where
\newcommand{\indep}{\perp \!\!\! \perp } % independent symbols
\def\cov#1#2{\mathrm{Cov}(#1, #2)} % covariance 
\def\mrm#1{\mathrm{#1}} % remove math
\newcommand{\reals}{\mathbb{R}} % Real number symbol
\def\t#1{\tilde{#1}} % tilde
\def\normal#1#2{\mathcal{N}(#1,#2)} % normal
\def\mbi#1{\boldsymbol{#1}} % Bold and italic (math bold italic)
\def\v#1{\mbi{#1}} % Vector notation
\def\mc#1{\mathcal{#1}} % mathical
\DeclareMathOperator*{\argmax}{arg\,max} % arg max
\DeclareMathOperator*{\argmin}{arg\,min} % arg min
\def\E#1{\mathrm{E}(#1)} % Expectation symbol
\def\var#1{\mathrm{Var}(#1)} % Variance symbol
\def\checkmark{\tikz\fill[scale=0.4](0,.35) -- (.25,0) -- (1,.7) -- (.25,.15) -- cycle;} % checkmark
\newcommand\red[1]{{\color{red}#1}}


\newcommand{\norm}[1]{\left\lVert#1\right\rVert} % A norm with 1 argument
\DeclareMathOperator{\Var}{Var} % Variance symbol

\newtheorem{cor}{Corollary}
\newtheorem{lem}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{defn}{Definition}
\newtheorem{prop}{Proposition}
\theoremstyle{definition}
\newtheorem{remark}{Remark}
\hypersetup{
  linkcolor  = blue,
  citecolor  = blue,
  urlcolor   = blue,
  colorlinks = true,
} % color setup

% proof to proposition 
\newenvironment{proof-of-proposition}[1][{}]{\noindent{\bf
    Proof of Proposition {#1}}
  \hspace*{.5em}}{\qed\bigskip\\}
% general proof of corollary
  \newenvironment{proof-of-corollary}[1][{}]{\noindent{\bf
    Proof of Corollary {#1}}
  \hspace*{.5em}}{\qed\bigskip\\}
% general proof of lemma
  \newenvironment{proof-of-lemma}[1][{}]{\noindent{\bf
    Proof of Lemma {#1}}
  \hspace*{.5em}}{\qed\bigskip\\}

\allowdisplaybreaks






% title
\title{Minimizing post-shock forecasting error using disparate information}
\author{Jilei Lin\thanks{jileil2@ilinois.edu} }
\author{Daniel J. Eck\thanks{dje13@illinois.edu}}
\affil{Department of Statistics, University of Illinois at Urbana-Champaign}

%%% New version of \caption puts things in smaller type, single-spaced 
%%% and indents them to set them off more from the text.
\makeatletter
\long\def\@makecaption#1#2{
  \vskip 0.8ex
  \setbox\@tempboxa\hbox{\small {\bf #1:} #2}
  \parindent 1.5em  %% How can we use the global value of this???
  \dimen0=\hsize
  \advance\dimen0 by -3em
  \ifdim \wd\@tempboxa >\dimen0
  \hbox to \hsize{
    \parindent 0em
    \hfil 
    \parbox{\dimen0}{\def\baselinestretch{0.96}\small
      {\bf #1.} #2
      %%\unhbox\@tempboxa
    } 
    \hfil}
  \else \hbox to \hsize{\hfil \box\@tempboxa \hfil}
  \fi
}
\makeatother

\begin{document}

\maketitle
\begin{abstract}
    We developed a forecasting methodology for providing credible forecasts for the time series data that have undergone a shock  by borrowing knowledge from disparate time series that have undergone similar shocks for which post-shock outcome is recorded. Three shock effects estimators were constructed for minimizing average forecast risk. We proposed risk-reduction propositions providing conditions when our methodology works. Bootstrap procedures are provided to estimate the variability of our shock effect estimators; and these procedures can be used to assess the potential prospective success of post-shock forecasts. %The risk-reduction propositions and risk-reduction quantities are powerful tools for users because we can empirically aid a prospective evaluation about whether the three aggregation techniques  will work well. 
    Leave-one-out cross validation is proposed to estimate correctness of risk-reduction propositions, prospectively informing users of the probabilities that this prospective evaluation is in line with the reality. Several simulated data examples, and a real data example of forecasting Conoco Phillips stock price are provided for verification and illustration.
\end{abstract}




\section{Introduction}


We provide forecasting adjustment techniques with the goal of lowering overall forecast error when the time series under study has undergone a structural shock in real-time. Standard forecasting methods may not allow users to explore the consequences that structural shocks have on baseline forecasts \citep{baumeister2014real}. This is a general problem that has many real life applications. For example, one may be interested in forecasting the stock price of a company tomorrow after hearing terrible or great news about the company  after hours trading. Companies may be interested in forecasting the demand of their products to adjust production after they were involved in a brand crisis, but they only have recent sales data for which the company is operating well. All is not lost in this setting, one may be able to supplement the present forecast with past data borrowed from disparate time series which contain similar structural shocks. The core idea of our methodology is to sensibly aggregate similar past realized shock effects which arose from disparate time series, and then incorporate the aggregated shock effect estimator into the present forecast. Our method of combining disparate shock effects embraces ideas from conditional forecasting \citep{baumeister2014real, kilian2017structural}, time series pooling using cross-sectional panel data \citep{ramaswamy1993empirical, pesaran1999pooled, hoogstrate2000pooling, baltagi2008forecasting, koop2012forecasting, liu2020forecasting}, forecasting with judgement and models \citep{svensson2005monetary, monti2008forecast}, synthetic control methodology \citep{abadie2010synthetic, agarwal2020two}, and expectation shocks \citep{croushore2006data, baumeister2014general, clements2019measuring}. 

We study the post-shock forecasting problem in the context of additive shock effects in linear autoregressive models. In this post-shock forecasting setting, the researcher has a time series of interest which is known to have recently undergone a structural shock, and the post-shock response is not observed. In this setting, the additive shock effect is a random effect that is parameterized in the autoregressive model. The shock effect is then estimated using ordinary least squares (OLS). The researcher must move beyond the modeling paradigm that they were previously working under to accommodate this new shock effect \citep{monti2008forecast, svensson2005monetary}. One method for estimating the shock effect is to produce a conditional point forecast where a sequence of non-zero future structural shocks are conditioned upon and estimated \citep{baumeister2014real}. Such conditional point forecasts are appropriate when the shock sequence considered is within the range of historical experience \citep{kilian2017structural}. On the other hand, our methodology allows for the inclusion of outside data sources and covariates into this conditional forecasting context provided that the shock effects are all thought to arise from a similar data generating process. For further differences of assumptions on shocks, our methodology allows for \emph{unprecedented} shocks and no observation of past shocks. 

In our methodological framework, the researcher creates a synthetic panel of disparate time series which have undergone similar structural shocks in the past. Construction of the donor pool that forms this synthetic panel is similar to that in synthetic control methodology (SCM) \citep{abadie2010synthetic}. As in SCM, care is needed when forming the donor pool of disparate time series. However, there are key differences between our framework and SCM. We assume that the disparate time series are independent from the time series under study before the timing of the shock {\bf Jilei, can weaken this assumption?}. We also assume that the shock effects for each disparate time series are independent realizations from some unknown distribution. 

We estimate the shock effects that are present in the disparate time series for which post-shock responses are observed. We then aggregate these estimated shock effects and use this aggregated estimate as an estimator for the shock effect in the time series of interest. This estimator is then added to a forecast for the yet to be realized post-shock response corresponding to the time series of interest. Shock effects in our post-shock forecasting framework is similar to ``expectation shocks'' which are studied in \cite{clements2019measuring}. The context in \cite{clements2019measuring} allowed for consistent estimation of expectation shocks under a vector autoregressive model, possibly involving an instrumental variable approach as in \cite{croushore2006data}. In our context, the yet to observed shock effect of interest is a random effect, and we can only partially estimate features of the random effect distribution using the disparate time series. 






%Therefore the traditional forecast combination framework may not be of any help.  
%The Bayesian hierarchical approach of \citet{lee2020estimation} may be too sensitive to prior and the hierarchical parametric model setup. Overall, it is very unlikely that the above mentioned methods will work ideally since they are trained on the time series data that do not experience such a shock. 


In this article, we will assume a simple auto regressive data generating process similar to that in \citet{blundell1998initial} with a general random effects structure. Therefore, our methodology is similar to the ``$K$ latent pooling'' framework of \cite{ramaswamy1993empirical}. However, our model formulation is more general than \cite{ramaswamy1993empirical}. In our model, the donor pool can consist of dependent time series but time series within the donor pool should be independent of the time series of interest. However, mutual independence among time series in the donor pool can aid prospective evaluation of the reliability of our method. 
%The main idea of our methodology is to provide a scalar adjustment, based on estimated shock effects from the disparate time series, which is added to the original forecast at the known shock time point. 
We consider three aggregation techniques: simple averaging, inverse-variance weighted averaging, and similarity weighting. The latter technique is similar to the weighting in synthetic control methodology \citep{abadie2010synthetic}. Our auto regressive model will consider present day and lagged covariates to better motivate similarity weighting. The considered adjustment strategies all target the mean of the shock effect distribution. However, such an estimation strategy can reduce mean squared error (MSE) when variation in the shock effect distribution is small relative to the mean. We provide risk-reduction propositions that detail the conditions when the adjusted forecasts will work better than the original forecast. The involved parameters in the risk-reduction propositions and risk-reduction quantities can be estimated by a residual bootstrap procedure that we develop within. %These propositions and risk-reduction quantities are powerful tools for users in the sense that we can empirically aid a prospective evaluation about whether the three aggregation techniques will work well before the post-shock response is observed. 
We also motivate a simple leave-one-out cross validation procedure which can prospectively assess the performance of our shock effect adjustment estimators. This prospective assessment does not require the observation of the post-shock response. Our Monte Carlo simulation results show that the risk-reduction propositions are nearly perfectly correct when the model for the shock effects is identified well with appropriate covariates under a fixed design. We demonstrate the utility of our methodology in a real data analysis in which we forecast the stock price of Conoco Phillips shares that experienced a large structural shock on March 9th, 2020. We show that our proposed adjustment estimators yield much better results than no adjustment in this setting. We also use this example to demonstrate settings in which the shock effect may be decomposed into separate estimable parts. We now motivate our framework for post-shock forecasting.


% Note that this methodology is not motivated with the goal of unbiased, asymptotically unbiased, or consistent estimation for the shock effect of the time series under study.


%The question is then how to estimate the shock effects and improve the 
%prediction? This paper proposes three estimators, the adjustment estimator, weighted adjustment estimator, and inverse-variance weighted estimators. Section (to be updated) discusses properties of those estimators. Section (to be updated) compares the  interplay between prediction risk and different shock effects estimators. Section (to be updated) conducts simulation to justify our claims and certain properties that cannot be found analytically.


\begin{figure}[H]
  \begin{center}
    \subfloat[A comparison between forecast without considering shock effects and the one uses simple averaging given $n=40$ disparate time series, and that the shock time is at $T_1^* +1=126$. The magenta dots represent least square estimate $\hat{\alpha}_i$ from disparate time series. The prediction of $\hat{y}^{2}_{T_1^*+1}$ and $\hat{y}^{1}_{T_1^*+1}$ differs only by an adjustment $\hat{\alpha}=5.22$. It is clear that $\hat{y}^{2}_{T_1^*+1}$ performs better than $\hat{y}^{1}_{T_1^*+1}$.]{\includegraphics[height = 7cm]{comp.pdf}}\\
     \subfloat[Histogram for $\hat{\alpha}_i$ for $i = 2, \ldots, n+1$]{\includegraphics[height = 7cm]{alphahist.pdf}}
  \end{center}
     \caption{The time series experience a shock at $T_1^*+1=126$ with true shock effect $\alpha = 4.21$. (a) presents the comparison of the prediction without adjustment and one with. (b) shows the histogram for the $\alpha_i$s used in estimating shock $\alpha_1$.}\label{figure1}
\end{figure}


\section{Setting}
\label{setting}

We will suppose that a researcher has time series data ($y_{i,t}$,$\x_{i,t}$), $t = 1$, $\ldots$, $T_i$, $i = 1$, $\ldots$, $n+1$, where $y_{i,t}$ is a scalar response and $\x_{i,t}$ is a vector of covariates that are revealed to the analyst prior to the observation of $y_{1,t}$.  Suppose that the analyst is interested in forecasting $y_{1,t}$, the first time series in the collection. 
%$y_1, y_2, \ldots$.  
%Given each time point $t \geq 1$, let $\x_{1,t}$ be a vector of covariates 
%revealed prior to the observation of $y_{1,t}$.  

We will suppose that specific interest is in forecasting the response after the occurrence of a structural shock. To gauge the performance of forecasts, we consider forecast risk in the form of mean squared error (MSE),
$$
  R_T = \frac{1}{T}\sum_{t=1}^T\E{\hat y_{1,t} - y_{1,t}}^2,
$$
and root mean squared error (RMSE), given by $\sqrt{R_T}$, in our analyses. Specific emphasis will be given to post-shock prediction where forecasts methods only differ at one future time point. In this setting we will consider the magnitude $|\E{\hat y_{1,t} - y_{1,t}}|$.


%The forecast consists of three steps: (1) pick a model, (2) selection of covariates, (3) choices of donor pool.
Our post-shock forecasting methodology will consist of selecting covariates $\x_{i,t}$, constructing a suitable donor pool of candidate time series that have undergone similar structural shocks to the time series under study, and specifying a model for the time series ($y_{i,t}$,$\x_{i,t}$), $t = 1$, $\ldots$, $T_i$, $i = 1$, $\ldots$, $n+1$. In this article, we consider a dynamic panel data model with autoregressive structure similar to that in \citet{blundell1998initial}. Our dynamic panel model includes an additional shock effect whose presence or absence is given by the binary variable $D_{i,t}$, and we will assume that the donor pool time series are independent of the time series under study. The details of this model are in the next section.



Figure \ref{figure1} provides a simple intuition of the practical usefulness of our proposed methodology. This figure depicts a time series that experienced a shock at time point $T_1^*+1 = 126$. It is supposed that the researcher does not have any information beyond $T_1^*+1$, but does have observations of forty disparate time series that have previously undergone a similar shock for which post-shock responses are recorded. Similarity in this context means that the shock effects are random variables that from a common distribution.
%As we can see, the purple line provides a better prediction than the red line in this particular example. But we will justify later that consideration of estimated shock effects will improve the prediction under certain conditions.
In this example, the mean of the estimated shock effects is taken as a shock effect estimator for the time series under study. Forecasts are then made by adding this shock effect estimator to the estimated response values obtained from the process that ignores the shock. It is apparent from Figure \ref{figure1} that adjusting forecasts in this manner 1) leads to a reduction in forecasting risk; 2) does not fully recover the true shock effect. We evaluate the performance of this post-shock forecasting methodology throughout this article; we outline situations for when it is expected to work and when it is not.




%Section \ref{properties} will provide a more detailed treatment about when our proposed estimators in Section \ref{constructionofestimators} will improve the prediction under various model setups in Section \ref{modelsetup}. More examples will be provided using Monte Carlo simulations in Section \ref{simulation}.



\subsection{Model Setup}

\label{modelsetup}

In this section, we will describe the assumed dynamic panel models for which 
post-shock aggregated estimators are provided. The basic structures of these models 
are the same for all time-series in the analysis, the differences between them lie in the setup of the shock effect distribution.

Let $I(\cdot)$ be an indicator function, $T_i$ be the time length of the time series $i$ for $i = 1, \ldots, n+1$, and $T_i^*$ be the time point just before the one when the shock is \emph{known} to occur, with $T_i^* < T_i$.  For $t= 1, \ldots, T_i$ and $i = 1, \ldots, n+1$, the model $\mc{M}_1$ is defined as
\begin{align}
\mc{M}_1 \colon y_{i,t} =\eta_i +\alpha_i D_{i,t} + \phi_i y_{i, t-1} + \theta_i'\mbf{x}_{i,t} + \varepsilon_{i,t}\label{equation1}
\end{align}
 where $D_{i,t} = I(t = T_i^* + 1)$ 
and $\x_{i,t} \in \R^{p}$ with $p \geq 1$.  We assume that the 
$\mbf{x}_{i,t}$'s are fixed. Let $|x|$ denote the absolute value of $x$ for $x\in \reals$. For $i = 1, \ldots, n+1$ and $t=1, \ldots, T_i$, the random effects structure for $\mc{M}_1$ is:
\begin{align*}
  \eta_i &\simiid  \; \E{\eta_i} = 0, \var{\eta_i} = \sigma^2_{\eta}\\
  \phi_i &\simiid \; |\phi_i|<1, \\
   \theta_i &\simiid  \; \E{\theta_i}=\mu_{\theta}, \var{\theta_i}=\Sigma_{\theta}^2 \\
\alpha_i &\simiid \; \E{\alpha_i}=\mu_{\alpha}, \var{\alpha_i}=\sigma_{\alpha}^2, \\
\varepsilon_{i,t} &\simiid \; \E{\varepsilon_{i,t}} =0, \var{\varepsilon_{i,t}}=\sigma^2 \where \sigma > 0 ,  \\
\eta_i &\indep  \alpha_i \indep \phi_i \indep \theta_i \indep \varepsilon_{i,t}.
\end{align*}
Notice that $\mc{M}_1$ assumes that $\alpha_i$ are iid with $\E{\alpha_i}=\mu_{\alpha}$ 
for $i = 1, \ldots, n+1$.  %Although synthesizing information from disparate time series assumes similarities of shock effects, shock effects may differ in terms of their means in practice. 
We also consider a model where the shock effects are linear functions of covariates with an additional additive mean-zero error.
%Additionally, $\mc{M}_1$ can be further improved in the sense that the shock effects may depend on the covariates around the shock time points, i.e., $T_i^*$ for $i = 1, \ldots, n+1$. 
%$\mc{M}_2$ can be constructed to accommodate those issues by imposing additional structures on the means of $\alpha_i$ as in (\ref{model2}) for $i = 1, \ldots, n+1$.
For $i = 1, \ldots, n+1$, the random effects structure for this model (model $\mc{M}_2$) is:
\begin{align}
\mc{M}_2 \colon \begin{array}{l}
  y_{i,t} =\eta_i +\alpha_i D_{i,t} + \phi_i y_{i, t-1} + \theta_i'\mbf{x}_{i,t} + \varepsilon_{i,t}\\[.2cm]
  \; \alpha_i = \mu_{\alpha}+\delta_{i}'\mbf{x}_{i, T_i^*+1}+ \t{\varepsilon}_{i},
\end{array}\label{model2}
\end{align}
 where the added random effects are
\begin{align*}
\t{\varepsilon}_{i} &\simiid  \E{\t{\varepsilon}}=0, \var{\t{\varepsilon}}=\sigma^2_{\alpha} \where \sigma_{\alpha}>0\\
\eta_i &\indep  \alpha_i \indep \phi_i \indep \theta_i \indep \varepsilon_{i,t} \indep \t{\varepsilon}_{i}.
\end{align*}
%and $\delta_i$ and $\gamma_i$ will be discussed shortly. 
We further define 
$\tilde{\alpha}_i=\mu_{\alpha}+\delta_i'\mbf{x}_{i, T_i^*+1}$. 
We will investigate the post-shock aggregated estimators in $\mc{M}_2$ 
in settings where $\delta_i$ is either fixed or random. 
We let $\mc{M}_{21}$ denote model $\mc{M}_{2}$ with $\delta_i = \delta$ for $i= 1, \ldots, n+1$, 
where $\delta$ is a  fixed unknown parameter.
We let $\mc{M}_{22}$ denote model $\mc{M}_{2}$ with the following random effects 
structure for $\delta_i$:
\begin{align*}
\delta_i \overset{iid}{\sim}\;  \mrm{E}(\delta) = \mu_\delta, \var{\delta} = \Sigma_\delta
   \quad \text{ with } \quad  \delta_i  \indep \t{\varepsilon}_{i}.
\end{align*}
We further define the parameter sets
\begin{align}
  \begin{array}{lll}
     \Theta &= &\{(\eta_i, \phi_i, \theta_i, \alpha_i, \mbf{x}_{i,t}, y_{i,t-1}, \delta_i)\colon t= 1, \ldots, T_i, i = 2, \ldots, n +1\},\\
    \Theta_1 &= &\{(\eta_i, \phi_i, \theta_i, \alpha_i, \mbf{x}_{i,t}, y_{i,t-1}, \delta_i)\colon t= 1, \ldots, T_i, i = 1\},\label{parameter}
  \end{array}
\end{align}
where $\Theta$ and $\Theta_1$ can adapt to $\mc{M}_1$ by dropping $\delta_i$. We assume this for notational simplicity.



\subsection{Forecast}
\label{forecast}
In this section we show how post-shock aggregate estimators improve upon standard 
forecasts that do not account for the shock effect.
%The interest of this study lies in comparing how consideration of shock effects 
%improves the prediction. 
More formally, we will consider the following candidate forecasts: 
\begin{align*}
  &\text{Forecast 1}: \hat y_{1,T_1^*+1}^1 = \hat\eta_1 
    + \hat\phi_1 y_{1,T_1^*} + \hat\theta_1'\x_{1,T_1^*+1} 
    , \\
  &\text{Forecast 2}: \hat y_{1,T_1^*+1}^2 = \hat\eta_1 
    + \hat\phi_1 y_{1,T_1^*} + \hat\theta_1'\x_{1,T_1^*+1} 
    + \hat{\alpha},
\end{align*}
where $\hat\eta_1$, $\hat\phi_1$, and $\hat\theta_1$ are all OLS estimators of $\eta_1$, $\phi_1$, and $\theta_1$, respectively, and $\hat{\alpha}$ is some form of estimator for the shock effect of time series of interest, i.e., $\alpha_1$. 
The first forecast ignores the presence of $\alpha_1$ while the second forecast 
incorporates an estimate of $\alpha_1$ that is obtained from the other independent forecasts under study. 
%Under $\mc{M}_1$ (Section \ref{modelsetup}), $\E{\alpha_1} = \mu_{\alpha}$.

Note that the two forecasts do not differ in their predictions for 
$y_{1,t}$, $t = 1,\ldots T_1^*$. Instead, they only differ in predicting 
$y_{1,T_1^*+1}$. Throughout the rest of this article we show that the collection of 
disparate time series $\{y_{i,t}, t = 1,\ldots,T_i, i = 2,\ldots,n+1\}$ has 
the potential to improve the forecasts for $y_{1, t}$ when $t > T_1^*$ under different 
circumstances for the dynamic panel model $\mc{M}_1$, $\mc{M}_{21}$, and $\mc{M}_{22}$. Improvement will be  measured by \emph{risk-reduction quantity}, which is the difference between the risk of Forecast 1 and Forecast 2. We will return to the theoretical details of risk-reduction quantity in Section \ref{properties}.

We specifically focus on predictions for $y_{1,T_1^*+1}$, the first post-shock response. It is important to note that in general $\hat{\alpha}$ 
is not a consistent estimator of the unobserved $\alpha_1$ nor does it converge 
to $\alpha_1$.  Despite these inferential shortcomings, adjustment of the forecast 
for $y_{1,T_1^*+1}$ through the addition of $\hat{\alpha}$ has 
the potential to lower forecast risk under several conditions corresponding to 
different estimators of $\alpha_1$. % which will be discussed shortly.


\subsection{Construction of shock effects estimators}
\label{constructionofestimators}

We now construct the aggregate estimators of the shock effects that appear in 
Forecast 2 (see Section \ref{forecast}). We use these to forecast response values $y_{1, T_1^*+1}$ assuming that $T_1^*$ is known.  %Notice that the shock effect 
%for time series $1$ is typically unobserved. But we can gather knowledge from 
%disparate time series to construct some sort of estimators that may be helpful for 
%estimating $\E{\alpha_1}$. 
First, we introduce the procedures of parameter estimation for 
$\mc{M}_1$, $\mc{M}_{21}$, and $\mc{M}_{22}$ (see Section \ref{modelsetup}). 
Conditional on all regression parameters, previous responses, and covariates, 
the response variable $y_{i,t}$ in $\mc{M}_1$, $\mc{M}_{21}$, and $\mc{M}_{22}$ 
has distribution 
$$
  y_{i,t} 
    \sim N(\eta_i + \alpha_iD_{i,t} + \phi_i y_{i,t-1} + \theta_i'\x_{i,t} 
      , \sigma^2).
$$
For $i = 2, \ldots, n+1$, all parameters in this model will be estimated with ordinary least squares 
(OLS) using historical data of $t = 1, \ldots, T_i$. For $i = 1$, we estimate all the parameters but $\alpha_1$ using OLS procedures for $t=1, \ldots, T_1^*$. In particular, let $\hat{\alpha}_i$, $i = 2, \ldots, n+1$ be the OLS estimate 
of $\alpha_i$.  Note that parameter estimation 
for $\mc{M}_1$ is identically the same as that for $\mc{M}_{21}$ or $\mc{M}_{22}$.  We emphasize that $\alpha_i$s are random variables but the OLS estimation is conditioned on the their realizations from some distribution.


Second, we introduce the candidate estimators for $\alpha_1$. Define the 
\emph{adjustment estimator} for time series $i=1$ by
\begin{equation} \label{adjusted}
  \hat{\alpha}_{\text{adj}} = \frac{1}{n}\sum_{i=2}^{n+1}\hat{\alpha}_i,
\end{equation}
where the $\hat{\alpha}_i$s in \eqref{adjusted} are OLS estimators of all of 
the $\alpha_i$s for $i = 2, \ldots, n+1$.  We can use $\hat{\alpha}_{\text{adj}}$ as an estimator for 
the unknown $\alpha_1$ term for which no meaningful estimation information 
otherwise exists. It is intuitive that $\hat{\alpha}_{\rm adj}$ should perform 
well under $\mc{M}_1$ where we assume that $\alpha_i$'s share the same mean 
for $i= 1, \ldots, n+1$. However, it can also be shown that 
$\hat{\alpha}_{\rm adj}$ may be less favorable in $\mc{M}_{21}$ 
and $\mc{M}_{22}$, which will be discussed in detail in Section \ref{properties}. 

We also consider the \emph{inverse-variance weighted estimator} 
in practical settings where the $T_i$'s and $T_i^*$'s vary greatly across $i=2, \ldots, n+1$. 
The inverse-variance weighted estimator is defined as 
\begin{align*}
  \hat{\alpha}_{\rm IVW} = \frac{\sum_{i=2}^{n+1} \hat{\alpha}_i / \hat{\sigma}_{i\alpha}^2}{\sum_{i=2}^{n+1} 1/\hat{\sigma}_{i\alpha}^2},
  \quad \text{ where } \quad  \hat{\sigma}_{i\alpha}^2 = \hat{\sigma}^2_i( \mathbf{U}_i'\mbf{U}_i)_{22}^{-1},
\end{align*}
where  $\hat{\alpha}_i$ is the OLS estimator of $\alpha_i$, 
$\hat{\sigma}_i$ is the residual standard error from OLS estimation, 
and $\mbf{U}_i$ is the design matrix for OLS with respect to time series 
for $i = 2, \ldots, n+1$. Note that since $\sigma$ is unknown, estimation 
is required and the numerator and denominator terms are dependent in general. 
%It is hard to evaluate its expectation and variance. 
%But it is clear 
%that $\hat{\alpha}_{\rm IVW}$ will generally not be unbiased. 
However, $\hat{\alpha}_{\rm IVW}$ can be a reasonable estimator in 
practical settings. %when the change 
%point is not symmetric and/or there are some series with small or large number 
%of time points recorded. We will then investigate the performance of this 
%estimator in simulation (Section \ref{simulation}).
We do not provide closed form expressions for $\E{\hat{\alpha}_{\rm IVW}}$ 
and $\var{\hat{\alpha}_{\rm IVW}}$ but empirical performance of 
$\hat{\alpha}_{\rm IVW}$ is assessed via Monte Carlo simulation 
(see Section \ref{simulation}).

%More importantly, we introduce the backgrounds and procedures of constructing \emph{weighted-adjustment estimator} as follows. 
We now motivate a \emph{weighted-adjustment estimator} for model $\mc{M}_{21}$ 
and $\mc{M}_{22}$. Our weighted-adjustment estimator is inspired by the 
weighting techniques in synthetic control methodology (SCM) developed 
in \cite{abadie2010synthetic}. 
%we intend to construct a weighted adjustment estimator by using similar but 
%different methods. 
However, our weighted-adjustment estimator is not a causal estimator and 
our estimation premise is a reversal of that in SCM. 
%The case study of \citet{abadie2010synthetic} in essence observes the data and 
%estimates the effect of policy. 
Our objective is in predicting a post-shock response $y_{1,T_1^*+1}$ that is not yet 
observed using disparate time series whose post-shock responses are observed.
%However, the idea of merging information from  similar events (i.e., time series in our 
%study) to improve the solutions for the problem of interest should be the same. 

We use similar notation as that in \cite{abadie2010synthetic} to motivate our weighted-adjustment estimator. Consider a $\mbf{W} \in \R^n$ weight vector 
$\mbf{W}=(w_2, \ldots, w_{n+1})'$, where $w_i\in [0,1]$ for all 
$i = 2, \ldots, n+1$. Construct
\begin{align*}
 \mbf{X}_1 = \mbf{x}_{1, T_1^*+1}',
  \quad  
  \mbf{X} = \begin{pmatrix}
    \mbf{x}_{2, T_2^*+1}' \\
    \vdots \\
    \mbf{x}_{n+1, T_{n+1}^*+1}'
  \end{pmatrix},
  \quad \text{and} \quad 
  \hat{\mbf{X}}_1(\mbf{W}) 
    = \mbf{W}'\mbf{X},
\end{align*}
where $\mbf{X}_1,\hat{\mbf{X}}_1(\mbf{W}) \in \R^{1 \times p}$. Define $\mc{W}=\{\mbf{W}\in [0,1]^n \colon 1_n'\mbf{W} = 1 \}$. 
Suppose there exists $\mbf{W}^*\in \mc{W}$ with 
$\mbf{W}^*=(w_2^*, \ldots, w_{n+1}^*)'$ such that
\begin{align}
 \mbf{X}_1=\hat{\mbf{X}}_1(\mbf{W}^*),  \quad i.e., \quad \mbf{x}_{1, T_1^*+1} = \sum_{i=2}^{n+1} w_i^*\mbf{x}_{i, T_i^*+1}.\label{SCM}
\end{align}
 Notice that $\mbf{W}^*$ exists as long as $\mbf{X}_1$ falls in the convex hull of 
 \begin{align*}
   \left\{ \mbf{x}_{2, T_2^*+1}', \ldots, \mbf{x}_{n+1, T_{n+1}^*+1}' \right\}.
 \end{align*}
{\bf Jilei, can you add clarity to this point? It is hard to see why this works on the first viewing.}
%It is a reasonable assumption that the pool of time series that we are considering 
%should be similar to the time series of interest. 
Our weighted-adjustment estimator will therefore perform well when the pool of 
disparate time series posses similar covariates to the time series for which 
no post-shock responses are observed. We compute $\mbf{W}^*$ as
\begin{align}
  \mbf{W}^* = \argmin_{\mbf{W}\in \mc{W}} \norm{\mbf{X}_1-\hat{\mbf{X}}_1(\mbf{W})}_{p}. 
  \label{W}
\end{align}
%which is a more general form of $\mbf{W}^*$ for the case when $\mbf{X}_1$ does not fall in the convex hull of (\ref{convexhull}). 
\cite{abadie2010synthetic} commented that we can select $\mbf{W}^*$ 
so that (\ref{SCM}) holds approximately %so that the property of $\mbf{W}^*$ should 
%still hold approximately 
and that weighted-adjustment estimation techniques of this form are not 
appropriate when the fit is poor. 
Note that $\mbf{W}^*$ is not random since the covariates are assumed to be fixed. Since $\mc{W}$ is a closed and bounded subset of $\reals^n$,  $\mc{W}$ is compact. Because the objective function 
is continuous in $\mbf{W}$, $\mbf{W}^*$ will always exist. %Relying on this weight, 
%we are mainly interested in constructing the following adjustment estimator:
Our weighted-adjustment estimator for the shock effect $\alpha_1$ is
  \begin{align*}
    \hat{\alpha}_{\rm wadj} = \sum_{i=2}^{n+1} w_i^*\hat{\alpha}_i
    \quad \text{ for } \quad \mbf{W}^* = \begin{pmatrix}
      w^*_2 & \cdots & w^*_{n+1}
    \end{pmatrix}'.
  \end{align*}
 %Different from \citet{abadie2010synthetic}, our construction customizes synthetic control methods to the setting of AR(1) model. To be more specific, notice that (\ref{SCM}) implicitly uses the covariates at $T_*$ the shock-time and $T_*-1$ the time point just before the shock. This model somehow accounts for the impact of past information on the shock effects. 
 We further define
\begin{align*}
  \mathbf{V} = (\mathbf{x}_{2, T_2^*+1}, \ldots,\mathbf{x}_{n+1, T_{n+1}^*+1}).
\end{align*}
\begin{prop}
  \label{uniqueness} If $\mathbf{V}$ has full rank and it exists some $\mathbf{W}$ satisfies (\ref{SCM}), the solution to  (\ref{W}) is unique.
\end{prop} 
Proposition \ref{uniqueness} details some conditions when $\mathbf{W}^*$ is unique.  Note that $\mathbf{V}$ is $p \times n$. Therefore, if the covariates are of full rank and the true solution lies in the convex and compact $\mathcal{W}$, a sufficient condition for $\mathbf{W}^*$ to be unique is $p \geq n$. However, when $p < n$, $\mathbf{W}^*$ may not be unique. If it exists some $\mathbf{W}^*$ satisfies (\ref{SCM}) and $p < n$, there are infinitely many solutions to (\ref{SCM}).  The issue of non-uniqueness is further discussed in Section \ref{varbootstrap}.

\begin{remark}
% Though in Section \ref{modelsetup} we assume $\mbf{x}_{i,t}\in \reals^p$ and bases construction for $\hat{\alpha}_{\rm adj}$ and $\hat{\alpha}_{\rm wadj}$  on this fact, we will shortly show that the covariates need not be of the same dimension across disparate time series. 
In Section \ref{modelsetup} we specify that $\mbf{x}_{i,t}, \theta_i \in \reals^p$. 
 % We can insert $\mathbf{0}$ into the covariates of disparate time series for the parts that they do not share. For example, suppose $\mathbf{x}_{2, t}, \mathbf{x}_{2, t-1}\in \reals^{p-1}$ and $\mathbf{x}_{3, t}, \mathbf{x}_{3, t-1}\in \reals^p$ are the covariates for time series 2 and 3. Assume that the $p$th column of $\mathbf{x}_{3, t}, \mathbf{x}_{3, t-1}$ is the part they do not share. In this case, we can let $\mathbf{x}^{adj}_{2, t}=(\mathbf{x}_{2, t}, \mathbf{0})$, $\mathbf{x}^{adj}_{2, t-1}=(\mathbf{x}_{2, t-1}, \mathbf{0})$ to satisfy the $p$-dimension requirement. 
However, it is not necessary that the all $p$ covariates are important for every time series under study. The regression coefficients $\theta_i$ are nuisance parameters that are not of primary importance. 
% In this regard, OLS estimations in software can reparameterize the design matrix.  Of course, the column space of the design matrix does not change compared to the one in original dimension. Thus, the least squares estimators do not change. In other words, OLS estimation need no adjustment. The generalization may only apply to the construction of weighted-adjustment  estimator $\hat{\alpha}_{\rm wadj}$.
It will be understood that structural 0s in $\theta_i$ correspond to variables that are unimportant. 
\end{remark}

\begin{remark}
  Our forecasting premise and estimation construction shares similarities with Bayesian viewpoints. From a Bayesian perspective, if we assign a prior $\pi$ to $\alpha_1$, $\hat{\alpha}_{\rm adj}$, $\hat{\alpha}_{\rm wadj}$, and $\hat{\alpha}_{\rm IVW}$ can be interpreted as the Bayes rules with respect to $\pi$ under different loss functions. If the sampling distribution of the data and $\pi$ are known, it is possible to compute the Bayes risks of $\hat{\alpha}_{\rm adj}$, $\hat{\alpha}_{\rm wadj}$, and $\hat{\alpha}_{\rm IVW}$ with respect to $\pi$, and thus enable comparisons among them. Additionally, from Theorem 2.4 in Chapter 5 of \cite{lehmann2006theory}, $\hat{\alpha}_{\rm adj}$, $\hat{\alpha}_{\rm wadj}$, and $\hat{\alpha}_{\rm IVW}$ are admissible if they are unique with probability one.
\end{remark}

\section{Forecast risk and properties of shock effects estimators}
\label{properties}

In this section, we discuss the properties that are related to forecast-risk reduction. In discussion of risk, it is useful to derive expressions for expectation and variance of the adjustment estimator $\hat{\alpha}_{\rm adj}$ and weighted-adjustment estimator.  The expressions for the expectations are as follow,

 \begin{enumerate}[label = (\roman*)]
    \item Under $\mc{M}_{1}$, $\E{\hat{\alpha}_{\rm adj}}=\E{\hat{\alpha}_{\rm wadj}} = \mu_{\alpha}$.
    \item Under $\mc{M}_{21}$, 
    \begin{align*}
      \E{\hat{\alpha}_{\rm adj}} = \mu_{\alpha} + \frac{1}{n} \sum_{i=2}^{n+1} \delta' \mbf{x}_{i, T_i^*+1} 
      \quad \text{ and } \quad 
       \E{\hat{\alpha}_{\rm wadj}} = \mu_{\alpha} + \delta'\mbf{x}_{1, T_1^*+1} .
    \end{align*}
    \item Under $\mc{M}_{22}$,
    \begin{align*}
      \E{\hat{\alpha}_{\rm adj}} = \mu_{\alpha} + \frac{1}{n} \sum_{i=2}^{n+1} \mu_{\delta}' \mbf{x}_{i, T_i^*+1}
      \quad \text{ and } \quad 
       \E{\hat{\alpha}_{\rm wadj}} = \mu_{\alpha} + \mu_{\delta}'\mbf{x}_{1, T_1^*+1} .
    \end{align*}
  \end{enumerate}
Formal justification for these results can be found in Appendix. Note that $\hat{\alpha}_{\rm adj}$, $\hat{\alpha}_{\rm wadj}$, and $\hat{\alpha}_{\rm IVW}$ are not unbiased estimators for $\alpha_1$. Notice that under $\mc{M}_{1}$, $\hat{\alpha}_{\rm adj}$ and $\hat{\alpha}_{\rm adj}$ are unbiased estimators for $\E{\alpha_1}=\mu_{\alpha}$ (see distributional details of $\alpha_1$ in Section \ref{modelsetup}). Nevertheless, $\hat{\alpha}_{\rm adj}$ is a biased estimator for $\E{\alpha_1}$ but $\hat{\alpha}_{\rm wadj}$ is an unbiased estimator for $\E{\alpha_1}$ under both $\mc{M}_{21}$ and $\mc{M}_{22}$. Thus, we collect these results  as the following proposition. 

\begin{prop}
\label{unbiased} 
\quad 
\begin{enumerate}[label = (\roman*)]
  \item Under $\mc{M}_1$, $\hat{\alpha}_{\rm adj}$ is an unbiased estimator of $\E{\alpha_1}$. Under $\mc{M}_{21}$ and $\mc{M}_{22}$, $\hat{\alpha}_{\rm adj}$ is a biased estimator of $\E{\alpha_1}$ in general.
  \item Suppose that $\mbf{W}^*$ satisfies (\ref{SCM}). Under $\mc{M}_{1}$, $\mc{M}_{21}$ and $\mc{M}_{22}$, $\hat{\alpha}_{\rm wadj}$ is an unbiased estimator of $\E{\alpha_1}$.
\end{enumerate}
\end{prop}


Unbiasedness properties for $\E{\alpha_1}$ of $\hat{\alpha}_{\rm adj}$ and $\hat{\alpha}_{\rm wadj}$ allow for simple risk-reduction conditions, and more importantly motivates a bootstrap estimation for evaluation of these conditions. % for $\hat{\alpha}_{\rm adj}$ and  $\hat{\alpha}_{\rm wadj}$ to reduce risk, and make it more clear with respect to when one is better than the other. 
These conditions and bootstrap will be discussed in Section \ref{conditions} and \ref{varbootstrap}, respectively. Next, we present the variance expressions for $\hat{\alpha}_{\rm adj}$ and $\hat{\alpha}_{\rm wadj}$ as below.

\begin{enumerate}[label = (\roman*)]
  \item Under $\mc{M}_1$ and $\mc{M}_{21}$,  
\begin{align*}
  \var{\hat{\alpha}_{\rm adj}} 
  &=\frac{\sigma^2}{n^2}\sum_{i=2}^{n+1}\mrm{E}\big\{(\mbf{U}'_i\mbf{U}_i)^{-1}_{22}\big\}+\frac{\sigma^2_{\alpha}}{n^2}\\
\var{\hat{\alpha}_{\rm wadj}}  &= \sigma^2\sum_{i=2}^{n+1}(w_i^*)^2\mrm{E}\big\{(\mbf{U}'_i\mbf{U}_i)^{-1}_{22}\big\}+\sigma^2_{\alpha}\sum_{i=2}^{n+1}(w_i^*)^2
\end{align*}
\item Under $\mc{M}_{22}$, 
\begin{align*}
\var{\hat{\alpha}_{\rm adj}} 
  &=\frac{\sigma^2}{n^2}\sum_{i=2}^{n+1}\mrm{E}\big\{(\mbf{U}'_i\mbf{U}_i)^{-1}_{22}\big\}+\frac{1}{n^2}(\mbf{x}_{i, T_i^*+1}'\Sigma_{\delta}\mbf{x}_{i, T_i^*+1} + \sigma^2_{\alpha})\\
  \var{\hat{\alpha}_{\rm wadj}} 
  &= \sigma^2\sum_{i=2}^{n+1}(w_i^*)^2\mrm{E}\big\{(\mbf{U}'_i\mbf{U}_i)^{-1}_{22}\big\}
  + \sum_{i=2}^{n+1} (w_i^*)^2 (\mbf{x}_{i, T_i^*+1}'\Sigma_{\delta}\mbf{x}_{i, T_i^*+1} + \sigma^2_{\alpha}).
\end{align*}
\end{enumerate}
Formal justification for these results can be found in Appendix. Note that the variances are not comparable in closed-form %we shall see that it is difficult to compare variances between $\hat{\alpha}_{\rm adj}$ and $\hat{\alpha}_{\rm wadj}$ 
because of the term $\mrm{E}\big\{(\mbf{U}'_i\mbf{U}_i)^{-1}_{22}\big\}$.  This term exists because of the inclusion of the random lagged response in our auto regressive model formulation.  Under $\mc{M}_{22}$, the expression for $\var{\alpha_i}$ is not of closed form because $\gamma_i$ and $\delta_i$ may be dependent when they are placed in a random-effects model.  



Section \ref{conditions} details conditions needed for risk-reduction and comparisons of adjustment estimators. These conditions involve variances and expectations which may be difficult to compute in practice. To make use of those properties in practice, estimation is required. Sections \ref{varbootstrap} and \ref{loocv} introduce  parametric bootstrap and leave-one-out cross validation procedures which prospectively estimate the conditions necessary for risk-reduction without observation of the post-shock response for the time series under study. Our simulations test these procedures. 


\subsection{Risk-reduction conditions for shock effects estimators}
\label{conditions}

In this section we will discuss the conditions for risk reduction for individual shock effects estimators under $\mc{M}_1$, $\mc{M}_{21}$, and $\mc{M}_{22}$. %The reason is that if the estimator of $\alpha_1$ turns out to be an unbiased estimator of $\E{\alpha_1}$, the conditions get  simplified. 

\subsubsection{Conditions under $\mc{M}_1$}
 \label{conditionsmodel1}
 
Recall that Proposition \ref{unbiased} implies that the adjustment estimator $\hat{\alpha}_{\rm adj}$ and weighted-adjustment estimator $\hat{\alpha}_{\rm wadj}$ are unbiased for $\E{\alpha_1}$ under $\mc{M}_1$. With this result, we will have  the following propositions that specify the conditions that are necessary for risk reduction. 

\begin{prop}
\label{proprisk}Under $\mc{M}_1$,
\begin{enumerate}[label = (\roman*)]
  \item  $R_{T_1^*+1, 2} < R_{T_1^*+1, 1}$ when 
$\Var(\hat{\alpha}_{\rm adj}) < \mu_{\alpha}^2$.
  \item if $\mbf{W}^*$ satisfies (\ref{SCM}), $R_{T_1^*+1,2}<R_{T_1^*+1,1}$ when $\var{\hat{\alpha}_{\rm wadj}}<\mu_{\alpha}^2$. 
\end{enumerate}
\end{prop}

Proposition \ref{proprisk} tells that under $\mc{M}_1$ if the variance of the estimator is smaller than the squared mean of $\alpha_1$, those estimators will enjoy the risk reduction properties. Recalling from variance expression at the beginning of Section \ref{properties}, Proposition \ref{proprisk} shows that the risk-reduction condition is
\begin{align}
  \var{\hat{\alpha}_{\rm adj}} 
  &=\frac{\sigma^2}{n^2}\sum_{i=2}^{n+1}\mrm{E}\big\{(\mbf{U}'_i\mbf{U}_i)^{-1}_{22}\big\}+\frac{\sigma^2_{\alpha}}{n^2} < \mu_{\alpha}^2. \label{riskconditionadj}
\end{align}

Condition (\ref{riskconditionadj}) implies two facts: (1) adjustment (Forecast 2) is preferable to no adjustment (Forecast 1) asymptotically in $n$ whenever $\mu_{\alpha} \neq 0$ (see Forecast in Section \ref{forecast}); (2) In finite donor pool settings, adjustment is preferable to no adjustment when $\mu_{\alpha}$ is large relative to its variability and overall regression variability.   %This result is also intuitive. For example, if  $\mu_{\alpha}$ is large, Forecast 1 will definitely work poor because large  $\mu_{\alpha}$ implies shock effects that cannot be ignored.  See Section \ref{forecast} for forecast formulation for details.

For the weighted-adjustment estimator $\hat{\alpha}_{\rm wadj}$, if  $\mathbf{W}^*$ does not satisfy (\ref{SCM}), its unbiased properties for $\E{\alpha_1}$ should hold approximately when the fit in (\ref{W}) is appropriate as commented in Section \ref{constructionofestimators}. From Proposition \ref{proprisk} and the variance expression for $\hat{\alpha}_{\rm wadj}$, the risk-reduction condition for $\hat{\alpha}_{\rm wadj}$ is
\begin{equation} \label{varwadj}
\var{\hat{\alpha}_{\rm wadj}}
 = \sigma^2\sum_{i=2}^{n+1}(w_i^*)^2\mrm{E}\big\{(\mbf{U}'_i\mbf{U}_i)^{-1}_{22}\big\}+\sigma^2_{\alpha}\sum_{i=2}^{n+1}(w_i^*)^2 < \mu_{\alpha}^2.
\end{equation}
In this case, adjustment is preferable to no adjustment when $\mu_{\alpha}$ is large relative to the weighted sum of variances for shock effects for other time series and overall regression variability.  However, the above criteria are generally difficult to evaluate in practice due to the term $\mrm{E}\big\{(\mbf{U}'_i\mbf{U}_i)^{-1}_{22}\big\}$. 


In fact, we can extend checking risk-reduction conditions to verifying the sign of risk-reduction quantities for generalization. For an adjustment estimator $\hat{\alpha}$, the risk-reduction quantity is defined as  $\Delta(\hat{\alpha})=R_{T_1^*+1,1}-R_{T_1^*+1,2}$. If $\Delta(\hat{\alpha})>0$, $\hat{\alpha}$ will improve the Forecast 1. In this context, according to Proposition \ref{proprisk}, under $\mc{M}_1$, $\Delta(\hat{\alpha}_{\rm adj})= \mu_{\alpha}^2-\var{\hat{\alpha}_{\rm adj}}$ and $\Delta(\hat{\alpha}_{\rm wadj})= \mu_{\alpha}^2-\var{\hat{\alpha}_{\rm wadj}}$. Sections \ref{varbootstrap} and \ref{loocv} will provide a detailed treatment about how to checking the sign  in practice.



\subsubsection{Conditions under $\mc{M}_{21}$ and $\mc{M}_{22}$}
\label{conditionsm2122}

The shock effects $\alpha_i$s have different means under $\mc{M}_{21}$ and $\mc{M}_{22}$ unlike under $\mc{M}_1$. %It is a more reasonable and general model since it is often the case that shock effects differ by means among disparate time series in practice. $\mc{M}_{22}$  further adds the random effect structure of $\delta$ and $\gamma$ to  $\mc{M}_{21}$ for generalization.
However, Proposition \ref{unbiased} implies that $\hat{\alpha}_{\rm wadj}$ is an unbiased estimator of $\E{\alpha_1}$. %From Proposition \ref{varprop}, the risk-reduction condition for $\hat{\alpha}_{\rm wadj}$  will be as in Proposition \ref{propriskwadj2}. 
We now state conditions for risk-reduction.

\begin{prop}
\label{propriskwadj2} If $\mbf{W}^*$ satisfies (\ref{SCM}), under $\mc{M}_{21}$ and $\mc{M}_{22}$, $R_{T_1^*+1,2}<R_{T_1^*+1,1}$ when $\var{\hat{\alpha}_{\rm wadj}}<(\E{\alpha_1})^2$. 
\end{prop}
Under Proposition \ref{propriskwadj2}, we can obtain a risk-reduction inequality that is similar to \eqref{varwadj},
\begin{align*}
\var{\hat{\alpha}_{\rm wadj}}
 = \sigma^2\sum_{i=2}^{n+1}(w_i^*)^2\mrm{E}\big\{(\mbf{U}'_i\mbf{U}_i)^{-1}_{22}\big\} + \sum_{i=2}^{n+1} (w_i^*)^2 (\mbf{x}_{i, T_i^*+1}'\Sigma_{\delta}\mbf{x}_{i, T_i^*+1} + \sigma^2_{\alpha}) < (\E{\alpha_1})^2,
\end{align*}
where $\mbf{x}_{i, T_i^*+1}'\Sigma_{\delta}\mbf{x}_{i, T_i^*+1} + \sigma^2_{\alpha}$ may be replaced with $\sigma^2_{\alpha}$ in $\mc{M}_{21}$. The conclusions and intuitions will be identically the same as what we have in Section \ref{conditionsmodel1}. Proposition \ref{unbiased} shows that $\hat{\alpha}_{\rm adj}$ is a biased estimator of $\E{\alpha_1}$ under $\mc{M}_{21}$ and $\mc{M}_{22}$ generally. Hence, Proposition \ref{proprisk} no longer holds for $\hat{\alpha}_{\rm adj}$ under $\mc{M}_{21}$ and $\mc{M}_{22}$.

As an alternative, we can derive similar risk-reduction conditions that are appropriate for this setting. By Lemma \ref{risklemma} (see Section \ref{proofs}) and risk decomposition, we will achieve risk-reduction as long as
\begin{align*}
 \E{\alpha_1^2}= \var{\alpha_1}+(\E{\alpha_1})^2
 &>\E{\hat{\alpha}_{\rm adj}-\alpha_1}^2\\
  &=\var{\hat{\alpha}_{\rm adj}} +  (\E{\hat{\alpha}_{\rm adj}}-\alpha_1)^2 \\
  &=\var{\hat{\alpha}_{\rm adj}} +  \var{\alpha_1} + (\E{\hat{\alpha}_{\rm adj}}-\E{\alpha_1})^2.
\end{align*}
The above inequality simplifies to 
\begin{equation} \label{ineq}
 (\E{\alpha_1})^2 >\var{\hat{\alpha}_{\rm adj}}+ (\E{\hat{\alpha}_{\rm adj}}-\E{\alpha_1})^2.
\end{equation}

%A simple mean-squares decomposition produces the following inequality for assessing the favorability of $\hat{\alpha}_{\rm wadj}$ to $\hat{\alpha}_{\rm adj}$ under models $\mc{M}_{21}$ and $\mc{M}_{22}$,
% \begin{align*}
%  \var{\hat{\alpha}_{\rm adj}} 
%  -\var{\hat{\alpha}_{\rm wadj}} + \big(\E{\hat{\alpha}_{\rm adj}}-\mrm{E}(\alpha_1)\big)^2> 0.
%\end{align*}

%If it turns out to be fact that the variance of the weighted-adjustment estimator is greater than that of adjustment estimator, we should be aware that  the compromise for variance because of using $\hat{\alpha}_{\rm wadj}$ shouldn't exceed the squared bias, i.e., $\big(\E{\hat{\alpha}_{\rm adj}}-\mrm{E}(\alpha_1)\big)^2$.
 


As mentioned in Section \ref{constructionofestimators}, it is difficult to evaluate the expectation and variance of $\hat{\alpha}_{\rm IVW}$. We note that $\hat{\alpha}_{\rm IVW}$ is generally biased for $\E{\alpha_1}$. That is to say we can adapt the above proof to derive the risk-reduction conditions for $\hat{\alpha}_{\rm IVW}$: under $\mc{M}_{1}$, $\mc{M}_{21}$, and $\mc{M}_{22}$, $R_{T_1^*+1,2}<R_{T_1^*+1,1}$ when $\var{\hat{\alpha}_{\rm IVW}} +(\E{\hat{\alpha}_{\rm IVW}}-\E{\alpha_1})^2<(\E{\alpha_1})^2$.  Therefore, using the generalization mentioned in Section \ref{conditionsmodel1}, under $\mc{M}_2$, it can be shown that the risk-reduction quantities are
\begin{align*}
  \Delta(\hat{\alpha}_{\rm adj}) 
  &= (\E{\alpha_1})^2 -\var{\hat{\alpha}_{\rm adj}}-(\E{\hat{\alpha}_{\rm adj}}-\E{\alpha_1})^2\\
  \Delta(\hat{\alpha}_{\rm IVW}) 
  &= (\E{\alpha_1})^2 -\var{\hat{\alpha}_{\rm IVW}}-(\E{\hat{\alpha}_{\rm IVW}}-\E{\alpha_1})^2\\
  \Delta(\hat{\alpha}_{\rm wadj}) 
  &= (\E{\alpha_1})^2 -\var{\hat{\alpha}_{\rm adj}},
\end{align*}
where we estimate $\Delta(\hat{\alpha})$  using the bootstrap and LOOCV techniques developed in Sections \ref{varbootstrap} and \ref{loocv}. 
 
%%%%%%%%%%% Commenting out Section 3.2 %%%%%%%%%%%%
%\subsection{Comparisons among estimators}
%\label{comparisons}

%In comparing  shock effects estimators, we would assume that the risk-reduction conditions are satisfied as in Section \ref{conditions}.  

%Denote the risk-reduction quantities for adjustment estimators as $\Delta_{\rm adj}$, $\Delta_{\rm IVW}$, and $\Delta_{\rm wadj}$, respectively for standard adjustment, inverse-variance weighted estimator, and weighted-adjustment estimato. %%%As long as the risk-reduction of one estimator is greater than those of others, we will vote it as the best estimator among our pool of estimators for consideration. For example, if we find that $\Delta_{\rm wadj}>\Delta_{\rm adj}$ and $\Delta_{\rm wadj}>\Delta_{\rm IVW}$, the weighted-adjustment estimator $\hat{\alpha}_{\rm wadj}$ is the most favorable.
%According to  discussion in Section \ref{conditionsm2122}, we know that under $\mc{M}_{1}$, $\mc{M}_{21}$, and $\mc{M}_{22}$, the risk-reduction quantity for $\hat{\alpha}_{\rm IVW}$ is
%\begin{align*}
%  \Delta_{\rm IVW} = (\E{\alpha_1})^2- \var{\hat{\alpha}_{\rm IVW}} -(\E{\hat{\alpha}_{\rm IVW}}-\E{\alpha_1})^2.
%\end{align*}
%From discussions in Section \ref{conditions}, we know that the risk-reduction quantities for $\hat{\alpha}_{\rm adj}$ and $\hat{\alpha}_{\rm wadj}$ differ across models, we will discuss in different cases accordingly.


%\subsubsection{Under $\mc{M}_{1}$}

%From Proposition \ref{proprisk}, we know that the risk-reduction quantities for $\hat{\alpha}_{\rm adj}$ and $\hat{\alpha}_{\rm wadj}$ are
%\begin{align*}
%  \Delta_{\rm adj} 
%  = \mu_{\alpha}^2 -\var{\hat{\alpha}_{\rm adj}}
%\quad   \text{ and } \quad 
%  \Delta_{\rm wadj} 
%  = \mu_{\alpha}^2-\var{\hat{\alpha}_{\rm wadj}}.
%\end{align*}
%Under the framework of $\mc{M}_1$, the risk-reduction quantity  for $\hat{\alpha}_{\rm IVW}$ is
%\begin{align*}
%  \Delta_{\rm IVW} = \mu_{\alpha}^2- \var{\hat{\alpha}_{\rm IVW}} -(\E{\hat{\alpha}_{\rm IVW}}-\mu_{\alpha})^2.
%\end{align*}
%In other words, when $\var{\hat{\alpha}_{\rm wadj}}<\var{\hat{\alpha}_{\rm adj}}$ and $\hat{\alpha}_{\rm wadj} < \var{\hat{\alpha}_{\rm IVW}} +(\E{\hat{\alpha}_{\rm IVW}}-\mu_{\alpha})^2$, we would prefer $\hat{\alpha}_{\rm wadj}$ as the best estimator. Other conditions for voting the other estimators as the best one follow similarly. 

%\subsubsection{Under $\mc{M}_{21}$ and $\mc{M}_{22}$}
%\label{section322}

%According to Proposition \ref{propriskwadj2} and the discussion in Section \ref{conditionsm2122}, the risk-reduction quantities $\hat{\alpha}_{\rm adj}$ and $\hat{\alpha}_{\rm wadj}$ are
%\begin{align*}
%  \Delta(\hat{\alpha}_{\rm adj})
%  = (\E{\alpha_1})^2 -\var{\hat{\alpha}_{\rm adj}} -(\E{\hat{\alpha}_{\rm adj}}-\E{\alpha_1})^2
%\quad   \text{ and } \quad 
%  \Delta(\hat{\alpha}_{\rm wadj})
%  = (\E{\alpha_1})^2-\var{\hat{\alpha}_{\rm wadj}}.
%\end{align*}
%In this case, the risk-reduction quantity for $\hat{\alpha}_{\rm adj}$ is similar to that of $\hat{\alpha}_{\rm IVW}$ since they are both biased for $\E{\alpha_1}$.  Thus,
%\begin{align*}
% \Delta(\hat{\alpha}_{\rm IVW})
%  = (\E{\alpha_1})^2 -\var{\hat{\alpha}_{\rm IVW}} -(\E{\hat{\alpha}_{\rm IVW}}-\E{\alpha_1})^2
%\end{align*}


 
% These are some analytical results for comparison studies among estimators of $\alpha_1$. Next, we will detail a framework for estimation of risk-reduction  quantities using a parametric bootstrap routine. Therefore, the above inequalities can be analyzed numerically and risk-reduction quantities can be estimated using plug-in estimators in practice.

%\begin{remark}
%  In Section \ref{constructionofestimators}, we noted that $\mathbf{W}^*$ may not be unique if $2p < n$. However, Proposition \ref{proprisk} and \ref{propriskwadj2} will hold for  every $\hat{\alpha}_{\rm wadj}$ using  $\mathbf{W}^*$ that satisfies (\ref{SCM}).
%\end{remark}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\subsection{Bootstrap for risk-reduction evaluation problems}
\label{varbootstrap}


In this section, we present bootstrap procedures that approximate the distribution of our shock effect estimators, checks the underlying conditions of our risk reduction propositions, and estimate risk-reduction quantity using plug-in approach in practice. Our procedure involves the resampling of residuals in the separate OLS fits. This procedure has its origins in Section 6 of \citet{efron1986bootstrap} and Chapter 12 of \cite{kilian2017structural}. Our procedure involves the resampling of the residuals which are assumed to be the realizations of an iid process.

Our first bootstrap procedure is as follows: Let $B$ be the bootstrap sample size. At iteration $b$, first resample the indices $I = \{2, \ldots, n+1\}$ of the donor pool with replacement to form $I^{(b)}$ with cardinality $n$, where we note that the elements of $I^{(b)}$ may not be unique in terms of their  indices in the donor pool. Initialize $y_{i,0}$ for all $i \in I^{(b)}$. Then, resample the residuals under models $\mc{M}_1$, $\mc{M}_{21}$, or $\mc{M}_{22}$ and obtain shock effect estimators for each of the disparate time series for all $i \in I^{(b)}$. These shock effect estimators are then used to construct any of the adjustment estimators $\hat{\alpha}^{(b)}_{\mrm{adj}}$, $\hat{\alpha}^{(b)}_{\mrm{wadj}}$, and $\hat{\alpha}^{(b)}_{\mrm{IVW}}$, for $b = 1,\ldots,B$. We can then estimate distributional quantities of our shock effect estimators under our considered models with the bootstrap samples $\hat{\alpha}^{(b)}_{\mrm{adj}}$, $\hat{\alpha}^{(b)}_{\mrm{wadj}}$, and $\hat{\alpha}^{(b)}_{\mrm{IVW}}$, for $b = 1,\ldots,B$. We denote this procedure by $\mc{B}_u$. We motivate a second bootstrap procedure $\mc{B}_f$ which treats the the donor pool as fixed, and not a realization from an infinite super-population. Therefore, there is no resampling of the donor pool in $\mc{B}_f$, it is otherwise similar to $\mc{B}_u$. An algorithmic formulation of $\mc{B}_u$ and $\mc{B}_f$  are outlined in Section 2 in the Supplementary Materials.

We will explicitly use these bootstrapped samples of shock effect estimators to check the risk-reduction conditions in Propositions \ref{proprisk} and \ref{propriskwadj2}. Recall that  $\hat{\alpha}_{\rm wadj}$ and $\hat{\alpha}_{\rm IVW}$ are unbiased estimators of their expectations, and $\hat{\alpha}_{\rm wadj}$ is an unbiased estimator of $\E{\alpha_1}$ from Proposition \ref{unbiased}. Our bootstrap procedure estimates the variance of our adjustment estimators. We can then estimate the risk-reduction propositions and inequalities. For example, we can estimate $\Delta(\hat{\alpha}_{\rm adj})$ under model $\mc{M}_{21}$ or $\mc{M}_{22}$ with 
\begin{align*}
%  \Delta(\hat{\alpha}_{\rm adj})
  %&= (\E{\alpha_1})^2 -\var{\hat{\alpha}_{\rm adj}} -(\E{\hat{\alpha}_{\rm adj}}-\E{\alpha_1})^2 \\
  \hat{\Delta}(\hat{\alpha}_{\rm adj}) & = (\hat{\alpha}_{\rm wadj})^2 -S^2_{\hat{\alpha}_{\rm adj}} -(\hat{\alpha}_{\rm adj}-\hat{\alpha}_{\rm wadj})^2,
\end{align*}
where $S^2_{\hat{\alpha}_{\rm adj}}$ is the bootstrap sample variance estimator for $\Var(\hat{\alpha}_{\rm adj})$. 

%Suppose we have a pool of shock effect estimators, $\mc{A}$, e.g., $\mc{A}= \{\hat{\alpha}_{\rm adj}, \hat{\alpha}_{\rm wadj}, \hat{\alpha}_{\rm IVW}\}$ in our study. We can determine which one is the best shock effect estimator. Suppose the $\hat{\Delta}(\hat{\alpha}_{\rm wadj})$ and $\hat{\Delta}(\hat{\alpha}_{\rm IVW})$ are estimators for $\Delta(\hat{\alpha}_{\rm wadj}) $ and $\Delta(\hat{\alpha}_{\rm IVW})$, respectively. Then, we can evaluate the risk-reduction propositions by judging whether $\hat{\Delta}(\hat{\alpha})>0$ for $\hat{\alpha}\in \mc{A}$. Besides, we can also select the best shock effect estimator accordingly. Define
%\begin{align}
%	\hat{\alpha}_{\rm best} = \argmax_{\hat{\alpha}\in \mc{A}} \hat{\Delta}(\hat{\alpha}) \quad \text{ and } \quad  \alpha_{\rm best} = \argmax_{\hat{\alpha}\in \mc{A}} \Delta(\hat{\alpha}). \label{best}
%\end{align}
%That is, the best estimator $\hat{\alpha}_{\rm best}$ is the one with the maximum estimated risk-reduction quantities whereas $\alpha_{\rm best}$ is the true best shock effect estimator given observed post-shock response. See more discussions in Section \ref{loocv}.


We stress that the our bootstrap approximations cannot alleviate the inherent bias of using our adjustment estimators as surrogates for $\alpha_1$. We caution that the bootstrapping residuals in OLS estimation may not provide valid inference in moderate or high dimension where $p < T_i$ but $p / T_i$ is not close to zero for $i\in \{2, \ldots, n+1\}$ \citep{el2018can}; see alternatives for residual bootstrapping in linear models in \citet{el2018can}. Recall that $\mathbf{W}^*$  may not be unique if the conditions in Proposition \ref{uniqueness} are not satisfied. Under the setup of our model, non-uniqueness of $\mathbf{W}^*$ would not be a problem for inferential purposes. This is because all risk-reduction propositions and other properties established will still hold. However, non-uniqueness may not be desirable in other model setups. For example, consider the model where $\alpha_i$ is assumed to be not identically distributed, the size of  donor pool to be 2, and there are two solutions to (\ref{SCM}), say, $\mathbf{W}^*_1=(1,0)$ and  $\mathbf{W}^*_2=(0,1)$ with $\var{\alpha_2}\neq \var{\alpha_3}$. In this scenario, the procedure of trying to recover $\alpha_1$ will fail since the resulting $\alpha_1$ will be different with different variances for $\mathbf{W}^*_1=(1,0)$ and  $\mathbf{W}^*_2=(0,1)$. If the non-uniqueness is of concern, users may select the weight that optimizes some objective function. For instance, in the example just discussed, users may select the weight that minimizes the estimated variance of $\hat{\alpha}_{\rm wadj}$.
%There are some issues in using $\mc{B}_u$ when $\mathbf{W}^*$ falls in the boundary of the parameter space. See detailed discussions in Section \ref{discussion}.

\subsection{Leave-one-out cross validation}
\label{loocv}

In this section, we adapt leave-one-out cross validation (LOOCV) to our estimation context in order to provide prospective evaluations of our adjustment techniques. Our proposed LOOCV procedure has its roots in Section 7.10 of \citet{hastie2009elements}.  Recall in Section \ref{modelsetup} that we are given the data $\{(\mbf{x}_{i,t}, y_{i,t}) \colon i = 1, \ldots, n+1, t = 1, \ldots, T_i\}$, where $\{(\mbf{x}_{1,t}, y_{1,t})\colon t = 1, \ldots, T_1\}$ is the data of the time series of interest and the remaining observations form the donor pool. For iteration $m \in \{1,\ldots,n\}$ of our LOOCV procedure, we set aside $\{(\mbf{x}_{m + 1, t}, y_{m + 1, t}) \colon t = 1, \ldots, T_{m+1}\}$ as the time series of interest, and construct a new donor pool $\{(\mbf{x}_{i, t}, y_{i, t}) \colon i \in \mc{I}_m, t = 1, \ldots, T_{i}\}$, where $\mc{I}_m=\{2, \ldots, n+1\} \setminus \{m+1\}$. Since the post-shock response $y_{m+1, T_{m+1}^*+1}$ is observed, we can evaluate the performance of our adjustment estimators and the original forecast made without adjustment (i.e., Forecast 1 in Section \ref{forecast}).

LOOCV can be very computationally intensive when $n$ is large, especially when combined with bootstrapping. To alleviate these concerns we can perform LOOCV with a random subset of $k \leq n$ iterations selected without replacement. In this setting, we let $\mc{J}$ be the randomly sampled indices. For $m \in \mc{J}$, we set aside $\{(\mbf{x}_{m + 1, t}, y_{m + 1, t}) \colon t = 1, \ldots, T_{m+1}\}$ as the time series of interest, and construct a new donor pool $\{(\mbf{x}_{i, t}, y_{i, t}) \colon i \in \mc{I}, t = 1, \ldots, T_{i}\}$, where $\mc{I}=\{2, \ldots, n+1\} \setminus \{m+1\}$. Based on the new donor pool, we estimate relevant parameters using bootstrap procedures outlined in Section \ref{varbootstrap}. In other words, $k$ times of bootstrapping are nested in a LOOCV procedure.  We find that $k=5$ or $k=10$ iterations of LOOCV performs well.

We now outline how LOOCV can be used to prospectively assess the performance of adjustment estimators. Let $\mc{A}$ be the set of adjustment estimators. For each $\hat{\alpha} \in \mc{A}$, let $\delta_{\hat{\alpha}} = I(\hat\Delta(\hat{\alpha})>0)$ be a decision rule where $I(\cdot)$ is the indicator function and a $1$ corresponds to the decision to use adjustment estimator $\hat\alpha$. If $\Delta(\hat{\alpha})>0$ ($\Delta(\hat{\alpha})<0$, respectively) but $\delta_{\hat{\alpha}}$ incorrectly reported 1 (0, respectively) so that it make the decision not to use $\hat{\alpha}$ (to use $\hat{\alpha}$, respectively), $\delta_{\hat{\alpha}}$ is said to be incorrect. If $\Delta(\hat{\alpha})<0$ ($\Delta(\hat{\alpha})>0$, respectively) and  $\delta_{\hat{\alpha}}$ correctly reported 0 (1, respectively) so that it make the decision to use $\hat{\alpha}$, $\delta_{\hat{\alpha}}$ is said to be correct. These situations are depicted in the following table: \vspace*{0.3cm}

\begin{center}
  \begin{center}
      \begin{tabular}{cc|c|c}
        \hline
        & & \multicolumn{2}{c}{Decision} \\
        & & $\delta_{\hat{\alpha}} = 1$ & $\delta_{\hat{\alpha}} = 0$ \\ 
                \hline
     \multirow{2}{*}{Truth}  & $\Delta(\hat{\alpha})>0$ & Correct & Incorrect \\
      \cline{3-4}
      & $\Delta(\hat{\alpha})<0$  & Incorrect & Correct \\
      \hline
      \end{tabular}
  \end{center}
\end{center}
%Similar definitions can be adapted to the best shock effect estimators. 
\vspace*{0.3cm}


We will use 
$
	\mc{C}(\delta_{\hat\alpha}) 
	= I(\delta_{\hat{\alpha}} \text{ is correct})
 %\quad \text{ and } \quad  	
 %\mc{C}(\mc{A}) 
%	= I(\hat{\alpha}_{\rm best} = \alpha_{\rm best})
$
as a metric that evaluates the performance of forecasts made with the adjustment estimator $\hat\alpha$. If $\E{\mc{C}(\delta_{\hat{\alpha}})} > 0.5$, we claim that $\delta_{\hat{\alpha}}$ is better than random guessing. Note that $\mc{C}(\delta_{\hat{\alpha}})$ can generally be computed only when the post-shock response is observed. However, it is possible to estimate $\E{\mc{C}(\delta_{\hat{\alpha}})}$ using LOOCV. %For each $\hat{\alpha}\in \mc{A}$ we can compute the consistency as $\mc{C}^{(-m)}(\delta_{\hat{\alpha}})$ using the estimation procedures in Section \ref{varbootstrap}.
The LOOCV estimates for $\E{\mc{C}(\delta_{\hat{\alpha}})}$ are
\begin{equation} \label{loocvm}
	 \bar{\mc{C}}(\delta_{\hat{\alpha}})= \frac{1}{n} \sum_{m = 1}^n \mc{C}^{(-m)}(\delta_{\hat{\alpha}}),
	\end{equation}
where $\mc{C}^{(-m)}(\delta_{\hat{\alpha}})$ is computed with respect to donor pool with index set $\mc{I}_m$ and the $m+1$ time series is treated as the time series of interest.  The LOOCV with $k$ random draws estimates $\E{\mc{C}(\delta_{\hat{\alpha}})}$ as
\begin{equation} \label{loocvk}
	 \bar{\mc{C}}^{(k)}(\delta_{\hat{\alpha}})= \frac{1}{k} \sum_{m \in \mc{J}} \mc{C} ^{(-m)}(\delta_{\hat{\alpha}})	,
\end{equation}
where $\mc{J}$ is the set of the $k$ randomly sampled indicies. %Similarly, assuming the candidates in the donor pool are  mutually independent and the data  satisfy $\mc{M}_{2}$, $\bar{\mc{C}}^{(k)}(\delta_{\hat{\alpha}})$ and $\bar{\mc{C}}^{(k)}(\mc{A})$ should be almost unbiased estimates of $\E{\mc{C}(\delta_{\hat{\alpha}})}$ and $\E{\mc{C}(\mc{A})}$, respectively. The estimation bias should decrease as $k \to n$.

\begin{remark}
  Note that we allow the time series within the donor pool to be dependent but donor pool should be independent of the time series of interest. However, if we assume the mutual  independence structure, $\bar{\mc{C}}(\delta_{\hat{\alpha}})$ will be an almost unbiased estimator of $\E{\mc{C}(\delta_{\hat{\alpha}})}$ \citep[Page 222]{msos}. In other words, mutual independence assumption is not related to  $\E{\mc{C}(\delta_{\hat{\alpha}})}$ (i.e., the intrinsic correctness) but its estimation. 
\end{remark}



\section{Numerical Examples}
\label{simulation}

\subsection{Modeling setup}

In this section we provide justification for our methods based on Monte Carlo simulation. We implemented our simulation based on $\mc{M}_{22}$ with negligibly small $\Sigma_{\gamma}$ and $\Sigma_{\delta}$ approximating the design of $\mathcal{M}_{21}$.  We consider $p=13$ and $\mu_{\alpha}=2$, where $p = 13$ is set to satisfy conditions in Proposition \ref{uniqueness}. Parameter setup of our simulations is detailed as follows: the $\phi_i$'s are sampled independently from $\mrm{Uniform}(0,1)$. We sampled $T_i$'s independently from  $\text{Gamma}(15, 10)$ that are further rounded to integers, where the minimum allowable value of $T_i$ is fixed to be 90. We will randomly draw $T_i^*$ from $\{2p + 4, \ldots, T_i-1\}$. The choices of $T_i$ and $T_i^*$ are set up to satisfy a necessary condition for the design matrix of OLS estimation to have full rank. Moreover, it is  designed to illustrate the performance of $\hat{\alpha}_{\rm IVW}$ that may perform well in time series with varying lengths. Additionally, we generated the covariates from $\text{Gamma}(1,2)$ to set up a setting when the $\hat{\alpha}_{\rm wadj}$ may perform well. Last, we set $\gamma_i, \delta_i\simiid  \normal{1}{0.5}$ and $\theta_i, \beta_i \sim \normal{0}{1}$. We will consider parameter setup by varying $\sigma$ in the model of $y_{i,t}$, $n$, the donor pool size, and $\sigma_{\alpha}$ in the model of $\alpha_i$. We choose a Monte Carlo sample size of $30$ replications and a bootstrap sample size of $B = 200$ for computation. Means and standard errors for estimated quantities will be recorded. Our LOOCV procedure will consider $k=5$ random draws. Recall in Section \ref{loocv} that $k$ times of bootstrap are nested in a LOOCV with $k$ random draws. It implies that $B(k+1)$ times of bootstrap replications are required for each Monte Carlo simulation.


\subsection{Performance metrics}

Our adjustment estimators will be evaluated by multiple criteria. We interpret $\delta_{\hat{\alpha}}= I(\hat{\Delta}(\hat{\alpha})>0)$ for $\hat{\alpha}\in \mc{A}$ as the \emph{guess}, with 1 indicating that $\hat{\alpha}$ provides risk-reduction over the simple no-adjustment forecast, and 0 indicates the converse. We will consider the LOOCV estimators \eqref{loocvm} and \eqref{loocvk} to assess correct decision making. We will also consider the Euclidean distance between the post-shock forecasts $\hat{y}_{1,T_1^*+1}$, $\hat{y}_{1,T_1^*+1}+ \hat{\alpha}_{\rm adj}$, $\hat{y}_{1,T_1^*+1}+\hat{\alpha}_{\rm wadj}$, and $\hat{y}_{1,T_1^*+1}+\hat{\alpha}_{\rm IVW}$ and the realized post-shock response $y_{1,T_1^*+1}$. The first two metrics can combine to assess our forecasting methodology prospectively while the latter requires the realization of the post-shock response $y_{1,T_1^*+1}$. 



\subsection{Monte Carlo results}
\label{parametricbootstrapsimulation}

In this section, we discuss simulation results for the bootstrap procedures used in estimating parameters for risk-reduction propositions and inequalities. We mainly discuss simulations under $\mc{M}_2$ (see Section \ref{modelsetup}) for $\mc{B}_u$ and $\mc{B}_f$ (see Section \ref{varbootstrap}) with comparisons to those under $\mc{M}_1$ whose results are listed in Section 3 in the Supplementary Materials. Two simulation setups are investigated. 

In the first simulation setup, we consider the parameter combination of  $n \in \{5, 10, 15, 25\}$ and $\sigma_{\alpha} \in  \{5, 10, 25, 50, 100\}$ where we fix $\sigma=10$. Note that $\E{\E{\alpha_1}}=54$, where the last expectation is operated under the density of the covariates. In other words, data with $\sigma_{\alpha} \in  \{5, 10, 25, 50, 100\}$  should well represent the situations when the signal of the covariates is strong and when it is nearly lost. Results are displayed in Table~\ref{table1}.


In the second simulation setup, we consider the parameter combination of $\sigma, \sigma_{\alpha} \in  \{5, 10, 25, 50, 100\}$ where we fix $n=10$. Likewise, $\sigma, \sigma_{\alpha} \in  \{5, 10, 25, 50, 100\}$ will produce situations when the signal of the covariates is strong and when it is nearly lost in the model of  both $y_{i,t}$ and $\alpha_i$. Results are displayed in Table~\ref{table2}.



\begin{table}[h]\caption{30 Monte Carlo simulations of $\mc{M}_2$ for $\mc{B}_u$ with varying $n$ and $\sigma_{\alpha}$} \vspace{.3cm} \label{table1}
\begin{center}\resizebox{\textwidth-1.2cm}{!}{\begin{tabular}{cc|ccc|ccc|cccc|}
   &   & \multicolumn{3}{|c|}{Guess} & \multicolumn{3}{|c|}{LOOCV with $k$ random draws} &  \multicolumn{4}{|c|}{Distance to $y_{1, T_1^*+1}$} \\  $n$   & $\sigma_{\alpha}$ &  $\delta_{\hat{\alpha}_{\rm adj}}$  & $\delta_{\hat{\alpha}_{\rm wadj}}$ & $\delta_{\hat{\alpha}_{\rm IVW}}$  & $\bar{\mc{C}}^{(k)}(\delta_{\hat{\alpha}_{\rm adj}})$  & $\bar{\mc{C}}^{(k)}(\delta_{\hat{\alpha}_{\rm wadj}})$ & $\bar{\mc{C}}^{(k)}(\delta_{\hat{\alpha}_{\rm IVW}})$ & Original & $\hat{\alpha}_{\rm adj}$ & $\hat{\alpha}_{\rm wadj}$ & $\hat{\alpha}_{\rm IVW}$\\[.15cm]   \hline \multirow{5}{*}{5}  & 5  & 1 (0) & 1 (0) & 1 (0) & 0.92 (0.02) & 0.96 (0.01) & 0.92 (0.02) & 65.47 (4.77) & 19.92 (3.57) & 21.86 (3.99) & 20.27 (3.62) \\     & 10  & 1 (0) & 1 (0) & 1 (0) & 0.9 (0.02) & 0.92 (0.02) & 0.9 (0.02) & 65.67 (4.9) & 20.66 (3.74) & 22.92 (4.2) & 21.1 (3.75) \\     & 25  & 0.97 (0.03) & 1 (0) & 0.97 (0.03) & 0.8 (0.02) & 0.81 (0.02) & 0.8 (0.03) & 66.29 (5.83) & 27.98 (4.21) & 30.3 (4.87) & 28.3 (4.18) \\     & 50  & 0.83 (0.07) & 0.87 (0.06) & 0.87 (0.06) & 0.55 (0.05) & 0.57 (0.04) & 0.55 (0.05) & 70.59 (7.46) & 43.1 (6.19) & 46.31 (6.8) & 43.07 (6.16) \\     & 100  & 0.47 (0.09) & 0.73 (0.08) & 0.47 (0.09) & 0.48 (0.04) & 0.48 (0.04) & 0.46 (0.04) & 89.82 (10.49) & 76.74 (11.42) & 79.78 (12.26) & 76.69 (11.33) \\[.3cm]     \multirow{5}{*}{10}  & 5  & 1 (0) & 1 (0) & 1 (0) & 0.95 (0.02) & 0.95 (0.02) & 0.95 (0.02) & 55.66 (4.28) & 16.36 (2.48) & 17.51 (2.41) & 16.6 (2.45) \\     & 10  & 1 (0) & 1 (0) & 1 (0) & 0.92 (0.02) & 0.91 (0.03) & 0.92 (0.02) & 55.91 (4.71) & 18.28 (2.85) & 19.38 (2.88) & 18.44 (2.83) \\     & 25  & 0.9 (0.06) & 0.97 (0.03) & 0.93 (0.05) & 0.77 (0.04) & 0.79 (0.04) & 0.75 (0.04) & 59.43 (6.1) & 29.01 (4.24) & 32.1 (4.3) & 28.84 (4.26) \\     & 50  & 0.77 (0.08) & 0.8 (0.07) & 0.77 (0.08) & 0.55 (0.04) & 0.64 (0.04) & 0.55 (0.04) & 69.34 (9.45) & 52.52 (6.75) & 58.05 (7.28) & 52.28 (6.76) \\     & 100  & 0.63 (0.09) & 0.7 (0.09) & 0.63 (0.09) & 0.53 (0.04) & 0.53 (0.05) & 0.51 (0.04) & 104.19 (15.88) & 99.93 (12.83) & 113.77 (13.42) & 99.57 (12.81) \\[.3cm]     \multirow{5}{*}{15}  & 5  & 1 (0) & 1 (0) & 1 (0) & 0.92 (0.02) & 0.93 (0.02) & 0.92 (0.02) & 51.78 (2.74) & 12.66 (2.48) & 13.89 (2.48) & 12.64 (2.49) \\     & 10  & 1 (0) & 1 (0) & 1 (0) & 0.92 (0.02) & 0.91 (0.02) & 0.92 (0.02) & 51.82 (3.04) & 13.93 (2.52) & 16 (2.63) & 14.05 (2.53) \\     & 25  & 1 (0) & 1 (0) & 1 (0) & 0.83 (0.03) & 0.83 (0.03) & 0.83 (0.03) & 51.94 (4.56) & 21.27 (2.93) & 24.49 (3.69) & 21.75 (2.92) \\     & 50  & 0.9 (0.06) & 0.93 (0.05) & 0.9 (0.06) & 0.71 (0.03) & 0.67 (0.04) & 0.69 (0.04) & 55.22 (7.06) & 35.85 (4.63) & 42.72 (5.93) & 36.41 (4.71) \\     & 100  & 0.7 (0.09) & 0.73 (0.08) & 0.7 (0.09) & 0.54 (0.05) & 0.61 (0.04) & 0.54 (0.05) & 76.44 (10.75) & 67.79 (8.77) & 79.49 (11.44) & 68.57 (8.96) \\[.3cm]     \multirow{5}{*}{25}  & 5  & 1 (0) & 1 (0) & 1 (0) & 0.9 (0.03) & 0.91 (0.02) & 0.9 (0.03) & 62.23 (6.88) & 21.29 (5.9) & 19.29 (5.88) & 21.34 (5.93) \\     & 10  & 1 (0) & 1 (0) & 1 (0) & 0.87 (0.03) & 0.89 (0.02) & 0.87 (0.03) & 61.28 (7.09) & 22.96 (5.91) & 20.81 (5.89) & 23.02 (5.94) \\     & 25  & 1 (0) & 1 (0) & 1 (0) & 0.73 (0.03) & 0.74 (0.04) & 0.73 (0.03) & 61.9 (7.5) & 30.04 (6.46) & 28.76 (6.46) & 30.17 (6.48) \\     & 50  & 0.83 (0.07) & 0.87 (0.06) & 0.83 (0.07) & 0.55 (0.05) & 0.56 (0.05) & 0.55 (0.05) & 67.46 (9.23) & 45.5 (8.55) & 47.38 (8.62) & 45.67 (8.58) \\     & 100  & 0.77 (0.08) & 0.73 (0.08) & 0.77 (0.08) & 0.48 (0.05) & 0.49 (0.04) & 0.49 (0.05) & 91.08 (14.54) & 81.72 (14.24) & 85.72 (15.39) & 82.3 (14.24) \\ \end{tabular}}
   \end{center}
      \vspace{-.5cm}
\end{table}

First, assuming that $\bar{C}^{(k)}(\delta_{\hat{\alpha}})$ well estimates $\E{\mc{C}(\delta_{\hat{\alpha}}})$ and fixing $n$, we  observe from Table \ref{table1} that the decision making of $\delta_{\hat{\alpha}}$ is nearly correct  for $\hat{\alpha}\in \mc{A}$ when $\sigma_{\alpha}$ is small  from Table \ref{table1}. The reasons can be explained as follows. When $\sigma_{\alpha}$ is small, the signal of the covariates is strong so that $\hat{\alpha}_{\rm wadj}$ will be expected to capture the signal according to construction of $\hat{\alpha}_{\rm wadj}$ in Section \ref{constructionofestimators}. Moreover, when $\sigma_{\alpha}$ is small, $\mc{M}_{22}$ approximates $\mc{M}_{21}$ such that estimation of $\E{\alpha_1}$ should be nearly unbiased according to Proposition \ref{unbiased}. However, when the signal of the covariates is poor ($\sigma_{\alpha}$ is big), the decision rule $\delta_{\hat{\alpha}}$  becomes unreliable for $\hat{\alpha}\in \mc{A}$. It is to be expected since the bootstrap estimates become more biased. However, users can be warned by $\bar{C}^{(k)}(\delta_{\hat{\alpha}})$ to have an idea of the effectiveness of $\delta_{\hat{\alpha}}$. Second, fixing $\sigma_{\alpha}$, we can observe that the correctness of $\delta_{\hat{\alpha}}$ increases when $n$ increases. It is due to the robustness gain in estimation when $n$ increases.  


Additionally, we  observe that in most cases $\delta_{\hat{\alpha}_{\rm wadj}}$ reports $\hat{\alpha}_{\rm wadj}$ reduces the risk even when $\bar{\mc{C}}^{(k)}(\delta_{\hat{\alpha}_{\rm wadj}})$ starts to break down.  Recall from Section \ref{varbootstrap} that $\hat{\Delta}(\hat{\alpha})$ contains the squared bias for estimating $\E{\alpha_1}$. But it is not present for $\hat{\Delta}(\hat{\alpha}_{\rm wadj})$ since we applied the fact  $\hat{\alpha}_{\rm wadj}$ is unbiased for $\E{\alpha_1}$ from Proposition \ref{unbiased} in plugging it in with replacing $\E{\alpha_1}$. Therefore, when the signal from covariates is poorer, $\delta_{\hat{\alpha}_{\rm wadj}}$ becomes less conservative. Besides, the averaged $I\big(\hat{\Delta}(\hat{\alpha})>0\big)$ times $\bar{\mc{C}}^{(k)}(\delta_{\hat{\alpha}})$ can provide an approximation for the probability that $\hat{\alpha}$ actually reduces the risk assuming an symmetry of correctness between the cases when $\hat{\Delta}(\hat{\alpha})>0$ and when $\hat{\Delta}(\hat{\alpha})<0$. For example, when $n = 5$ and $\sigma_{\alpha}=50$, the probability that $\hat{\alpha}_{\rm adj}$ reduces the risk is approximately $0.83 \times 0.55 = 0.457$ from Table \ref{table1}.  In other words,  the probability that $\hat{\alpha}$ reduces the risk has the same pattern as $\bar{\mc{C}}^{(k)}(\delta_{\hat{\alpha}})$ has with $n$ and $\sigma_{\alpha}$ for $\hat{\alpha}\in \mc{A}$.

From columns related to distance to $y_{1, T_1^*+1}$ in Table \ref{table1}, as $\sigma_{\alpha}$ increases, the prediction appears to be poorer. When $\sigma_{\alpha}= 5, 10, 25$, forecasts using $\hat{\alpha}_{\rm adj}$, $\hat{\alpha}_{\rm wadj}$, and $\hat{\alpha}_{\rm IVW}$ are always better than the original forecast significantly. But it does not hold generally for the case when $\sigma_{\alpha}=50, 100$. It is reasonable in that when the $\sigma_{\alpha}$ is large, it is difficult to find a reliable estimate of $\alpha_1$.  Nevertheless, no statistical evidence has been found to support the claim that $n$ matters in prediction. In other words, the size of the donor pool matters for producing reliable decision-making of $\delta_{\hat{\alpha}}$ rather than reliable prediction. 


\begin{table}[H]\caption{30 Monte Carlo simulations of $\mc{M}_2$ for $\mc{B}_u$ with varying $\sigma$ and $\sigma_{\alpha}$} \vspace{.3cm} \label{table2}
\begin{center}\resizebox{\textwidth-1.2cm}{!}{\begin{tabular}{cc|ccc|ccc|cccc|}
   &   & \multicolumn{3}{|c|}{Guess} & \multicolumn{3}{|c|}{LOOCV with $k$ random draws} &  \multicolumn{4}{|c|}{Distance to $y_{1, T_1^*+1}$} \\  $\sigma$   & $\sigma_{\alpha}$ &  $\delta_{\hat{\alpha}_{\rm adj}}$  & $\delta_{\hat{\alpha}_{\rm wadj}}$ & $\delta_{\hat{\alpha}_{\rm IVW}}$  & $\bar{\mc{C}}^{(k)}(\delta_{\hat{\alpha}_{\rm adj}})$  & $\bar{\mc{C}}^{(k)}(\delta_{\hat{\alpha}_{\rm wadj}})$ & $\bar{\mc{C}}^{(k)}(\delta_{\hat{\alpha}_{\rm IVW}})$ & Original & $\hat{\alpha}_{\rm adj}$ & $\hat{\alpha}_{\rm wadj}$ & $\hat{\alpha}_{\rm IVW}$\\[.15cm]   \hline \multirow{5}{*}{5} & 5  & 1 (0) & 1 (0) & 1 (0) & 0.97 (0.01) & 0.97 (0.01) & 0.97 (0.01) & 49.95 (2.46) & 12.36 (1.71) & 11.71 (1.55) & 12.13 (1.71) \\ 
  & 10  & 1 (0) & 1 (0) & 1 (0) & 0.92 (0.02) & 0.92 (0.02) & 0.92 (0.02) & 51.25 (2.88) & 13.14 (1.88) & 14.55 (1.7) & 12.84 (1.87) \\ 
  & 25  & 0.97 (0.03) & 1 (0) & 1 (0) & 0.81 (0.03) & 0.84 (0.03) & 0.81 (0.03) & 54.85 (4.6) & 19.32 (3.07) & 20.87 (3.45) & 19.75 (3.13) \\ 
  & 50  & 0.77 (0.08) & 0.8 (0.07) & 0.77 (0.08) & 0.59 (0.04) & 0.62 (0.03) & 0.58 (0.04) & 60.57 (8.15) & 43.17 (5.49) & 47.62 (5.88) & 43.59 (5.63) \\ 
  & 100  & 0.67 (0.09) & 0.63 (0.09) & 0.67 (0.09) & 0.45 (0.04) & 0.49 (0.04) & 0.49 (0.04) & 71.15 (10.52) & 72.15 (9.61) & 80.17 (9.52) & 71.7 (9.57) \\[.3cm] 
 \multirow{5}{*}{10} & 5  & 0.97 (0.03) & 1 (0) & 0.97 (0.03) & 0.91 (0.02) & 0.91 (0.02) & 0.91 (0.02) & 48.65 (3.85) & 18.3 (2.4) & 19.78 (2.31) & 18.64 (2.39) \\ 
  & 10  & 1 (0) & 1 (0) & 1 (0) & 0.9 (0.02) & 0.93 (0.02) & 0.91 (0.02) & 52.46 (4.4) & 16.52 (3.06) & 15.86 (3.18) & 16.46 (3.06) \\ 
  & 25  & 1 (0) & 1 (0) & 1 (0) & 0.79 (0.04) & 0.81 (0.03) & 0.8 (0.04) & 64.81 (4.93) & 24.85 (3.5) & 24.78 (3.7) & 24.94 (3.58) \\ 
  & 50  & 0.87 (0.06) & 0.9 (0.06) & 0.87 (0.06) & 0.57 (0.04) & 0.61 (0.04) & 0.57 (0.04) & 65.69 (6.74) & 40.16 (5.47) & 37.29 (5.35) & 39.44 (5.49) \\ 
  & 100  & 0.63 (0.09) & 0.67 (0.09) & 0.63 (0.09) & 0.43 (0.04) & 0.47 (0.03) & 0.43 (0.04) & 67.98 (10.7) & 65.69 (8.35) & 78.45 (9.42) & 67.75 (8.58) \\[.3cm] 
 \multirow{5}{*}{25} & 5  & 1 (0) & 1 (0) & 1 (0) & 0.73 (0.03) & 0.74 (0.03) & 0.73 (0.03) & 58.32 (7.69) & 39.37 (7.46) & 39.16 (7.89) & 39.6 (7.47) \\ 
  & 10  & 1 (0) & 1 (0) & 1 (0) & 0.71 (0.04) & 0.73 (0.05) & 0.73 (0.04) & 65.93 (5.72) & 33.34 (5.91) & 34.04 (5.49) & 33.05 (5.89) \\ 
 & 25  & 0.9 (0.06) & 0.97 (0.03) & 0.93 (0.05) & 0.67 (0.04) & 0.68 (0.03) & 0.66 (0.04) & 56.05 (7.5) & 39.49 (5.25) & 35.65 (4.98) & 39.73 (5.26) \\ 
  & 50  & 0.77 (0.08) & 0.8 (0.07) & 0.77 (0.08) & 0.59 (0.04) & 0.62 (0.04) & 0.59 (0.04) & 60.85 (7.93) & 46.55 (6.83) & 47.97 (7.4) & 47.23 (6.73) \\ 
  & 100  & 0.67 (0.09) & 0.7 (0.09) & 0.63 (0.09) & 0.53 (0.05) & 0.53 (0.04) & 0.53 (0.05) & 95.21 (12.76) & 98.68 (11.57) & 99.87 (13.28) & 98.77 (11.61) \\[.3cm] 
   \multirow{5}{*}{50} & 5  & 0.77 (0.08) & 0.7 (0.09) & 0.77 (0.08) & 0.6 (0.04) & 0.61 (0.03) & 0.61 (0.04) & 71.05 (8.49) & 52.9 (8.7) & 57.45 (9.57) & 53.05 (8.59) \\ 
    & 10  & 0.63 (0.09) & 0.63 (0.09) & 0.63 (0.09) & 0.57 (0.04) & 0.57 (0.05) & 0.57 (0.04) & 68.23 (7.38) & 44.22 (5.95) & 55.53 (6.2) & 44.63 (5.86) \\ 
  & 25  & 0.73 (0.08) & 0.67 (0.09) & 0.77 (0.08) & 0.55 (0.04) & 0.55 (0.04) & 0.57 (0.04) & 69.78 (10.51) & 63.97 (9.49) & 68.82 (9.79) & 64.33 (9.47) \\ 
  & 50  & 0.83 (0.07) & 0.8 (0.07) & 0.83 (0.07) & 0.55 (0.04) & 0.51 (0.05) & 0.55 (0.04) & 64.9 (11.37) & 66.61 (10.07) & 73.22 (10.92) & 67.06 (9.99) \\ 
  & 100  & 0.47 (0.09) & 0.53 (0.09) & 0.47 (0.09) & 0.49 (0.04) & 0.51 (0.04) & 0.49 (0.04) & 92.78 (12) & 73.61 (11.81) & 78.33 (10.92) & 74.37 (11.63) \\[.3cm] 
 \multirow{5}{*}{100} & 5  & 0.5 (0.09) & 0.47 (0.09) & 0.47 (0.09) & 0.49 (0.05) & 0.48 (0.04) & 0.47 (0.05) & 125.13 (15.27) & 104.01 (14.95) & 100.33 (13.71) & 105.4 (14.95) \\ 
    & 10  & 0.4 (0.09) & 0.4 (0.09) & 0.37 (0.09) & 0.49 (0.03) & 0.51 (0.05) & 0.51 (0.04) & 106.46 (14.76) & 101.82 (14.64) & 110.6 (14.95) & 98.85 (14.69) \\ 
  & 25  & 0.63 (0.09) & 0.57 (0.09) & 0.63 (0.09) & 0.49 (0.04) & 0.48 (0.04) & 0.51 (0.04) & 142.91 (16.43) & 132.29 (18.34) & 146.26 (17.96) & 132.06 (18.25) \\ 
  & 50  & 0.57 (0.09) & 0.57 (0.09) & 0.57 (0.09) & 0.5 (0.05) & 0.5 (0.05) & 0.49 (0.04) & 114.36 (15.46) & 93 (16.26) & 95.41 (15.89) & 91.92 (15.98) \\ 
    & 100  & 0.33 (0.09) & 0.3 (0.09) & 0.3 (0.09) & 0.49 (0.05) & 0.49 (0.05) & 0.48 (0.05) & 150.5 (20.71) & 148.07 (17.57) & 151.26 (17.18) & 148.96 (17.71) \\ \end{tabular}}
   \end{center}
      \vspace{-.5cm}
\end{table}




From Table \ref{table2}, we observe that as $\sigma_{\alpha}$ increases fixing $\sigma$, $\bar{\mc{C}}(\delta_{\hat{\alpha}})$   decreases, which is a pattern similar to the one shown in the first experiment. Furthermore, as $\sigma$ increases fixing $\sigma_{\alpha}$, $\bar{\mc{C}}(\delta_{\hat{\alpha}})$ decreases as well. Note that the correctness  hinges on the estimation of the parameters. Since $\hat{\alpha}_{\rm wadj}$  is a linear combination of OLS estimates, as $\sigma$ increases, $\var{\hat{\alpha}_{\rm wadj}}$ increases as well. Therefore, $\hat{\alpha}_{\rm wadj}$ become more volatile and its estimation of $\E{\alpha_1}$ can be less reliable. Those reasons can explain  why an increase of $\sigma_{\alpha}$ contributes to a decrease of  $\bar{\mc{C}}(\delta_{\hat{\alpha}})$.  We observe similar patterns for distance to $y_{1, T_1^*+1}$ as well. When $\sigma$ increases with fixing $\sigma_{\alpha}$, it is likely that the degree of variation of $y_{1,t}$ exceeds the extent of adjustment improvement $\hat{\alpha}$ can contribute to for $\hat{\alpha}\in \mc{A}$.




With respect to averaged $I(\hat{\Delta}(\hat{\alpha})>0)$ (i.e., the guess), it starts to decrease as $\sigma$ increases. This is reasonable if we believe the bootstrap estimate $S^2_{\hat{\alpha}}$ provides a good approximation for $\var{\hat{\alpha}}$ for $\hat{\alpha}\in \mc{A}$. The reasons can be outlined as below. Recall in Section \ref{conditionsm2122}, the conditions of risk-reduction propositions involve $(\E{\alpha_1})^2 > \var{\hat{\alpha}} + (\E{\hat{\alpha}}-\E{\alpha_1})^2$ for $\hat{\alpha}\in \mc{A}$, where we note that those parameters are \emph{true} ones but not estimated ones. Notice that $\var{\hat{\alpha}}$ is  an increasing function of $\sigma$ since $\hat{\alpha}$ is estimated by OLS. Therefore, it explains the reason why the increase of $\sigma$ would result in a decrease of averaged $I(\hat{\Delta}(\hat{\alpha})>0)$ since the inequality is not likely to hold when  $\var{\hat{\alpha}}$ increases.



\begin{table}[H]\caption{30 Monte Carlo simulations of $\mc{M}_2$ for $\mc{B}_f$ with varying $n$ and $\sigma_{\alpha}$} \vspace{.3cm} \label{table3}
\begin{center}\resizebox{\textwidth-1.2cm}{!}{\begin{tabular}{cc|ccc|ccc|cccc|}
   &   & \multicolumn{3}{|c|}{Guess} & \multicolumn{3}{|c|}{LOOCV with $k$ random draws} &  \multicolumn{4}{|c|}{Distance to $y_{1, T_1^*+1}$} \\  $n$   & $\sigma_{\alpha}$ &  $\delta_{\hat{\alpha}_{\rm adj}} $  & $\delta_{\hat{\alpha}_{\rm wadj}}$ & $\delta_{\hat{\alpha}_{\rm IVW}}$  & $\bar{\mc{C}}^{(k)}(\delta_{\hat{\alpha}_{\rm adj}})$  & $\bar{\mc{C}}^{(k)}(\delta_{\hat{\alpha}_{\rm wadj}})$ & $\bar{\mc{C}}^{(k)}(\delta_{\hat{\alpha}_{\rm IVW}})$ & Original & $\hat{\alpha}_{\rm adj}$ & $\hat{\alpha}_{\rm wadj}$ & $\hat{\alpha}_{\rm IVW}$\\[.15cm]   \hline  \multirow{5}{*}{5} & 5  & 1 (0) & 1 (0) & 1 (0) & 0.89 (0.02) & 0.9 (0.02) & 0.89 (0.02) & 51.92 (4.04) & 19.23 (2.55) & 20.64 (2.76) & 19.36 (2.52) \\   & 10  & 1 (0) & 1 (0) & 1 (0) & 0.89 (0.02) & 0.89 (0.02) & 0.89 (0.02) & 52.58 (4.35) & 21.57 (2.58) & 23.38 (2.86) & 21.72 (2.5) \\   & 25  & 1 (0) & 1 (0) & 1 (0) & 0.78 (0.03) & 0.83 (0.02) & 0.79 (0.03) & 55.01 (5.84) & 30.3 (3.59) & 31.98 (4.36) & 30.2 (3.5) \\   & 50  & 0.9 (0.06) & 0.97 (0.03) & 0.93 (0.05) & 0.66 (0.04) & 0.65 (0.04) & 0.65 (0.04) & 64.42 (8.11) & 50 (5.78) & 52.56 (6.92) & 49.55 (5.7) \\   & 100  & 0.77 (0.08) & 0.97 (0.03) & 0.8 (0.07) & 0.57 (0.04) & 0.53 (0.04) & 0.57 (0.04) & 91.51 (13.2) & 94.26 (10.41) & 97.26 (12.57) & 93.61 (10.27) \\[.3cm]   \multirow{5}{*}{10} & 5  & 1 (0) & 1 (0) & 1 (0) & 0.91 (0.02) & 0.92 (0.02) & 0.91 (0.02) & 52.34 (4) & 17.23 (2.96) & 18.54 (2.83) & 17.39 (2.95) \\   & 10  & 1 (0) & 1 (0) & 1 (0) & 0.89 (0.02) & 0.89 (0.02) & 0.89 (0.02) & 52.59 (4.04) & 19.02 (3.24) & 20.95 (3.13) & 19.23 (3.24) \\   & 25  & 1 (0) & 1 (0) & 1 (0) & 0.75 (0.03) & 0.78 (0.03) & 0.77 (0.03) & 54.07 (4.97) & 27.66 (4.55) & 31.79 (4.47) & 27.84 (4.61) \\   & 50  & 0.83 (0.07) & 1 (0) & 0.8 (0.07) & 0.59 (0.04) & 0.63 (0.04) & 0.59 (0.04) & 60.32 (7.53) & 47.7 (7.04) & 52.97 (7.54) & 47.78 (7.17) \\   & 100  & 0.8 (0.07) & 0.93 (0.05) & 0.8 (0.07) & 0.47 (0.04) & 0.51 (0.04) & 0.46 (0.04) & 85.6 (12.99) & 89.85 (12.82) & 100.74 (13.61) & 90.4 (12.91) \\[.3cm]   \multirow{5}{*}{15} & 5  & 1 (0) & 1 (0) & 1 (0) & 0.91 (0.02) & 0.93 (0.02) & 0.91 (0.02) & 49.85 (4.01) & 18.07 (2.88) & 18.38 (2.71) & 18.04 (2.88) \\   & 10  & 1 (0) & 1 (0) & 1 (0) & 0.87 (0.02) & 0.89 (0.02) & 0.87 (0.02) & 48.73 (4.3) & 19.45 (2.97) & 19.35 (2.86) & 19.32 (2.99) \\   & 25  & 1 (0) & 1 (0) & 1 (0) & 0.75 (0.03) & 0.78 (0.03) & 0.76 (0.03) & 47.06 (5.13) & 26.16 (3.31) & 26.81 (3.13) & 26.23 (3.33) \\   & 50  & 0.93 (0.05) & 1 (0) & 0.9 (0.06) & 0.61 (0.04) & 0.69 (0.03) & 0.64 (0.04) & 48.75 (6.86) & 40.27 (4.43) & 42.09 (4.49) & 40.77 (4.38) \\   & 100  & 0.67 (0.09) & 1 (0) & 0.63 (0.09) & 0.55 (0.04) & 0.51 (0.04) & 0.55 (0.04) & 64.29 (11.11) & 68.85 (8.27) & 74.08 (8.72) & 69.91 (8.14) \\[.3cm]   \multirow{5}{*}{25} & 5  & 1 (0) & 1 (0) & 1 (0) & 0.95 (0.02) & 0.94 (0.02) & 0.95 (0.02) & 57.6 (6.94) & 21.58 (5.9) & 20 (5.86) & 21.58 (5.9) \\   & 10  & 1 (0) & 1 (0) & 1 (0) & 0.93 (0.02) & 0.91 (0.02) & 0.93 (0.02) & 56.8 (7.01) & 22.2 (5.97) & 20.47 (5.89) & 22.22 (5.97) \\   & 25  & 1 (0) & 1 (0) & 1 (0) & 0.78 (0.04) & 0.79 (0.04) & 0.77 (0.04) & 56.58 (7.49) & 28.96 (6.49) & 27.06 (6.19) & 29.03 (6.48) \\  & 50  & 0.9 (0.06) & 1 (0) & 0.9 (0.06) & 0.57 (0.04) & 0.6 (0.04) & 0.58 (0.04) & 64.33 (8.75) & 47.16 (8.28) & 46.3 (7.26) & 47.35 (8.25) \\ 
     & 100  & 0.83 (0.07) & 1 (0) & 0.8 (0.07) & 0.49 (0.04) & 0.48 (0.04) & 0.5 (0.04) & 95.61 (13.02) & 90.1 (13.29) & 86.81 (11.75) & 90.55 (13.23) \\\end{tabular}}
   \end{center}
      \vspace{-.5cm}
\end{table}

\begin{table}[H]\caption{30 Monte Carlo simulations of $\mc{M}_2$ for $\mc{B}_f$ with varying $\sigma$ and $\sigma_{\alpha}$} \vspace{.3cm} \label{table4}
\begin{center}\resizebox{\textwidth-1.2cm}{!}{\begin{tabular}{cc|ccc|ccc|cccc|}
   &   & \multicolumn{3}{|c|}{Guess} & \multicolumn{3}{|c|}{LOOCV with $k$ random draws} &  \multicolumn{4}{|c|}{Distance to $y_{1, T_1^*+1}$} \\  $\sigma$   & $\sigma_{\alpha}$ &  $\delta_{\hat{\alpha}_{\rm adj}}$  & $\delta_{\hat{\alpha}_{\rm wadj}}$ & $\delta_{\hat{\alpha}_{\rm IVW}}$  & $\bar{\mc{C}}^{(k)}(\delta_{\hat{\alpha}_{\rm adj}})$  & $\bar{\mc{C}}^{(k)}(\delta_{\hat{\alpha}_{\rm wadj}})$ & $\bar{\mc{C}}^{(k)}(\delta_{\hat{\alpha}_{\rm IVW}})$ & Original & $\hat{\alpha}_{\rm adj}$ & $\hat{\alpha}_{\rm wadj}$ & $\hat{\alpha}_{\rm IVW}$\\[.15cm]   \hline  \multirow{5}{*}{5} & 5  & 1 (0) & 1 (0) & 1 (0) & 0.99 (0.01) & 0.99 (0.01) & 0.99 (0.01) & 53.27 (2.59) & 10.91 (1.7) & 11.77 (1.55) & 10.8 (1.69) \\   & 10  & 1 (0) & 1 (0) & 1 (0) & 0.91 (0.02) & 0.95 (0.02) & 0.92 (0.02) & 50.86 (3.83) & 18.06 (2.18) & 17.26 (2.17) & 18.25 (2.17) \\   & 25  & 0.97 (0.03) & 1 (0) & 0.97 (0.03) & 0.83 (0.03) & 0.89 (0.02) & 0.83 (0.03) & 60.52 (3.97) & 16.09 (2.4) & 19.83 (3.05) & 15.87 (2.38) \\   & 50  & 0.87 (0.06) & 1 (0) & 0.87 (0.06) & 0.67 (0.04) & 0.69 (0.03) & 0.67 (0.04) & 54.65 (6.95) & 51.79 (6.87) & 53.83 (7.26) & 52.6 (6.91) \\   & 100  & 0.7 (0.09) & 0.93 (0.05) & 0.77 (0.08) & 0.52 (0.04) & 0.51 (0.04) & 0.51 (0.05) & 104.73 (13) & 88.31 (12.16) & 88.88 (12.63) & 86.72 (12.35) \\[.3cm]   \multirow{5}{*}{10} & 5  & 1 (0) & 1 (0) & 1 (0) & 0.93 (0.02) & 0.93 (0.02) & 0.93 (0.02) & 58.17 (4.18) & 18.17 (2.61) & 16.59 (2.39) & 18.09 (2.63) \\   & 10  & 1 (0) & 1 (0) & 1 (0) & 0.86 (0.03) & 0.89 (0.03) & 0.87 (0.03) & 52.81 (4.07) & 19.05 (2.49) & 19.67 (2.66) & 18.95 (2.53) \\   & 25  & 0.97 (0.03) & 1 (0) & 0.97 (0.03) & 0.78 (0.03) & 0.82 (0.03) & 0.79 (0.03) & 61.53 (5.69) & 28.55 (4.07) & 31.82 (4.27) & 28.76 (4.07) \\   & 50  & 0.93 (0.05) & 1 (0) & 0.9 (0.06) & 0.66 (0.04) & 0.67 (0.04) & 0.66 (0.04) & 56.31 (8.03) & 47.33 (4.89) & 41.44 (4.39) & 46.86 (4.79) \\   & 100  & 0.77 (0.08) & 0.97 (0.03) & 0.7 (0.09) & 0.54 (0.05) & 0.54 (0.04) & 0.55 (0.04) & 84.38 (11.62) & 82.91 (11.77) & 84.5 (12.39) & 84.3 (11.93) \\[.3cm]   \multirow{5}{*}{25} & 5  & 0.97 (0.03) & 1 (0) & 1 (0) & 0.78 (0.03) & 0.77 (0.03) & 0.79 (0.03) & 56.35 (6.1) & 25.54 (4.06) & 30.49 (4.61) & 25.94 (4.02) \\    & 10  & 1 (0) & 1 (0) & 1 (0) & 0.81 (0.03) & 0.79 (0.03) & 0.81 (0.03) & 49.8 (5.24) & 25.04 (4.38) & 26.74 (3.64) & 24.86 (4.38) \\   & 25  & 1 (0) & 1 (0) & 1 (0) & 0.72 (0.03) & 0.77 (0.03) & 0.71 (0.03) & 54.21 (6.51) & 44.17 (6.66) & 43.41 (6.95) & 43.89 (6.63) \\   & 50  & 0.87 (0.06) & 0.97 (0.03) & 0.87 (0.06) & 0.55 (0.04) & 0.57 (0.04) & 0.52 (0.04) & 66.51 (7.86) & 46.19 (8.04) & 44.83 (9.31) & 46.54 (8.27) \\   & 100  & 0.9 (0.06) & 1 (0) & 0.87 (0.06) & 0.54 (0.04) & 0.54 (0.04) & 0.56 (0.04) & 109.21 (13.29) & 78.47 (12.45) & 83.99 (12) & 78.57 (12.75)\\[.3cm]   \multirow{5}{*}{50} & 5  & 0.83 (0.07) & 0.73 (0.08) & 0.8 (0.07) & 0.54 (0.04) & 0.57 (0.04) & 0.55 (0.04) & 75.29 (10.75) & 63.51 (8.3) & 64.25 (8.88) & 63.32 (8.4) \\   & 10  & 0.77 (0.08) & 0.8 (0.07) & 0.77 (0.08) & 0.53 (0.04) & 0.55 (0.05) & 0.53 (0.04) & 57.59 (6) & 48.51 (8.32) & 50.58 (8.63) & 48.08 (8.36) \\   & 25  & 0.73 (0.08) & 0.8 (0.07) & 0.73 (0.08) & 0.58 (0.04) & 0.58 (0.04) & 0.57 (0.04) & 77.21 (12.03) & 54.73 (9.47) & 54.76 (10.24) & 54.2 (9.62) \\   & 50  & 0.8 (0.07) & 0.83 (0.07) & 0.8 (0.07) & 0.59 (0.04) & 0.53 (0.04) & 0.6 (0.04) & 90.48 (10.21) & 68.88 (9.2) & 68.28 (10.48) & 68.8 (9.28) \\   & 100  & 0.5 (0.09) & 0.73 (0.08) & 0.53 (0.09) & 0.51 (0.05) & 0.48 (0.05) & 0.51 (0.05) & 111.09 (17.54) & 102.47 (16.68) & 110.15 (15.87) & 101.53 (16.52) \\[.3cm]   \multirow{5}{*}{100} & 5  & 0.43 (0.09) & 0.37 (0.09) & 0.43 (0.09) & 0.47 (0.04) & 0.47 (0.04) & 0.47 (0.04) & 214.07 (67.4) & 195.46 (67.65) & 197.51 (68.45) & 196.58 (67.51) \\   & 10  & 0.63 (0.09) & 0.6 (0.09) & 0.67 (0.09) & 0.51 (0.04) & 0.49 (0.04) & 0.51 (0.04) & 120.85 (15.39) & 114.79 (15.51) & 119.19 (15.75) & 114.02 (15.74) \\   & 25  & 0.57 (0.09) & 0.6 (0.09) & 0.57 (0.09) & 0.51 (0.04) & 0.53 (0.04) & 0.49 (0.04) & 97.84 (13.75) & 95.02 (14.88) & 100.04 (16.94) & 96.23 (14.71) \\   & 50  & 0.53 (0.09) & 0.43 (0.09) & 0.5 (0.09) & 0.47 (0.04) & 0.49 (0.05) & 0.49 (0.05) & 141.22 (24.51) & 136.11 (25.73) & 150.62 (27.62) & 135.26 (25.39) \\   & 100  & 0.63 (0.09) & 0.63 (0.09) & 0.63 (0.09) & 0.43 (0.04) & 0.41 (0.04) & 0.45 (0.04) & 95.53 (12.8) & 103.01 (14.12) & 103.31 (16.27) & 105.79 (14.32) \\\end{tabular}}
   \end{center}
      \vspace{-.5cm}
\end{table}


Simulation for $\mc{B}_f$ with the same parameter setup as that of $\mc{B}_u$ are implemented. See Table \ref{table3} and Table \ref{table4} for results. Comparing Table \ref{table1}
 and Table \ref{table2} yields that when $n$ is small ($n = 5$ or $n = 10$) and $\sigma_{\alpha}$ is small ($\sigma_{\alpha}=5$), $\mc{B}_u$ is better than $\mc{B}_f$ with statistical evidence. For other situations, $\mc{B}_u$  and $\mc{B}_f$  are rather similar. It is likely that the extra randomness from sampling with replacement from donor pool compensates for the possible noises from a small donor pool. Concerning  Table \ref{table2} and Table \ref{table4}, it appears that when $n = 10$ and $\sigma_{\alpha}=5$, $\mc{B}_u$ is better than  $\mc{B}_f$  when $\sigma$ increases. It might be the case that additional layer of bootstrap in the donor pool buffers the negative effects on $\bar{\mc{C}}(\delta_{\hat{\alpha}})$  introduced from increasing variation of $y_{i,t}$. However, when $\sigma_{\alpha}$ increases over 5 and $n = 10$,  $\mc{B}_f$ and $\mc{B}_u$ are quite similar under  situations of different $\sigma$ and $\sigma_{\alpha}$. In conclusion, $\mc{B}_u$ is better than $\mc{B}_f$ when the signal of the covariates is strong and $n$ is small; otherwise, they are similar. %See more discussions for differences between $\mc{B}_u$ and $\mc{B}_f$ in Section \ref{discussion}. 
 
 
 Simulation results corresponding to model $\mc{M}_1$ are listed in Section 3 in Supplementary Materials. Results under model $\mc{M}_1$ are very similar to those of $\mc{M}_2$, except for the difference among estimators. The results show that (1) the performance of $\hat{\alpha}_{\rm adj}$ and  $\hat{\alpha}_{\rm IVW}$ are nearly the same and (2) in many situations, $\hat{\alpha}_{\rm adj}$ and  $\hat{\alpha}_{\rm IVW}$ are  better than $\hat{\alpha}_{\rm wadj}$; in other situations, they are mostly the same. Recall that in $\mc{M}_1$, the models for $\alpha_1$ do not involve the covariates. Therefore, similarity weighting may not be informative when the model for $\alpha_i$ is identified wrongly. Under $\mc{M}_1$, simple averaging, aimed for a reduction of variance, or inverse-variance weighting, targeting on reducing negative effects from varying time lengths, may work better.








\section{Forecasting Conoco Phillips stock in the presence of shocks}
\label{forecasting}

We demonstrate our post-shock forecasting methodology on a time series of Conoco Phillips share prices after the occurrence of a structural shock. Conoco Phillips is a large oil and gas resources company \citep{conocowhatwedo}. The particular post-shock response that we predict happened after trading ended on Friday March 6th, 2020 and before trading began on Monday March 9th, 2020. It is reasonable that the timing of this shock is known, several events occurred over the trading weekend which had an impact on stock markets and the oil markets. For example, Russia and OPEC began a battle for global oil price control on Sunday, March 8th \citep{sukhankin2020russian}, and several US states began declaring state of emergencies in response to the evolving coronavirus pandemic \citep{nygov, alonso2020state}. In this analysis we make the following design considerations:

%In this example we forecast Conoco Phillips stock prices in the midst of the coronavirus recession. Specific interest is in predictions made after March 6, 2020, the Friday before the stock market crash on March 9, 2020. We will detail how we combine knowledge from disparate time series to improve the forecast of Conoco Phillips stock price that would be made without adjustments for the shock. %Section \ref{background} provides the justification for the first three steps. Section \ref{results} discusses the result of our forecast.

%\subsection{Background}
%\label{background}

%Conoco Phillips is chosen for this analysis because it is a large oil and gas resources company \citep{conocowhatwedo}. %and with a relatively recent initial public offering \citep{conocohist}. 
%Focus on the oil sector is because oil prices have been shown to exhibit a cointegrating behavior with economic indices \citep{he2010global}, and our chosen time frame represents the onset of a significant economic down turn, coupled with a Russia and OPEC battle for global oil price control on the Sunday before trading resumes on Monday, March 9th \citep{sukhankin2020russian}. Furthermore, fear and action in response to the coronavirus pandemic began to uptick dramatically between Friday, March 6th and Monday, March 9th. Major events include the SXSW festival being cancelled as trading closed on March 6th \citep{wang2020impact}. New York declared a state of emergency on March 7th \citep{nygov}, and by Sunday, March 8th, eight states have declared a state of emergency \citep{alonso2020state} while Italy placed 16 million people in quarantine \citep{sjodin2020only}.


%Economic indicators forecasted our recession before the coronavirus pandemic began. The current recession followed an inversion of the yield curve that first happened back in March, 2019 \citep{tokic2019yield}. An inversion of the yield curve is an event that signals likely recessions \citep{andolfatto2018yield, bauer2018economic}. In this analysis we investigate the performance of oil companies in previous recessions that followed an inversion of the yield curve to obtain a suitable Conoco Phillips donor pool for estimating the March 9th shock effect on Conoco Phillips oil stock. We also consider previous OPEC oil supply shocks \citep{mensi2014opec}. We will borrow from the literature on oil price forecasting to establish appropriate time horizons and forecasting models. Recessions that occurred before 1973 are disregarded since oil price forecasts cannot be represented by standard time series models before 1973 \citep{alquist2013forecasting}. 


\begin{enumerate}
\item[(1)] {\bf Selection of model}. We will use an AR(1) model to forecast Conoco Phillips stock price. This model has been shown to beat no-change forecasts when predicting oil prices over time horizons of one and three months \citep{alquist2013forecasting}.  For these reasons, we will consider 30 pre-shock trading days and we will forecast the immediate shock effect. All estimates will be adjusted for inflation. The model setup for AR(1) is exactly the same as what is stated in Section \ref{modelsetup} with addition of shock effects. All the parameters are estimated using OLS.
\item[(2)] {\bf Selection of covariates}. We perform our analyses incorporating daily S\&P 500 index prices and West Texas Intermediate (WTI) crude oil prices as covariates. 
\item[(3)] {\bf Construction of donor pool}. Our donor pool consists of Conoco Phillips shock effects observed in the past. We consider shock effects which occurred on March 14, 2008, several days in September, 2008, and November 27, 2014. The first sets of shock effects were observed during recessions that possessed similar characteristics to the current recession. In particular, all of these recessions were predicated by an inversion of the yield curve \citep{bauer2018economic}. These 2008 shock effects correspond to the collapse of Bear Stearns, the placement of Fannie May and Freddie Mac in conservatorship on September 7th, the collapse of Lehman Brothers on September 15th, and the closing of Washington Mutual on September 25th \citep{shorter2008bear, ewing2013volatility, dwyer2009financial, longstaff2010subprime}. The last shock effect corresponds to an OPEC induced supply side shock effect \citep{huppmann2015opec}. %The reasons for those three shocks are.
%  \begin{enumerate}
%  \item On March 14, 2008, Bear Stearns was verging on bankruptcy from what its officials described as a sudden liquidity squeeze related to its large exposure to devalued mortgage-backed securities. On that day, it also received word that it was getting an unprecedented loan from the Federal Reserve System, this decision was unprecedented: never before had the Fed committed to ``bailing out'' a financial entity that was not a commercial bank. The day of the announcement, the stocks of other major Wall Street firms tumbled (including Conoco Phillips). These concerns then spilled over into the broader universe of stocks \citep{shorter2008bear}. %In heavy trading on Tuesday, March 18, the firm’s share price closed at \$5.91.
%  \item  In early September 2008, time series of oil prices experienced a sudden increase in volatility simultaneously due to turmoil in financial markets. The political, economic, social or environmental events may coincide with these shocks \citep{ewing2013volatility}. Notable shock effects followed the placement of Fannie May and Freddie Mac in conservatorship on September 7th (shock effect on the 8th), Lehman Brothers filing for bankruptcy on September 15th, and the Office of Thrift Supervision closes Washington Mutual Bank on September 25th \citep{dwyer2009financial, longstaff2010subprime}.
%  \item On November 27th, 2014, it is documented that oil prices fall as OPEC opts not to cut production \citep{huppmann2015opec}. During the Great Recession when economic activity clearly declined, both oil and stock prices fell which points to demand factors. During the second half of 2014, oil prices plummeted but equity prices generally increased, suggesting that supply factors were the key driver \citep[Page 19]{baffes2015great}. 
%  \end{enumerate}
\end{enumerate}


We assume that the five shocks are independent of the shock that Conoco Phillips experienced on March 9, 2020. The covariates and response of time series in the donor pool are adjusted for inflation. Note that there are three shock effects nested in the time series 2008 September, we assume that these three shocks are independent, where the assumption checks using likelihood ratio test are provided in the Section 1 in the Supplementary Materials. Under $\mc{M}_{2}$, we computed $\hat{\alpha}_{\rm adj}$, weighted adjustment $\hat{\alpha}_{\rm wadj}$, and $\hat{\alpha}_{\rm IVW}$. For $\hat{\alpha}_{\rm wadj}$, we observe that 
$
  \mathbf{W}^*= (0.000,0.000, 0.000, 0.000, 1.000)
$
and 
$
  \norm{\mbf{X}_1-\hat{\mbf{X}}_1(\mbf{W}^*)}_{2} = 900.13.
$
Note that the norm is computed using the $k$-dimensional Euclidean metric. The solution $\mathbf{W}^*$ suggests that the shock effect of interest is replicated by the November 27, 2014 shock effect. 

%\begin{table}[H]
%  \caption{Bootstrap estimates and results yielded by risk-reduction propositions with $B = 1000$}\label{table5}
%  \begin{center}
%    \begin{tabular}{lrrr}
%      & $\hat{\alpha}_{\rm adj}$ & $\hat{\alpha}_{\rm wadj}$ & $\hat{\alpha}_{\rm IVW}$ \\
 %     \hline 
 %   Bootstrapped variance & 0.531 & 0.479 & 0.970 \\
 %   \end{tabular}
 % \end{center}  
%\end{table}
%\vspace{-.5cm}

The resulting shock effect estimates are $\hat{\alpha}_{\rm adj}=-5.348$, $\hat{\alpha}_{\rm wadj}= -5.761$, and $\hat{\alpha}_{\rm IVW}=-5.290$. Using the bootstrap procedure $\mc{B}_f$, we estimated parameters for risk-reduction propositions and risk-reduction quantities proposed in  Section \ref{properties}. The estimated bootstrap variances for $\hat{\alpha}_{\text{adj}}$, $\hat{\alpha}_{\text{wadj}}$, and $\hat{\alpha}_{\text{IVW}}$  are 0.567, 0.499, and 1.006, respectively. %Plugging these estimates into conditions in Section \ref{properties} yields: (1) $\hat{\alpha}_{\text{adj}}$, $\hat{\alpha}_{\text{wadj}}$, and $\hat{\alpha}_{\text{IVW}}$  reduce the risk and (2) the risk-reduction quantities are $32.452$, $32.690$, and $31.960$, respectively. 
We verify the consistency of the result yielded by risk-reduction propositions with the reality as below.

\begin{figure}
  \begin{center}
    \includegraphics[height = 9cm]{fig2.pdf}
    \caption{March 9th, 2020 post-shock forecasts for Conoco Phillips stock price.}
    \label{Fig:CP}
  \end{center}  
  \vspace{-.6cm}
\end{figure}


We can see from Figure~\ref{Fig:CP} that $\hat{\alpha}_{\text{adj}}$, $\hat{\alpha}_{\text{wadj}}$ and $\hat{\alpha}_{\text{IVW}}$ perform decently well, and they do not recover the magnitude of the shock effect but are much better than unadjusted forecasts that do not account for shock effects. 
The unadjusted forecast misses the post-shock response by 9.870 dollars whereas 
the use of $\hat{\alpha}_{\text{adj}}$, $\hat{\alpha}_{\text{wadj}}$, and $\hat{\alpha}_{\text{IVW}}$ misses by $4.522$, $4.109$, and $3.581$ dollars, respectively. 
%Therefore, the risk-reduction propositions are consistent with the reality  with the reduced risks for forecasts using  $\hat{\alpha}_{\text{adj}}$, $\hat{\alpha}_{\text{wadj}}$, and $\hat{\alpha}_{\text{IVW}}$ than without. Moreover, the risk-reduction quantities are consistent with the reality as well. 
The true shock effect is not fully recovered by $\hat{\alpha}_{\text{adj}}$, $\hat{\alpha}_{\text{wadj}}$, and $\hat{\alpha}_{\text{IVW}}$. This may be a result of a poorly constructed donor pool. The shock on March 9th, 2020 is in the midst of the COVID-19 pandemic and oil production volatility. It is difficult to find available stock market time series data that were generated under a similar setting. In any event, the shock on March 9th, 2020 was the largest price shock to Conoco Phillips shares by a wide margin, even after adjusting for inflation.


From another perspective, it is possible that the stock of Conoco Phillips actually experienced multiple shocks on 2020 March 9th. For example, \citet{kilian2009not} studied the effect that different supply and demand shocks have on oil prices through a vector auto regressive model. Their model postulates an additive nature of shock effects, although the additivity parameters requires estimation in their context. Motivated by his study, we also studied additive shock effect estimators where the shock effects corresponding to separate supply and demand shocks are added to estimate the unknown shock effect. The supply shock donor pool consists of the November 27, 2014 shock effect; and the demand shock donor pool consists of the remaining shock effects. The additive adjustment estimator computed by adding the $\hat{\alpha}_{\text{adj}}$, $\hat{\alpha}_{\text{wadj}}$, and $\hat{\alpha}_{\text{IVW}}$ estimators for the demand and supply shock effects have  RMSEs of $1.136$, $2.421$, and $0.818$ dollars, respectively. These additive adjustment estimators do extremely well. 
%There is apriori justification for the use of these simply additive adjustment estimators, although their nearly perfect performance in this example is a retrospective finding.  %This provides some anecdotal justification for apriori estimation of the March 9th Conoco Phillips shock effect with the addition of the adjustment estimator corresponding to the separate supply and demand aspects of this shock effect.






\section{Discussion}
\label{discussion}

We developed methodology for forecasting post-shock response values after the occurrence of a structural shock. Our methodology is as follows: construct a synthetic panel of disparate time series which have undergone similar shocks, estimate the shock effects in those series, aggregate them, and then adjust the original forecast by adding the aggregated shock effect estimator to the original forecast. We provided risk-reduction propositions and empirical tools that can prospectively assess the effectiveness of our adjustment strategies in additive shock effect settings. The model, under which we verify these claims, is a simple AR(1) model. Similar results can be obtained for more general models such as AR($p$), vector autoregression, and generalized autoregressive conditional heteroskedasticity models. %for $y_{i,t}$ with an additional component $\alpha_i 1(D_{i,t}=T_i^* + 1)$. 

Generally, multiple shock effects can be nested within a time series; and time series in the donor pool can be dependent. As an example, we could consider a dependency structure for the September 2008 shock effects in our analysis of Conoco Phillips stock. But we note that consistency estimates from LOOCV with $k$ random draws may not work well if donor pool candidates are not mutually independent since the almost unbiased property hinges on the mutual independence among candidates in the donor pool.
%This generalization is possible since our risk-reduction propositions in Section \ref{properties} assumes the shock effect estimates are independent of $\alpha_1$, the shock effect for the time series of interest; and allows arbitrary dependence of shock effects in the donor pool. 
%Specific to this generalization, we edit the model of $\alpha_i$ to $\alpha_i = \mu_{\alpha} + \delta_i'\mathbf{x}_{3, T_i^* + 1} + \gamma_i'\mathbf{x}_{3, T_i^*} + \tilde{\varepsilon}_i$ for $i = 3, 4, 5$ and $\alpha_i = \mu_{\alpha} + \delta_i'\mathbf{x}_{4, T_i^* + 1} + \gamma_i'\mathbf{x}_{4, T_i^*} + \tilde{\varepsilon}_i$ for $i = 6$.
%This generalization was adopted in Section \ref{forecasting}. In this case, the variance expressions proposed in Section \ref{properties} will not work. However, the risk-reduction propositions in Section \ref{properties} will work  as long as those shock effects (not necessarily mutually independent) in the donor pool are independent of the one of interest. 
Although it is reflected in $\mc{M}_2$, we stress that our proposed methods allow $\alpha_i$ to follow arbitrary distributions provided that its first and second moments exist. The covariates in the model for $\alpha_i$ under $\mc{M}_2$ can be different from the covariates in the model of $y_{i,t}$.  We also note that our post-shock framework can be extended to settings where the shock effect can be decomposed into separable estimable parts. An example of this is the additive shock effect estimators that we studied in our Conoco Phillips analysis. Although our work is developed for  time-series or AR$(p)$ models, in fact, it can be generalized to any similar setting with a model of the response, whose parameters can be estimated \emph{unbiasedly}, and an additive shock-effect structure.




Our bootstrap procedures can be extended to approximate the distribution of shock effect estimators from more general time series. If the data are subject to heteroskedasticity of unknown form, bootstrapping tuples of regressands and regressors proposed by \citet{freedman1981bootstrapping} is robust in this situation with asymptotic validity in autoregressive models established by \citet{gonccalves2004bootstrapping}. If serial correlation exists in the data, various block bootstrapping procedures \citep{kunsch1989jackknife, liu1992moving} can be possible reasonable alternatives. Note that the pseudo time series generated by our proposed parametric bootstrap are not stationary. If stationarity is of concern, one can be referred to the stationary bootstrap invented by \citet{politis1994stationary} for stationary and weakly dependent time series. Nevertheless, it was shown that approximation accuracy might be a cost for the stationary bootstrap in autoregressive  models in finite sample \citep{berkowitz1999finite}.  More work related to bootstrapping time series  can be referred to Chapters 3 and 4 in \citet{politis1999subsampling}, \citet{berkowitz2000recent}, and Chapter 12 in \citet{kilian2017structural}. It is up to  users in terms of selecting which procedure to choose but under different assumptions on the time series.

% \citet{politis1994stationary} motivated a stationary bootstrap method for strictly stationary and weakly dependent time series $\{X_n \colon n \in \mathbb{N}\}$.  This algorithm generates a sequence of blocks of observations $B_{I_1, L_1}, B_{I_2, L_2}, \ldots$ where $B_{i,b}= \{X_i, X_{i+1}, \ldots, X_{i+b-1}\}$; for $j > N$, $X_{j}$ is defined to be $X_k$, where $k = j \hspace{-.1cm} \mod N$ and $X_0 = X_N$. The sampling stops when $N$ observations are reached. Note that the collection of random positions $\{I_n \colon n \in \mathbb{N}\}$ is a sequence of i.i.d. discrete uniform random variables; and the collection of random lengths $\{L_n \colon n \in \mathbb{N}\}$ is a sequence of  i.i.d. geometric random variables with parameter $p$.  However, the consistency needs to be proved by a case-by-case analysis \citep[Page 66]{politis1999subsampling}. Additionally, the asymptotic accuracy of this algorithm can be sensitive to the selection of $p$. This issue is similar to that of the selection of block size in moving-block bootstrapping \citep{kunsch1989jackknife, liu1992moving}. 



We have implicitly assumed that $\mathbf{W}^*$ is non-degenerate in the population.  Recall that in Section \ref{constructionofestimators} we noted that if there exists some $\mathbf{W}^*$ which satisfies \eqref{SCM} and $p < n$, then there will be infinitely many solutions to $\mathbf{W}^*$. However, in applications, it is possible that $\mathbf{W}^*$ may take values on the boundary of $\mc{W}$, in which case bootstrapping may fail to estimate the distribution of $\hat{\alpha}_{\mrm{wadj}}$ \citep{andrews2000inconsistency}.  Moreover, when $p < n$, $\mc{B}_u$ fails since the existence of infinitely many solutions is certain (if there exists some $\mathbf{W}^*$ satisfies (\ref{SCM})), and will guarantee degeneracy of  $\mathbf{W}^*$. However, this issue will not occur under $\mc{B}_f$ since it takes $\mbf{W}^*$ as being fixed and the parameter space is $\Theta$ that does not involve the constrained $\mc{W}$. Nevertheless, it does not seriously compromise the inference according to our simulation results in Section 4 in the Supplementary Materials. 

Note that there are some philosophical distinctions between $\mc{B}_u$  and $\mc{B}_f$. $\mc{B}_u$ treats the donor pool as realizations from some infinite super-population of potential donors. In contrast, $\mc{B}_f$ treats the donor pool as being fixed  and known before the analysis is conducted, where the randomness comes from parameters and idiosyncratic error.


%Double bootstrap can also be employed as an alternative to the bootstrap procedure proposed in Section \ref{varbootstrap}. 
A double bootstrap procedure with similar steps to the bootstrap technique in Section~\ref{varbootstrap} can estimate the distribution of $\hat\Delta(\hat{\alpha})$ for $\hat{\alpha} \in \mc{A}$. The double bootstrap, instead of checking whether $\Delta(\hat{\alpha})>0$, can check whether a bootstrap percentile interval of resampled estimates of $\Delta(\hat{\alpha})$ contain 0 at a desired error threshold. We investigated such a double bootstrap procedure and found that it produced inferences that were similar to those produced using the bootstrap techniques developed in the main text. 


There have been several recent time series pooling methods developed for forecasting COVID-19 cases. \citet{lee2020estimation} constructed a Bayesian hierarchical model embracing data integration to improve predictive precision of COVID-19 infection trajectories for different countries. A similar setup may be appropriate for post-shock forecasting but may be too dependent upon model specification for the shock distribution. \citet{plessen2020integrated} employed a data-mining approach to combine COVID-19 data from different countries as input to predict global net daily infections and deaths of COVID-19 using a clustering approach. However, there is a tremendous amount of volatility in this form of COVID-19 data, and the fit of this prediction method may be improved with modeling structure or preprocessing of the donor pool. \citet{agarwal2020two} proposed a model-free synthetic intervention method to predict unobserved potential outcomes after different interventions given a donor pool of observed outcomes with given interventions. They also provide useful guidelines for how to estimate the effects of potential interventions by giving recommendations for choosing the metric of interest, the intervention of interest, time horizons, and the donor pool. Although the methodology in \citet{agarwal2020two} is quite general, there is no guarantee for theoretical properties in prediction without assuming any distributional structure.


\section{Appendix}
\label{proofs}

\subsection{Justification of Expectation of $\hat{\alpha}_{\rm adj}$ and $\hat{\alpha}_{\rm wadj}$}
\label{exp}

The building block for the following proof is the fact that least squares is conditionally unbiased conditioned on $\Theta$. 

\noindent \textbf{Case I: under $\mc{M}_{1}$:} It follows that  under $\mc{M}_{1}$ (see Section \ref{modelsetup}),
\begin{align*}
\E{\hat{\alpha}_{\rm adj}} =\frac{1}{n}  \sum_{i=2}^{n+1} \E{\E{\hat{\alpha}_i|\Theta}} = \mu_{\alpha} 
\quad \text{ and } \quad \E{\hat{\alpha}_{\rm wadj}}&= \sum_{i=2}^{n+1} w_i^* \E{\E{\hat{\alpha}_i|\Theta}}= \sum_{i=2}^{n+1} w_i^*\mu_{\alpha}= \mu_{\alpha}.
\end{align*}
where we used the fact that $\sum_{i=2}^{n+1} w_i=1$. 

\noindent \textbf{Case II: under $\mc{M}_{21}$ and $\mc{M}_{22}$:} Since $\E{\tilde{\varepsilon}_{i, T_i}}=0$, $\E{\hat{\tilde{\alpha}}_{i}}=\E{\tilde{\alpha}_{i}}=\E{\alpha_{i}}$, it follows that
  \begin{align*}
   \E{\hat{\alpha}_{\rm wadj}}= \mrm{E}\left\{\mrm{E}\left(\sum_{i=2}^{n+1} w_i^*\hat{\alpha}_i|\Theta\right)\right\}
   &= \mrm{E}\left( \sum_{i=2}^{n+1} w_i^*\alpha_i\right)\\
   &= \mrm{E}\bigg\{ \sum_{i=2}^{n+1} w_i^*\left[\mu_{\alpha}+\delta_{i}'\mbf{x}_{i, T_i^*+1}\right]\bigg\}\\
   &=\mu_{\alpha}+ \mu_{\delta}' \sum_{i=2}^{n+1} w_i^*\mbf{x}_{i, T_i^*+1}\tag{$\mbf{W}\in \mc{W}$}
   \\
   &=\mu_{\alpha}+  \mu_{\delta}'\mbf{x}_{1, T_1^*+1}. \tag{from (\ref{SCM})}
   \end{align*}
Similarly,
  \begin{align*}
   \E{\hat{\alpha}_{\rm adj}}
   &=\mu_{\alpha}+\frac{1}{n}\sum_{i=2}^{n+1} \mu_{\delta}'  \mbf{x}_{i, T_i^*+1}.
   \end{align*}


\subsection{Justification of Variance of $\hat{\alpha}_{\rm adj}$ and $\hat{\alpha}_{\rm wadj}$}
\label{var}

Notice that under the setting of OLS, the design matrix for $\mc{M}_2$ is the same as the one for $\mc{M}_1$. Therefore, it follows that
  \begin{align*}
  \var{\hat{\alpha}_{\rm wadj}} 
  &= \E{\var{\hat{\alpha}_{\rm wadj}|\Theta}} + \var{\E{\hat{\alpha}_{\rm wadj}|\Theta}} \\
  &=\mrm{E} \left\{\mrm{Var}\left(\sum_{i=2}^{n+1} w_i^*\hat{\alpha}_i|\Theta\right)\right\} +\mrm{Var}\left(\sum_{i=2}^{n+1} w_i^*\alpha_i\right) 
\end{align*}
Under $\mc{M}_{21}$ where $\delta_i=\delta$ are fixed unknown parameters,  we will have
  \begin{align}
  \var{\hat{\alpha}_{\rm wadj}} 
  &= \mrm{E} \left\{\sum_{i=2}^{n+1}(w_i^*)^2(\sigma^2(\mbf{U}'_i\mbf{U}_i)^{-1}_{22})\right\} +\sigma^2_{\alpha}\sum_{i=2}^{n+1}(w_i^*)^2  \nonumber\\
  &= \sigma^2\sum_{i=2}^{n+1}(w_i^*)^2\mrm{E}\big\{(\mbf{U}'_i\mbf{U}_i)^{-1}_{22}\big\}+\sigma^2_{\alpha}\sum_{i=2}^{n+1}(w_i^*)^2.\label{equation6}
\end{align}
Similarly, under $\mc{M}_{22}$ where we assume $\delta_i \indep \gamma_i \indep \varepsilon_{i,t}$, we have
 \begin{align*}
  \var{\hat{\alpha}_{\rm wadj}} 
  &= \sigma^2\sum_{i=2}^{n+1}(w_i^*)^2\mrm{E}\big\{(\mbf{U}'_i\mbf{U}_i)^{-1}_{22}\big\}
  + \sum_{i=2}^{n+1} (w_i^*)^2 (\mbf{x}_{i, T_i^*+1}'\Sigma_{\delta}\mbf{x}_{i, T_i^*+1} + \sigma^2_{\alpha})
\end{align*}
For the adjustment estimator, we simply replace $\mbf{W}^*$ with $1/n\mbf{1}_n$. Thus, under $\mc{M}_{21}$ we have 
 \begin{align*}
  \var{\hat{\alpha}_{\rm adj}} 
  &=\frac{\sigma^2}{n^2}\sum_{i=2}^{n+1}\mrm{E}\big\{(\mbf{U}'_i\mbf{U}_i)^{-1}_{22}\big\}+\frac{\sigma^2_{\alpha}}{n^2}
\end{align*}
Under $\mc{M}_{22}$, we shall have
 \begin{align*}
  \var{\hat{\alpha}_{\rm adj}} 
  &=\frac{\sigma^2}{n^2}\sum_{i=2}^{n+1}\mrm{E}\big\{(\mbf{U}'_i\mbf{U}_i)^{-1}_{22}\big\}+\frac{1}{n^2}(\mbf{x}_{i, T_i^*+1}'\Sigma_{\delta}\mbf{x}_{i, T_i^*+1} + \sigma^2_{\alpha}).
\end{align*}
Notice that $\mc{M}_{1}$ differs from $\mc{M}_{21}$ only by its mean parameterization of $\alpha$ (see Section \ref{modelsetup}). In other words, the variances of $\hat{\alpha}_{\rm adj}$ and $\hat{\alpha}_{\rm wadj}$ under $\mc{M}_1$ are the same for those under $\mc{M}_{21}$.

\subsection{Proofs for lemmas and propositions}

\begin{proof-of-proposition}[\ref{uniqueness}]
  The proof of \citet{li2019statistical} in Appendix A.2 and A.3 adapts easily to Proposition \ref{uniqueness}.
\end{proof-of-proposition}


\begin{proof-of-proposition}[\ref{unbiased}] The proof for unbiasedness follows immediately from discussions related to expectation in Section \ref{properties}. For the biasedness of  $\hat{\alpha}_{\rm adj}$ under $\mc{M}_{21}$ and $\mc{M}_{22}$, we write the bias term for $\hat{\alpha}_{\rm adj}$ as below.
\begin{align*}
  \mrm{Bias}(\hat{\alpha}_{\rm adj}) = 
  \begin{cases}
       \frac{1}{n} \sum_{i=2}^{n+1} \delta'(\mbf{x}_{i, T_i^*+1}-n\mbf{x}_{1, T_1^*+1})  & \text{ for } \mc{M}_{21}\\
    \frac{1}{n} \sum_{i=2}^{n+1} \mu_{\delta}'(\mbf{x}_{i, T_i^*+1}-n\mbf{x}_{1, T_1^*+1})  & \text{ for }\mc{M}_{22}
  \end{cases}.
\end{align*}
But it may be unbiased in some special circumstances when the above bias turns out to be 0. \end{proof-of-proposition}

\begin{lem}
  \label{risklemma} The forecast risk reduction is $R_{T_1^*+1,1}-R_{T_1^*+1,2}=\E{\alpha_1^2}-\E{\hat{\alpha}-\alpha_1}^2$ for all estimators of $\alpha_1$ that are independent of $\Theta_1$ (see Section \ref{modelsetup}).
\end{lem}

  
\begin{proof-of-lemma}[\ref{risklemma}]
  Define 
  \begin{align*}
    C(\Theta_1) =\hat{\eta}_1 +\hat{\phi}_1 y_{1, T_1^*}+\hat{\theta}_1'\mbf{x}_{1, T_1^*+1} -(\eta_1 +\phi_1y_{1,T_1^*}+\theta_1'\mbf{x}_{1,T_1^*+1}),
  \end{align*}
  where $\Theta_1$ is as defined in (\ref{parameter}). Notice that
  \begin{align*}
    R_{T_1^*+1,1}= \mrm{E}\big\{\big(C(\Theta_1)-\alpha_1\big)^2\big\}
    \qquad \text{ and } 
    \qquad  R_{T_1^*+1,2}= \mrm{E}\big\{\big(C(\Theta_1)+\hat{\alpha}-\alpha_1\big)^2\big\}.
  \end{align*}
  It follows that
  \begin{align*}
    R_{T_1^*+1,1}-R_{T_1^*+1,2}=\E{\alpha_1^2}-2\E{C(\Theta_1)\hat{\alpha}}-\E{\hat{\alpha}-\alpha_1}^2.
  \end{align*}
  Assuming $\mbf{S}=(\mbf{1}_n, \mbf{y}_{1,t-1}, \mbf{x}_{1})$ has full rank, under OLS setting, $\hat{\eta}_1$, $\hat{\phi}_1$, and $\hat{\theta}_1$ are unbiased estimators of $\eta_1$, $\phi_1$, and $\theta_1$, respectively under conditioning of $\Theta_1$. Since we assume $\hat{\alpha}$ is independent of $\Theta_1$, through the method of iterated expectation,
  \begin{align*}
    \E{C(\Theta_1)\hat{\alpha}}=\mrm{E}\big\{\hat{\alpha}\cdot \E{C(\Theta_1)\mid \Theta_1}\}=0.
  \end{align*}
  It follows that
  \begin{align*}
    R_{T_1^*+1,1}-R_{T_1^*+1,2}=\E{\alpha_1^2}-\E{\hat{\alpha}-\alpha_1}^2,
  \end{align*}
  which finishes the proof.
\end{proof-of-lemma}





\begin{proof-of-proposition}[\ref{proprisk}] The proofs are arranged into two separate parts as below.

 \textbf{Proof for statement (i):} Under $\mc{M}_1$, $\hat{\alpha}_{\rm adj}$ is an unbiased estimator of $\E{\alpha_1}$ because
  \begin{align*}
   \mrm{E}\left( \frac{1}{n}\sum_{i=2}^{n+1} \hat{\alpha}_i\right)
   = \frac{1}{n}\sum_{i=2}^{n+1}\E{\hat{\alpha}_i}
   &= \frac{1}{n}\sum_{i=2}^{n+1}\E{\E{\hat{\alpha}_i\mid \Theta}}\\
   &=  \frac{1}{n}\sum_{i=2}^{n+1}\E{\alpha_i}
   = \mu_{\alpha}=\E{\alpha_1},
  \end{align*}
  where we used the fact that OLS estimator is unbiased when the design matrix $\mbf{U}_i$ is of full rank for all $i = 2, \ldots, n+1$. Because $\alpha_1\indep \varepsilon_{i,t}$, $\E{\hat{\alpha}_{\rm adj}\alpha_1}=\E{\hat{\alpha}_{\rm adj}}\E{\alpha_1}=(\E{\hat{\alpha}_{\rm adj}})^2$. By Lemma \ref{risklemma}, 
    \begin{align*}
    R_{T_1^*+1,1}-R_{T_1^*+1,2}
    &=\E{\alpha_1^2}-\E{\hat{\alpha}_{\rm adj}-\alpha_1}^2\\
   & =\E{\alpha_1^2}-\E{\alpha_1^2}- \E{\hat{\alpha}_{\rm adj}^2}+2\E{\hat{\alpha}_{\rm adj}\alpha_1} \\
   &= \mu_{\alpha}^2 - \var{\hat{\alpha}_{\rm adj}} 
  \end{align*}
  Therefore, as long as we have $\var{\hat{\alpha}_{\rm adj}}<\mu_{\alpha}^2$, we will achieve the risk reduction. 

 \textbf{Proof for statement (ii):} By Proposition \ref{unbiased}, the property that $\hat{\alpha}_{\rm wadj}$ is an unbiased estimator of $\mu_{\alpha}$ holds for $\mc{M}_{1}$. The remainder of the proof follows a similar argument to the proof of statement (i).
\end{proof-of-proposition}



\begin{proof-of-proposition}[\ref{propriskwadj2}]
  By Proposition \ref{unbiased}, the property that $\hat{\alpha}_{\rm wadj}$ is an unbiased estimator of $\E{\alpha_1}$ holds for $\mc{M}_{21}$ and $\mc{M}_{22}$. The remainder of the proof follows a similar argument to the proof of Proposition \ref{proprisk}.
\end{proof-of-proposition}







\bibliographystyle{plainnat}
\bibliography{synthetic-prediction-notes}




\end{document}

