\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
%\usepackage{amscd}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{natbib}
\usepackage{url}

\usepackage{geometry}
\usepackage[usenames]{color}
\geometry{margin=1in}

\newcommand{\R}{\mathbb{R}}
\newcommand{\w}{\textbf{w}}
\newcommand{\x}{\textbf{x}}
\newcommand{\X}{\textbf{X}}
\newcommand{\Y}{\textbf{Y}}
\newcommand{\Hist}{\mathcal{H}}

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\indep}{\perp\!\!\!\perp}

\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\Var}{Var}

\newtheorem{cor}{Corollary}
\newtheorem{lem}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{defn}{Definition}
\newtheorem{prop}{Proposition}

\newcommand\red[1]{{\color{red}#1}}

\allowdisplaybreaks

\title{Minimizing post shock forecasting error using disparate information}
\author{Daniel J. Eck}

\begin{document}


\maketitle
\begin{abstract}
    We develop a forecasting methodology for time series data that is 
    thought to have undergone a shock which has origins that have not been 
    previously observed.  We still can provide credible forecasts for a time 
    series in the presence of such systematic shocks by drawing from disparate 
    time series that have undergone similar shocks for which post-shock 
    outcome data is recorded.  These disparate time series are assumed to have 
    mechanistic similarities to the time series under study but are otherwise 
    independent (Granger noncausal).  The inferential goal of our forecasting 
    methodology is to supplement observed time series data with post-shock 
    data from the disparate time series in order to minimize average forecast 
    risk. 
\end{abstract}


{\bf Things to do}: \\

  - get regression model interpretation of $\Var(\hat\alpha_j)$. \\

  - simulations for simple model with normal errors; model with normal 
    errors and $p > 1$; model where shock effect is Gamma. \\

  - more general panel model where covariates may be different. \\

  - get references on time series pooling. \\

  - investigate orthogonal parameterizations of regression model 
    matrices in order to isolate estimation of $\Var(\hat\alpha_j)$, 
    so that the asymptotic estimate of $\Var(\hat\alpha_j)$ is independent 
    of other terms. \\

  - expand method to weighted cases when the shock effect depends on the 
    measured covariates. \\

  - get a real dataset. Air conditiong units in hot humid summer vs salt sales 
  	in very icy/snoy winters and portable generators for hurricane/fires/tornados  \\ 



\section{Introduction}
The technique of combining forecasts to lower forecast error has a rich 
history \citep{bates1969combination, mundlak1978pooling, 
  timmermann2006forecast, granger2014forecasting}.  
The Introduction of \citet{timmermann2006forecast} provided several reasons 
for combining forecasts.  In particular, combining forecasts may be 
beneficial when: 
1) the information set underlying individual forecasts is often unobserved to 
the forecast user; 2) different individual forecasts may be very differently 
affected by non-stationarities and model misspecifications; 3) different 
individual forecasts may be motivated by different loss functions 
\citep[and references therein]{timmermann2006forecast}.
The setting for the forecast combination problem is that there are 
competing forecasts for a single time series.  In this setting, one may 
desire combining forecasts as a method for lowering overall forecast error.  




In this article we propse a new setting for the forecast combination 
problem.  We will suppose that a time series of interest has recently 
undergone a structural shock that is not similar to anything observed in its 
past, and we desire reliable post-shock forecasts in this setting.  It is 
unlikely that any forecast that previously gave successful predictions for  
the time series of interest will be able to accomondate the recent structural 
shock.  However, it may be the case that disparate time series have previously 
undergone similar structural shocks.  When this is so, one may be able to 
aggreagate the post-shock information from these disparate time series to aid 
the post-shock forecast for the time series under investigation.  



\section{Setting}

We will suppose that an analyst has time series data ($y_{i,t}$,$\x_{i,t}$), 
$t = 1$, $\ldots$, $T_i$, $i = 1$, $\ldots$, $n+1$, where $y_{i,t}$ is a 
scalar response and $\x_{i,t}$ is a vector of covariates that revealed prior 
to the observation of $y_{1,t}$.  Suppose that the analyst is interested in 
forecasting $y_{1,t}$, the first time series in the collection.
%$y_1, y_2, \ldots$.  
%Given each time point $t \geq 1$, let $\x_{1,t}$ be a vector of covariates 
%revealed prior to the observation of $y_{1,t}$.  
To gauge the performance of a procedure that produces forecasts 
$\{\hat y_{1,t}, t= 1,2,\ldots\}$ given time horizon $T_1$, we consider the 
average forecast risk
$$
  R_T = \frac{1}{T}\sum_{t=1}^T\E(\hat y_{1,t} - y_{1,t})^2
$$
in our analyses. In this article, we consider a similar dynamic panel data 
model with autoregressive structure to that in \citet{blundell1998initial}. 
%without past time period covariate 
%information and with a single present time covariate.  
Our dynamic panel model includes an additional shock effect whose presence 
or absence is given by the binary variable $D_{i,t}$.  Our dynamic panel 
model is 
\begin{equation} \label{DPM}
  y_{i,t} = \eta_i + \alpha_iD_{i,t} + \phi_i y_{i,t-1} + \theta_i' \x_{i,t} + 
    \beta_i' \x_{i,t-1} + \varepsilon_{i,t},  
\end{equation}
$t = 1,\ldots,T_i$ and $i = 1,\ldots, n+1$, where $D_{i,t} = 1(t > T_i^*)$, 
$T_i^* < T_i$ and $\x_{i,t} \in \R^{p}$, $p \geq 1$.  We will consider 
the following random effects structure:  
%\begin{align*}
%  \eta_i &\overset{iid}{\sim} N(0, \sigma_\eta^2), 
%    \qquad i = 1,\ldots n+1, \\
%  \alpha_i &\overset{iid}{\sim} N(\mu_\alpha, \sigma_\alpha^2), 
%    \qquad i = 1,\ldots n+1, \\
%  \phi_i &\overset{iid}{\sim} U(-1,1), 
%    \qquad i = 1,\ldots n+1, \\
%  \theta_i &\overset{iid}{\sim} N(0, \Sigma_\theta), 
%    \qquad i = 1,\ldots n+1, \\
%  \beta_i &\overset{iid}{\sim} N(0, \Sigma_\beta), 
%    \qquad i = 1,\ldots n+1, \\
%  \varepsilon_{i,t} &\overset{iid}{\sim} N(0, \sigma^2), 
%    \qquad i = 1,\ldots n+1;\; t = 1, \ldots T, \\
%  \eta &\indep \alpha \indep \phi \indep \theta \indep \varepsilon;
%\end{align*}
\begin{align*}
  \eta_i &\overset{iid}{\sim} \eta,\; \text{where}\; \E(\eta) = 0,\; \Var(\eta) = \sigma_\eta^2, 
    \qquad i = 1,\ldots n+1, \\
  \alpha_i &\overset{iid}{\sim} \alpha,\; \text{where}\; \E(\alpha) = \mu_\alpha,\; 
    \Var(\alpha) = \sigma_\alpha^2, \qquad i = 1,\ldots n+1, \\
  \phi_i &\overset{iid}{\sim} \phi,\; \text{where}\; |\phi| < 1, 
    \qquad i = 1,\ldots n+1, \\
  \theta_i &\overset{iid}{\sim} \theta,\; \text{where}\; \E(\theta) = 0,\; 
    \Var(\theta) = \Sigma_\theta^2, \qquad i = 1,\ldots n+1, \\
  \beta_i &\overset{iid}{\sim} \beta,\; \text{where}\; \E(\beta) = 0,\; 
    \Var(\beta) = \Sigma_\beta^2, \qquad i = 1,\ldots n+1, \\    
  \varepsilon_{i,t} &\overset{iid}{\sim} N(0, \sigma^2), 
    \qquad t = 1, \ldots T_i,\; i = 1,\ldots n+1; \\
  \eta &\indep \alpha \indep \phi \indep \theta \indep \varepsilon.
\end{align*}

Throughout the rest of this article we show that the collection of 
disparate time series $\{y_{i,t}, t = 2,\ldots,T_i, i = 1,\ldots,n\}$ has 
the potential to improve the forecasts for $y_{1, t}$ when $t > T_1^*$ 
and no observations arre made for these time periods.


\section{Adjustment via disparate infromation in dynamic panel model}

Our first goal is to evaluate the forecast risk of competing forecasts which 
offer predicts for $y_{1, T_1^* + 1}$, the response observed after the first 
post shock time period for out ime series of interest.  
The difficulty in this forecast stems from not observing $\alpha_1$ and not 
having any readily infromation available to estimate it directly from 
model \eqref{DPM}.  We show that there is a balance between $\mu_\alpha$ 
and $\sigma_\alpha^2$ that allows us to lower the forecast risk for 
$y_{1, T_1^* + 1}$ by incorporating what is known about the other $\alpha_i$s 
when such information is available.

Conditional on all regression parameters, previous responses, and covariates, 
the response variable $y_{i,t}$ in model \eqref{DPM} has distribution 
$$
  y_{i,t} 
    \sim N(\eta_i + \alpha_iD_{i,t} + \phi_i y_{i,t-1} + \theta_i'\x_{i,t} 
      + \beta_i'\x_{i,t-1}, \sigma^2).
$$
All parameters in this model will be estimated with ordinary least squares 
(OLS) using historical data.  In particular, let $\hat{\alpha}_i$, 
$i = 2, \ldots, n+1$ be the OLS estimate of $\alpha_i$ and define the 
adjusted $\alpha$ plugin estimator for time series $i=1$ by,
\begin{equation} \label{adjusted}
  \hat{\alpha}_{\text{adj}} = \frac{1}{n}\sum_{i=2}^{n+1}\hat{\alpha}_i
\end{equation}
where the $\hat{\alpha}_i$s in \eqref{adjusted} are OLS estimators of all of 
the $\alpha_i$s.  We can use $\hat{\alpha}_{\text{adj}}$ as an estimator for 
the unknown $\alpha_1$ term for which no meaningful estimation information 
otherwise exists.  

It is important to note that the adjustment $\hat{\alpha}_{\text{adj}}$ 
is a consistent estimator of $\mu_\alpha$, it is not an unbiased 
estimator for $\alpha_1$, nor does it converge to $\alpha_1$.  
Despite these inferential shortcomings, adjustment of the forecast for 
$y_{1,T_1^*+1}$ through the addition of $\hat{\alpha}_{\text{adj}}$ has 
the potential to lower forecast risk in settings where $\mu_\alpha$ is 
large relative to $\sigma_\alpha$.  


We will consider the candidate 
forecasts: 
\begin{align*}
  &\text{Forecast 1}: \hat y_{1,T_1^*+1}^1 = \hat\eta_1 
    + \hat\phi_1 y_{1,T_1^*} + \hat\theta_1'\x_{1,T_1^*+1} 
    + \hat\beta_1'\x_{1,T_1^*}, \\
  &\text{Forecast 2}: \hat y_{1,T_1^*+1}^2 = \hat\eta_1 
    + \hat\phi_1 y_{1,T_1^*} + \hat\theta_1'\x_{1,T_1^*+1} 
    + \hat\beta_1'\x_{1,T_1^*} + \hat{\alpha}_{\text{adj}},
\end{align*}
where $\hat\eta_1$, $\hat\phi_1$, $\hat\theta_1$, and $\hat\beta_1$ are all 
OLS estimators of $\eta_1$, $\phi_1$, $\theta_1$, and $\beta_1$ respectively.  
The first forecast ignores the information about the distribution of 
$\alpha_1$ while the second forecast incorporates an estimate of $\mu_\alpha$ 
that is obtained from the other individual forecasts under study.  
Note that the two forecasts do not differ in their predictions for 
$y_{1,t}$, $t = 1,\ldots T_1^*$.  They only differ in predicting 
$y_{1,T_1^*+1}$.  We want to determine when either $\hat y_{1,T_1^*+1}^1$ or 
$\hat y_{1,T_1^*+1}^2$ minimizes the forecast risk for $\hat y_{1,T_1^*+1}$.  
Let $R_{T_1^*+1, k} = \E(\hat y_{1,T_1^*+1}^k - y_{1,T_1^*+1}^k)^2$, where 
$k = 1,2$ and define the parameter sets 
\begin{equation}
\begin{split}
  \Hist &= \{(\eta_i, \phi_i, \theta_i, \beta_i, \alpha_i, \x_{i,t}, y_{i,t}); 
    t = 1,\ldots,T_i, i = 2,\ldots,n+1\}, \\
  \Hist_1 &= \{(\eta_1, \phi_1, \theta_1, \beta_1, \alpha_1, 
    \x_{1,T_1^*+1}, \x_{1,t}, y_{1,t});  t = 1,\ldots,T_1^*\}.
\label{Hist}
\end{split}
\end{equation}
Proposition~\ref{prop:R1R2} states when the incorporation of disparate 
information improves forecasting.

\begin{prop}
We have that $R_{T_1^*+1, 2} < R_{T_1^*+1, 1}$ when 
$\Var(\hat{\alpha}_{\text{adj}}) < \mu_{\alpha}^2$.
\label{prop:R1R2}
\end{prop}

\begin{proof}
The forecast risk for $y_{1,T^*_1+1}^2$ is
\begin{align*}
  &R_{T_1^*+1, 2} = \E(\hat y_{1,T_1^*+1}^2 - y_{1,T_1^*+1}^2)^2 \\
    &\qquad= \E\left\{ \hat\eta_1 + \hat\phi_1 y_{1,T_1^*} 
      + \hat\theta_1'\x_{1,T_1^*+1} + \hat\beta_1'\x_{1,T_1^*} 
      + \hat{\alpha}_{\text{adj}}\right. \\
        &\qquad\qquad\left.- (\eta_1 + \phi_1 y_{1,T_1^*} + \theta_1'\x_{1,T_1^*+1} 
          + \beta_1'\x_{1,T_1^*} + \alpha_1 + \varepsilon_{1,T_1^*+1}) \right\}^2 \\
    &\qquad= \E\left\{ (\hat\eta_1 + \hat\phi_1 y_{1,T_1^*} + \hat\theta_1'\x_{1,T_1^*+1} 
      + \hat\beta_1'\x_{1,T_1^*} - \eta_1 - \phi_1 y_{1,T_1^*}\right. \\ 
        &\qquad\qquad\left.- \theta_1'\x_{1,T_1^*+1} - \beta_1'\x_{1,T_1^*} 
          - \alpha_1 - \varepsilon_{1,T_1^*+1}) + \hat{\alpha}_{\text{adj}} \right\}^2 \\      
    &\qquad= R_{T_1^*+1, 1} + \E(\hat{\alpha}_{\text{adj}}^2) - 2\E\left\{(\hat\eta_1 
      + \hat\phi_1 y_{1,T_1^*} + \hat\theta_1'\x_{1,T_1^*+1}\right. \\
        &\qquad\qquad\left. + \hat\beta_1'\x_{1,T_1^*} - \eta_1 - \phi_1 y_{1,T_1^*} 
          - \theta_1'\x_{1,T_1^*+1} - \beta_1'\x_{1,T_1^*} - \alpha_1 
          - \varepsilon_{1,T_1^*+1})\hat{\alpha}_{\text{adj}} \right\} \\
    &\qquad= R_{T_1^*+1, 1} + \E(\hat{\alpha}_{\text{adj}}^2) 
      - 2\E(\hat{\alpha}_{\text{adj}})\E(\alpha_1) \\
      &\qquad\qquad- 2\E\left\{(\hat\eta_1 + \hat\phi_1 y_{1,T_1^*} + \hat\theta_1'\x_{1,T_1^*+1} 
        + \hat\beta_1'\x_{1,T_1^*} - \eta_1 - \phi_1 y_{1,T_1^*} 
        - \theta_1'\x_{1,T_1^*+1} - \beta_1'\x_{1,T_1^*})\hat{\alpha}_{\text{adj}} \right\} \\
    &\qquad= R_{T_1^*+1, 1} + \Var(\hat{\alpha}_{\text{adj}}) - \mu_{\alpha}^2 \\
      &\qquad\qquad- 2\E\left(\hat\eta_1 + \hat\phi_1 y_{1,T_1^*} 
        + \hat\theta_1'\x_{1,T_1^*+1} + \hat\beta_1'\x_{1,T_1^*} - \eta_1 - \phi_1 y_{1,T_1^*} 
        - \theta_1'\x_{1,T_1^*+1} - \beta_1'\x_{1,T_1^*}\right)\mu_{\alpha},
\end{align*}
where 
$$
  \E(\hat{\alpha}_{\text{adj}}) = \E\left\{\E(\hat{\alpha}_{\text{adj}}| \Hist )\right\}
    = \E\left(\frac{1}{n}\sum_{i=2}^{n+1}\alpha_i\right) 
    = \mu_{\alpha},
$$
and $\Hist$ defined in \eqref{Hist}.  Observe that 
\begin{align*}
  &\E\left(\hat\eta_1 + \hat\phi_1 y_{1,T_1^*} + \hat\theta_1'\x_{1,T_1^*+1} 
    + \hat\beta_1'\x_{1,T_1^*} - \eta_1 - \phi_1 y_{1,T_1^*} 
    - \theta_1'\x_{1,T_1^*+1} - \beta_1'\x_{1,T_1^*}\right) \\
  &= \E\left\{\E\left(\hat\eta_1 + \hat\phi_1 y_{1,T_1^*} 
    + \hat\theta_1'\x_{1,T_1^*+1} + \hat\beta_1'\x_{1,T_1^*} - \eta_1 
    - \phi_1 y_{1,T_1^*} - \theta_1'\x_{1,T_1^*+1} 
    - \beta_1'\x_{1,T_1^*}\right)|\Hist_1\right\} \\
  &= 0.
\end{align*}
Therefore,
$$
  R_{T_1^*+1, 2} = R_{T_1^*+1, 1} + \Var(\hat{\alpha}_{\text{adj}}) - \mu_{\alpha}^2,
$$ 
and we have that $R_{T_1^*+1, 2} < R_{T_1^*+1, 1}$ when 
$\Var(\hat{\alpha}_{\text{adj}}) < \mu_{\alpha}^2$.
\end{proof}



When we estimate all of the parameters via OLS we can write 
$\Var(\hat{\alpha}_{\text{adj}})$ as
\begin{equation}
\begin{split}
  &\Var(\hat{\alpha}_{\text{adj}}) = \E\left\{\Var(\hat{\alpha}_{\text{adj}}|\Hist)\right\} 
    + \Var\left\{\E(\hat{\alpha}_{\text{adj}}|\Hist)\right\} \\
    %= \E\left\{\Var(\hat{\alpha}_{\text{adj}}|\Hist)\right\} 
    %+ \frac{\sigma_{\alpha}^2}{n} \\
  &\qquad= \frac{1}{n^2} \sum_{i=2}^{n+1} \E\left\{\Var(\hat{\alpha}_i|\Hist)\right\} 
    + \frac{\sigma_{\alpha}^2}{n}. %\\
%  &\qquad= \frac{1}{n^2(T-1)}\sum_{i=2}^{n+1} 
%    \E\left\{\frac{s_{e,i}^2}{(1-R^2_i)s_{\alpha_i}^2}\right\} 
%      + \frac{\sigma_{\alpha}^2}{n},
\label{reg}
\end{split}
\end{equation}
%where $s_{e,i}^2$ is the estimated variance of model $i$, $R^2_{\alpha_i}$ is 
%the multiple $R^2$ obtained from regressing the shock indicator $D$ on the 
%other regressors, and $s_{\alpha_i}^2$ is... .
Propostion~\ref{prop:R1R2} states that Forecast 2 has lower forecast risk 
than Forecast 1 when  
$
  \Var(\hat{\alpha}_{\text{adj}}) 
    %- 2\E\left(\hat\eta_1 + \hat\phi_1 y_{1,T^*} + \hat\theta_1'\x_{1,T^*+1} 
    %+ \hat\beta_1'\x_{1,T^*} - \eta_1 - \phi_1 y_{1,T^*} - \theta_1'\x_{1,T^*+1}
    %- \beta_1'\x_{1,T^*}\right)\mu_{\alpha} 
    < \mu_{\alpha}^2.
$
Combining this result with \eqref{reg}, we see that Forecast 2 has lower 
forecast risk than Forecast 1 when 
%$$
%  \frac{1}{n^2(T-1)}\sum_{i=2}^{n+1} \E\left\{\frac{s_{e,j}^2}{(1-R^2_i)s_{\alpha_i}^2}\right\} 
%    + \frac{\sigma_{\alpha}^2}{n} < \mu_{\alpha}^2.
%$$
$$
  \frac{1}{n^2} \sum_{i=2}^{n+1} \E\left\{\Var(\hat{\alpha}_i|\Hist)\right\} 
    + \frac{\sigma_{\alpha}^2}{n} < \mu_{\alpha}^2.
$$
Forecast 2 is preferable to Forecast 1 asymptotically in both $T$ and $n$ 
whenever $\mu_{\alpha} \neq 0$. In finite samples, Forecast 2 is preferable to 
Forecast 1 when the $\mu_{\alpha}$ is large relative to its variability and 
overall regression variability.  












\bibliographystyle{plainnat}
\bibliography{synthetic-prediction-notes}


\end{document}

