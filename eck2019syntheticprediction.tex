\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{natbib}

\usepackage{geometry}
\usepackage[usenames]{color}
\geometry{margin=1in}

\newcommand{\w}{\textbf{w}}
\newcommand{\x}{\textbf{x}}
\newcommand{\X}{\textbf{X}}
\newcommand{\Y}{\textbf{Y}}
\newcommand{\Hist}{\mathcal{H}}

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\indep}{\perp\!\!\!\perp}

\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\Var}{Var}

\newcommand\red[1]{{\color{red}#1}}

\title{Minimizing post shock forecasting error using disparate information}
\author{Daniel J. Eck}
\date{May 2019}

\begin{document}


\maketitle
\begin{abstract}
    We seek to develop a forecasting methodology for time series data that is 
    thought to have undergone a shock which has origins that have not been 
    previously observed.  We still can provide credible forecasts for a time 
    series in the presence of such systematic shocks by drawing from disparate 
    time series that have undergone similar shocks for which post-shock 
    outcome data is recorded.  These disparate time series are assumed to have 
    mechanistic similarities to the time series under study but are otherwise 
    independent (Granger noncausal).  The inferential goal of our forecasting 
    methodology is to supplement observed time series data with post-shock 
    data from the disparate time series in order to minimize average forecast 
    risk. 
\end{abstract}


\section{Setting}
Suppose that an analyst is interested in forecasting a real-valued time series 
$y_1, y_2, \ldots$.  Given each time point $t \geq 1$, let $\x_t$ be the 
(possibly multivariate) information variable vector revealed prior to the 
observation of $y_t$.  To gauge the performance of a procedure that produces forecasts 
$\{\hat y_t, t= 1,2,\ldots\}$ given time horizon $T$, we consider the average 
forecast risk
$$
  R_T = \frac{1}{T}\sum_{t=1}^T\E(y_t - \hat y_t)^2
$$
in our analyses.


\section{Dynamic panel model}
\label{sec:dpm}

To fix ideas we consider a similar dynamic panel data model with autoregressive 
structure in \citet{blundell1998initial} %without past time period covariate 
%information and with a single present time covariate.  
We consider an additional shock effect whose presence is given by the binary 
variable $D_{i,t}$.  Our dynamic panel model is  
\begin{equation} \label{DPM}
  y_{i,t} = \eta_i + \alpha_iD_{i,t} + \phi_i y_{i,t-1} + \theta_i' \x_{i,t} + 
    \beta_i' \x_{i,t-1} + \varepsilon_{i,t},  
\end{equation}
where $i = 1,\ldots,J+1$ and $t = 1,\ldots,T$ and $D_{i,t} = 1(t > T_i^*)$, 
$T_i^* < T$.  We will consider a simple random effects structure where,  
%\begin{align*}
%  \eta_i &\overset{iid}{\sim} N(0, \sigma_\eta^2), 
%    \qquad i = 1,\ldots J+1, \\
%  \alpha_i &\overset{iid}{\sim} N(\mu_\alpha, \sigma_\alpha^2), 
%    \qquad i = 1,\ldots J+1, \\
%  \phi_i &\overset{iid}{\sim} U(-1,1), 
%    \qquad i = 1,\ldots J+1, \\
%  \theta_i &\overset{iid}{\sim} N(0, \Sigma_\theta), 
%    \qquad i = 1,\ldots J+1, \\
%  \beta_i &\overset{iid}{\sim} N(0, \Sigma_\beta), 
%    \qquad i = 1,\ldots J+1, \\
%  \varepsilon_{i,t} &\overset{iid}{\sim} N(0, \sigma^2), 
%    \qquad i = 1,\ldots J+1;\; t = 1, \ldots T, \\
%  \eta &\indep \alpha \indep \phi \indep \theta \indep \varepsilon;
%\end{align*}
\begin{align*}
  \eta_i &\overset{iid}{\sim} \eta,\; \text{where}\; \E(\eta) = 0,\; \Var(\eta) = \sigma_\eta^2, 
    \qquad i = 1,\ldots J+1, \\
  \alpha_i &\overset{iid}{\sim} \alpha,\; \text{where}\; \E(\alpha) = \mu_\alpha,\; 
    \Var(\alpha) = \sigma_\alpha^2, \qquad i = 1,\ldots J+1, \\
  \phi_i &\overset{iid}{\sim} \phi,\; \text{where}\; |\phi| < 1, 
    \qquad i = 1,\ldots J+1, \\
  \theta_i &\overset{iid}{\sim} \theta,\; \text{where}\; \E(\theta) = 0,\; 
    \Var(\theta) = \Sigma_\theta^2, \qquad i = 1,\ldots J+1, \\
  \beta_i &\overset{iid}{\sim} \beta,\; \text{where}\; \E(\beta) = 0,\; 
    \Var(\beta) = \Sigma_\beta^2, \qquad i = 1,\ldots J+1, \\    
  \varepsilon_{i,t} &\overset{iid}{\sim} N(0, \sigma^2), 
    \qquad i = 1,\ldots J+1;\; t = 1, \ldots T, \\
  \eta &\indep \alpha \indep \phi \indep \theta \indep \varepsilon;
\end{align*}

Our first goal is to evaluate the forecast risk of competing forecasts which 
offer predicts for $y_{1, T_1^* + 1}$, the response observed after the first 
post shock time period for subject 1.  The difficulty in this forecast stems 
from not observing $\alpha_1$ and not having any readily infromation available 
to estimate it directly.  We show that there is a balance between $\mu_\alpha$ 
and $\sigma_\alpha^2$ that allows us to lower the forecast risk for 
$y_{1, T_1^* + 1}$ by incorporating what is known about the other $\alpha_i$s 
when such information is available.

Conditional on all regression parameters, previous responses, and covariates, 
model \eqref{DPM} has distribution 
$$
  y_{i,t} 
    \sim N(\eta_i + \alpha_iD_{i,t} + \phi_i y_{i,t-1} + \theta_i'\x_{i,t} 
      + \beta_i'\x_{i,t-1}, \sigma^2).
$$
All parameters in this model will be estimated with OLS using historical data. 
In particular, let $\hat{\alpha}_i$, $i = 2, \ldots, J+1$ be the OLS estimate 
of $\alpha_i$ and define the adjusted $\alpha$ plugin estimator for time 
series $i=1$ by,
\begin{equation} \label{adjusted}
  \hat{\alpha}_{\text{adj}} = \frac{1}{J}\sum_{i=2}^{J+1}\hat{\alpha}_i
\end{equation}
where the $\hat{\alpha}_i$s are MLEs of all of the $\alpha_i$s.  
We can use $\hat{\alpha}_{\text{adj}}$ as an estimator for the unknown 
$\alpha_1$ term for which no meaningful estimation information otherwise 
exists. 


Consider the candidate forecasts: 
\begin{align*}
  &\text{Forecast 1}: \hat y_{1,T_1^*+1}^1 = \hat\eta_1 
    + \hat\phi_1 y_{1,T_1^*} + \hat\theta_1'\x_{1,T_1^*+1} 
    + \hat\beta_1'\x_{1,T_1^*}, \\
  &\text{Forecast 2}: \hat y_{1,T_1^*+1}^2 = \hat\eta_1 
    + \hat\phi_1 y_{1,T_1^*} + \hat\theta_1'\x_{1,T_1^*+1} 
    + \hat\beta_1'\x_{1,T_1^*} + \hat{\alpha}_{\text{adj}},
\end{align*}
where $\hat\eta_1$, $\hat\phi_1$, $\hat\theta_1$, and $\hat\beta_1$ are MLEs 
of $\eta_1$, $\phi_1$, $\theta_1$, and $\beta_1$ respectively.  
The first forecast ignores the information about the distribution of 
$\alpha_1$ while the second forecast incorporates an estimate of $\mu_\alpha$ 
that is obtained from the other individual forecasts under study.  
Note that the two forecasts do not differ in their predictions for 
$y_{1,t}$, $t = 1,\ldots T_1^*$.  They only differ in predicting 
$y_{1,T_1^*+1}$.  We want to determine when either $\hat y_{1,T_1^*+1}^1$ or 
$\hat y_{1,T_1^*+1}^2$ minimizes the forecast risk for $\hat y_{1,T_1^*+1}$.  
Let $R_{T_1^*+1, k} = \E(\hat y_{1,T_1^*+1}^k - y_{1,T_1^*+1}^k)^2$, 
where $k = 1,2$.  \\

The forecast risk for $y_{1,T^*_1+1}^2$ is: 
\begin{align*}
  &R_{T_1^*+1, 2} = \E(\hat y_{1,T_1^*+1}^2 - y_{1,T_1^*+1}^2)^2 \\
    &\qquad= \E\left\{ \hat\eta_1 + \hat\phi_1 y_{1,T_1^*} 
      + \hat\theta_1'\x_{1,T_1^*+1} + \hat\beta_1'\x_{1,T_1^*} 
      + \hat{\alpha}_{\text{adj}}\right. \\
        &\qquad\qquad\left.- (\eta_1 + \phi_1 y_{1,T_1^*} + \theta_1'\x_{1,T_1^*+1} 
          + \beta_1'\x_{1,T_1^*} + \alpha_1 + \varepsilon_{1,T_1^*+1}) \right\}^2 \\
    &\qquad= \E\left\{ (\hat\eta_1 + \hat\phi_1 y_{1,T_1^*} + \hat\theta_1'\x_{1,T_1^*+1} 
      + \hat\beta_1'\x_{1,T_1^*} - \eta_1 - \phi_1 y_{1,T_1^*}\right. \\ 
        &\qquad\qquad\left.- \theta_1'\x_{1,T_1^*+1} - \beta_1'\x_{1,T_1^*} 
          - \alpha_1 - \varepsilon_{1,T_1^*+1}) + \hat{\alpha}_{\text{adj}} \right\}^2 \\      
    &\qquad= R_{T_1^*+1, 1} + \E(\hat{\alpha}_{\text{adj}}^2) - 2\E\left\{(\hat\eta_1 
      + \hat\phi_1 y_{1,T_1^*} + \hat\theta_1'\x_{1,T_1^*+1}\right. \\
        &\qquad\qquad\left. + \hat\beta_1'\x_{1,T_1^*} - \eta_1 - \phi_1 y_{1,T_1^*} 
          - \theta_1'\x_{1,T_1^*+1} - \beta_1'\x_{1,T_1^*} - \alpha_1 
          - \varepsilon_{1,T_1^*+1})\hat{\alpha}_{\text{adj}} \right\} \\
    &\qquad= R_{T_1^*+1, 1} + \E(\hat{\alpha}_{\text{adj}}^2) 
      - 2\E(\hat{\alpha}_{\text{adj}})\E(\alpha_1) \\
      &\qquad\qquad- 2\E\left\{(\hat\eta_1 + \hat\phi_1 y_{1,T_1^*} + \hat\theta_1'\x_{1,T_1^*+1} 
        + \hat\beta_1'\x_{1,T_1^*} - \eta_1 - \phi_1 y_{1,T_1^*} 
        - \theta_1'\x_{1,T_1^*+1} - \beta_1'\x_{1,T_1^*})\hat{\alpha}_{\text{adj}} \right\} \\
    &\qquad= R_{T_1^*+1, 1} + \Var(\hat{\alpha}_{\text{adj}}) - \mu_{\alpha}^2 \\
      &\qquad\qquad- 2\E\left(\hat\eta_1 + \hat\phi_1 y_{1,T_1^*} 
        + \hat\theta_1'\x_{1,T_1^*+1} + \hat\beta_1'\x_{1,T_1^*} - \eta_1 - \phi_1 y_{1,T_1^*} 
        - \theta_1'\x_{1,T_1^*+1} - \beta_1'\x_{1,T_1^*}\right)\mu_{\alpha},
\end{align*}
where 
$$
  \E(\hat{\alpha}_{\text{adj}}) = \E\left\{\E(\hat{\alpha}_{\text{adj}}| \Hist )\right\}
    = \E\left(\frac{1}{J}\sum_{i=2}^{J+1}\alpha_i\right) 
    = \mu_{\alpha},
$$
and 
$$
  \Hist = \{(\eta_i, \phi_i, \theta_i, \beta_i, \alpha_i, \x_{i,t}, y_{i,t}); 
    t = 1,\ldots,T_i, i = 2,\ldots,J+1\}.
$$
Define
$$
  \Hist_1 = \{\eta_1, \phi_1, \theta_1, \beta_1, \alpha_1, 
    \x_{1,T_1^*+1}, (\x_{1,t}, y_{1,t});  t = 1,\ldots,T_1^*\},
$$
and observe that 
\begin{align*}
  &\E\left(\hat\eta_1 + \hat\phi_1 y_{1,T_1^*} + \hat\theta_1'\x_{1,T_1^*+1} 
    + \hat\beta_1'\x_{1,T_1^*} - \eta_1 - \phi_1 y_{1,T_1^*} 
    - \theta_1'\x_{1,T_1^*+1} - \beta_1'\x_{1,T_1^*}\right) \\
  &= \E\left\{\E\left(\hat\eta_1 + \hat\phi_1 y_{1,T_1^*} 
    + \hat\theta_1'\x_{1,T_1^*+1} + \hat\beta_1'\x_{1,T_1^*} - \eta_1 
    - \phi_1 y_{1,T_1^*} - \theta_1'\x_{1,T_1^*+1} 
    - \beta_1'\x_{1,T_1^*}\right)|\Hist_1\right\} \\
  &= 0,
\end{align*}
and that 
\begin{align*}
  &\Var(\hat{\alpha}_{\text{adj}}) = \E\left\{\Var(\hat{\alpha}_{\text{adj}}|\Hist)\right\} 
    + \Var\left\{\E(\hat{\alpha}_{\text{adj}}|\Hist)\right\} \\
    %= \E\left\{\Var(\hat{\alpha}_{\text{adj}}|\Hist)\right\} 
    %+ \frac{\sigma_{\alpha}^2}{J} \\
  &\qquad= \frac{1}{J^2} \sum_{i=2}^{J+1} \E\left\{\Var(\hat{\alpha}_i|\Hist)\right\} 
    + \frac{\sigma_{\alpha}^2}{J} \\
  &\qquad= \frac{1}{J^2(T-1)}\sum_{i=2}^{J+1} 
    \E\left\{\frac{s_{e,i}^2}{(1-R^2_i)s_{\alpha_i}^2}\right\} 
      + \frac{\sigma_{\alpha}^2}{J},
\end{align*}
where $s_{e,i}^2$ is the estimated variance of model $i$, $R^2_{\alpha_i}$ is 
the multiple $R^2$ obtained from regressing the shock indicator $D$ on the 
other regressors, and $s_{\alpha_i}^2$ is... .

Forecast 2 has lower forecast risk than Forecast 1 when,  
$
  \Var(\hat{\alpha}_{\text{adj}}) 
    %- 2\E\left(\hat\eta_1 + \hat\phi_1 y_{1,T^*} + \hat\theta_1'\x_{1,T^*+1} 
    %+ \hat\beta_1'\x_{1,T^*} - \eta_1 - \phi_1 y_{1,T^*} - \theta_1'\x_{1,T^*+1}
    %- \beta_1'\x_{1,T^*}\right)\mu_{\alpha} 
    < \mu_{\alpha}^2.
$
Putting everything together, we see that Forecast 2 has lower forecast risk 
than Forecast 1 when 
$$
  \frac{1}{J^2(T-1)}\sum_{i=2}^{J+1} \E\left\{\frac{s_{e,j}^2}{(1-R^2_i)s_{\alpha_i}^2}\right\} 
    + \frac{\sigma_{\alpha}^2}{J} < \mu_{\alpha}^2.
$$
Forecast 2 is preferable to Forecast 1 asymptotically in both $T$ and $J$ 
whenever $\mu_{\alpha} \neq 0$. In finite samples, Forecast 2 is preferable to 
Forecast 1 when the $\mu_{\alpha}$ is large relative to its variability and 
overall regression variability.  









\bibliographystyle{plainnat}
\bibliography{synthetic-prediction-notes}


\end{document}

