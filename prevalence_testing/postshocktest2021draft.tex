\documentclass[11pt]{article}

% use packages
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amscd}
\usepackage{amssymb}
\usepackage{natbib}
\usepackage{url}

\usepackage{graphicx}
%\usepackage{mathtools}
\usepackage{enumitem}
\usepackage{authblk}
\usepackage{bm}
\usepackage[usenames]{color}
\usepackage{hyperref}

\usepackage{caption}
\usepackage{float}
\usepackage[caption = false]{subfig}
\usepackage{tikz}
\usepackage{multirow}
\usepackage[linesnumbered, ruled,vlined]{algorithm2e}
\usepackage{pdflscape}

% margin setup
\usepackage{geometry}
\geometry{margin=0.8in}


% function definition
\newcommand{\R}{\mathbb{R}}
\newcommand{\w}{\textbf{w}}
\newcommand{\x}{\textbf{x}}
\newcommand{\dbf}{\textbf{d}}
\newcommand{\y}{\textbf{y}}
\newcommand{\X}{\textbf{X}}
\newcommand{\Y}{\textbf{Y}}
\newcommand{\L}{\textbf{L}}
\newcommand{\Hist}{\mathcal{H}}
\def\mbf#1{\mathbf{#1}} % bold but not italic
\def\ind#1{\mathrm{1}(#1)} % indicator function
\newcommand{\simiid}{\stackrel{iid}{\sim}} %[] IID 
\def\where{\text{ where }} % where
\newcommand{\indep}{\perp \!\!\! \perp } % independent symbols
\def\cov#1#2{\mathrm{Cov}(#1, #2)} % covariance 
\def\mrm#1{\mathrm{#1}} % remove math
\newcommand{\reals}{\mathbb{R}} % Real number symbol
\def\t#1{\tilde{#1}} % tilde
\def\normal#1#2{\mathcal{N}(#1,#2)} % normal
\def\mbi#1{\boldsymbol{#1}} % Bold and italic (math bold italic)
\def\v#1{\mbi{#1}} % Vector notation
\def\mc#1{\mathcal{#1}} % mathical
\DeclareMathOperator*{\argmax}{arg\,max} % arg max
\DeclareMathOperator*{\argmin}{arg\,min} % arg min
\def\E{\mathbb{E}} % Expectation symbol
\def\mc#1{\mathcal{#1}}
\def\var#1{\mathrm{Var}(#1)} % Variance symbol
\def\checkmark{\tikz\fill[scale=0.4](0,.35) -- (.25,0) -- (1,.7) -- (.25,.15) -- cycle;} % checkmark
\newcommand\red[1]{{\color{red}#1}}
\def\bs#1{\boldsymbol{#1}}
\def\P{\mathbb{P}}

\newcommand{\ceil}[1]{\lceil #1 \rceil}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert} % A norm with 1 argument
\DeclareMathOperator{\Var}{Var} % Variance symbol

\newtheorem{cor}{Corollary}
\newtheorem{lem}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{defn}{Definition}
\newtheorem{prop}{Proposition}
\theoremstyle{definition}
\newtheorem{remark}{Remark}
\hypersetup{
  linkcolor  = blue,
  citecolor  = blue,
  urlcolor   = blue,
  colorlinks = true,
} % color setup

% proof to proposition 
\newenvironment{proof-of-proposition}[1][{}]{\noindent{\bf
    Proof of Proposition {#1}}
  \hspace*{.5em}}{\qed\bigskip\\}
% general proof of corollary
  \newenvironment{proof-of-corollary}[1][{}]{\noindent{\bf
    Proof of Corollary {#1}}
  \hspace*{.5em}}{\qed\bigskip\\}
% general proof of lemma
  \newenvironment{proof-of-lemma}[1][{}]{\noindent{\bf
    Proof of Lemma {#1}}
  \hspace*{.5em}}{\qed\bigskip\\}

\allowdisplaybreaks

\title{Prospective testing for the prevalence or transience of a shock effect before it occurs}
\author{}
\date{}

\begin{document}

\maketitle

%We develop a forecasting methodology for providing credible forecasts for time series that have recently undergone a shock. We achieve this by borrowing knowledge from other time series that have undergone similar shocks for which post-shock outcomes are observed. Three shock effect estimators are motivated with the aim of minimizing average forecast risk. We propose risk-reduction propositions that provide conditions that establish when our methodology works. Bootstrap and leave-one-out cross validation procedures are provided to prospectively assess the performance of our methodology. Several simulated data examples, and two real data examples of forecasting Conoco Phillips and Apple stock price are provided for verification and illustration

\begin{abstract}
We develop a hypothesis testing procedure to prospectively test whether an anticipated shock is likely to be transient or permanent over a time horizon. We achieve this by borrowing knowledge from other time series that have undergone similar shocks for which post-shock outcomes are observed. These additional time series form a donor pool. 
For each of the time series in the donor pool we calculate a p-value corresponding to a hypothesis test on the relevance of the inclusion of shock-effect information in predicting the response over the time horizon.
These p-values are then combined to form an aggregated p-value which guides one decision in determining whether the shock effect for the time series under study is expected to be prevalent or transient. This p-value can be computed before the shock-effect is observed in the time series under study provided one can form a suitable donor pool. Several simulated data examples, and two real data examples of forecasting Conoco Phillips stock price and .... are provided for verification and illustration.
\end{abstract}


\section{Introduction}

%We provide forecasting adjustment techniques with the goal of lowering overall forecast error when the time series under study has undergone a structural shock.
We provide forecasting methodology for assessing the lingering effect of an anticipated structural shock to a time series under study. We focus on the setting in which a structural shock has occurred and one desires a prediction for the post-shock response over a set time horizon $H$. Specific interest is in determining whether the shock is expected to be permanent or transient over $H$. Standard forecasting methods may not yield any guidance on the post-shock trajectories \citep{baumeister2014real}. 
This is a general problem that has many real life applications. For example, one may acquire terrible or great news about a company and desire to determine whether that news is bound to impact the stock price of that company over a relevant time period.  Companies may be interested in forecasting the demand of their products after they were involved in a brand crisis, but they only have recent sales data from pre-crises times. %Policy makers, economists, and citizens alike may be interested in determining whether inflation will dissipate or persist for the foreseeable future
All is not lost in this forecasting setting, one may be able to supplement the present forecast with past data borrowed from other time series which contain post-shock trajectories arising from materially similar structural shocks.

The core idea of our methodology is to sensibly aggregate similar past realized shock effects which arose from other time series, and then incorporate the aggregated shock effect estimator into the present forecast.

Our testing method embraces ideas from 
forecast aggregation in the post-shock setting \citep{lin2021minimizing}, 
forecast comparison \citep{diebold1995comparing, quaedvlieg2021multi}, 
p-value combination, 
conditional forecasting \citep{baumeister2014real, kilian2017structural}, 
time series pooling using cross-sectional panel data \citep{ramaswamy1993empirical, pesaran1999pooled, hoogstrate2000pooling, baltagi2008forecasting, koop2012forecasting, liu2020forecasting},
forecasting with judgement and models \citep{svensson2005monetary, monti2008forecast}, 
synthetic control methodology \citep{abadie2010synthetic, agarwal2020two},  
expectation shocks \citep{croushore2006data, baumeister2014general, clements2019measuring}.




\section{Setting}

We will suppose that a researcher has multivariate time series data $\y_{i,t}$, $t = 1, \ldots,  T_i$ and $i = 1, \ldots, n+1$. We let $\y_{i,t} = (y_{i,t}$, $\x_{i,t}$) where $y_{i,t}$ is a scalar response and $\x_{i,t}$ is a vector of covariates that are revealed to the analyst prior to the observation of $y_{1,t}$.  Suppose that the analyst is interested in forecasting $y_{1,t}$, the first time series in the collection. 
We will suppose that each time series $\y_{i,t}$ undergoes a shock at time $T^*_i \leq T_i + 1$. To define an interesting setting, we will suppose that $T^*_1 = T_1 + 1$, and $1 < T^*_i < T_i + 1$ for $i \geq 2$. 
We will suppose that $\x_{i,t=T^*_i}$ is observed before the shock takes effect on $y_{i,t=T^*_i}$.

We are interested in point forecasts $y_{i,t}^h$ at multiple horizons, $h = 1, \ldots, H$ with the aim of determining whether the shock has an effect on $y_{i,t}^h$.
\cite{quaedvlieg2021multi} provided a methodology for comparing forecasts jointly across all horizons of a forecast path, $h = 1,\ldots, H$. In our post-shock setting, we want to compare the forecasts 
$$
  \hat y^{i,h}_{1,t} \; \text{and} \; \hat y^{2,h}_{i,t}
$$
where $y^{1,h}_{i,t}$ is the forecast for $y_{i,t}$ that accounts for the yet-to-be observed structural shock and is based on the information set $\mathcal{F}_{t-h}$, and $\hat y^{2,h}_{i,t}$ is defined similarly for the forecast that does not include any shock effect information. We will compare these forecasts in terms of their loss differential
$$
  \dbf_{i,t} = \L_{i,t,1} - \L_{i,t,2},
$$
where $L_{i,t,j} \in \R^H$ has elements $L^h(y_{i,t}$, $\hat y_{i,t}^{h,j})$, $j = 1,2$, and $L$ is a loss function. Hypothesis tests in \cite{quaedvlieg2021multi} are with respect to $E(\dbf_{i,t}) = \mbf\mu_{i,t}$. Conditions for these tests require conditions of \cite{giacomini2006tests}. 

We will be interested in $\mathbf{\mu}_i = \lim_{T\to\infty}\frac{1}{T}\sum_{i=1}^T \mathbf{\mu}_{i,t}$.



\vspace*{0.5cm}\noindent\textbf{Note}: We need more formality for constructing $\hat y^{1,h}_{1,t}$. We could use the forecasts in \cite{lin2021minimizing} and then consider $h$-ahead methods after adjusting for the shock. Or we could consider aggregation approaches which average all post-shock responses of the series in the donor pool. 
\vspace*{0.5cm}

We will consider the average superior predictive ability (aSPA) to assess whether or not a shock is permanent or transitory. The aSPA investigates forecast comparisons based on their weighted average loss difference
$$
  \mu^{(AVG)} = \textbf{w}^T\mathbf{\mu} = \sum_{h=1}^H w_h \mu^h
$$
with weights $\textbf{w}$ that sum to one. Note that aSPA requires the user to take a stand on the relative importance of under-performance at one horizon against out-performance at another, and note that it is likely that $\mu^h > 0$ for $h$ closer to 1 since the user expects that a structural shock will occur and the structural shock is taken into account by forecast 1. 





\subsection{Model setup}
\label{modelsetup}

\noindent\textbf{Note}: We need to update the modeling setup. We should present a general modeling class which includes both the decay model and the permanent shift model.

\vspace{0.5cm}\noindent\textbf{Possible modeling approach}

\vspace{0.5cm} We now describe the assumed autoregressive models with random effects for which post-shock aggregated estimators are provided. The model $\mc{M}$ is defined as
\begin{align}
\mc{M} \colon \begin{array}{l}
  y_{i,t} =\eta_i + \sum_{j=1}^{q_1}\phi_{i,j}y_{i, t-j} + \sum_{j=0}^{q_2-1}\theta_{i,j+1}'\mbf{x}_{i,t-j} + \alpha_i D_{i,t}f(t) + \varepsilon_{i,t},\\[.2cm]
  %\; f(\mc{F}_{i,t-1},\x_{i,t-1},\alpha_i) =  \\[.2cm] %+ \sum_{j=1}^{q_3}\t\phi_{i,j}y_{i, t-j} + \sum_{j=0}^{q_4-1}\t\theta_{i,j+1}'\mbf{x}_{i,t-j}, \\[.2cm]
  \; \alpha_i = \mu_{\alpha} + \delta_i'\mbf{x}_{i, T_i^*+1} + \t{\varepsilon}_{i},
  %\sum_{j=1}^{q_3}\delta_{i,j}'\mbf{x}_{i, T_i^*-j+1}+ \t{\varepsilon}_{i}, 
\end{array}\label{model}
\end{align}
where $D_{i,t} = I(t \geq T_i^* + 1)$, $I(\cdot)$ is the indicator function, $\x_{i,t} \in \R^{p}$ are fixed with $p \geq 1$, $f(t)$ is a bounded continuous function which does not cross zero and $\lim_{t\to\infty}g(t) = a \in \R$. Let 
$\mathbf{\phi}_i = (\phi_{i,1},\ldots,\phi_{i,q_1})'$, 
$\mathbf{\theta}_i = (\theta_{i,1},\ldots,\theta_{i,q_2})'$, 
%$\tilde{\mathbf{\phi}}_i = (\t\phi_{i,1},\ldots,\t\phi_{i,q_3})'$, 
%$\tilde{\mathbf{\theta}}_i = (\t\theta_{i,1},\ldots,\t\theta_{i,q_4})'$, 
$\mathbf{\delta}_i = (\delta_{i,1},\ldots,\delta_{i,q_3})'$, 
and suppose that the regression coefficients in \eqref{model} have the following random effects structure:
\begin{align*}
  \eta_i &\simiid \mc{F}_{\eta} \text{ with }  \; \mrm{E}_{\mc{F}_{\eta}}(\eta_i) = 0, \mrm{Var}_{\mc{F}_{\eta}}(\eta_i)  = \sigma^2_{\eta}, \\
  \mathbf{\phi}_i &\simiid \mc{F}_{\mathbf{\phi}} \text{ where } |\phi_{i,j}| < 1, \\
  \mathbf{\theta}_i &\simiid \mc{F}_{\mathbf{\theta}} \text{ with }  \; \mrm{E}_{\mc{F}_{\mathbf{\theta}}}(\theta_i) = \mu_{\mathbf{\theta}}, \mrm{Var}_{\mc{F}_{\mathbf{\theta}}}(\mathbf{\theta}_i)  = \Sigma^2_{\mathbf{\theta}}, \\
  %\tilde{\mathbf{\phi}}_i &\simiid \mc{F}_{\tilde{\mathbf{\phi}}} \text{ where } |\t\phi_{i,j}| < 1, \\
  %\tilde{\mathbf{\theta}}_i &\simiid \mc{F}_{\tilde{\mathbf{\theta}}} \text{ with }  \; \mrm{E}_{\mc{F}_{\tilde{\mathbf{\theta}}}}(\theta_i) = \mu_{\tilde{\mathbf{\theta}}}, \mrm{Var}_{\mc{F}_{\tilde{\mathbf{\theta}}}}(\tilde{\mathbf{\theta}}_i)  = \Sigma^2_{\tilde{\mathbf{\theta}}}, \\  
  \mathbf{\delta}_i &\simiid  \mc{F}_{\mathbf{\delta}} \text{ with } \mrm{E}_{\mc{F}_{\mathbf{\delta}}}(\mathbf{\delta}_i)=\mu_{\mathbf{\delta}}, \mrm{Var}_{\mc{F}_{\mathbf{\delta}}}(\mathbf{\delta}_i)=\Sigma_{\mathbf{\delta}}, \\
\varepsilon_{i,t} & \simiid  \mc{F}_{\varepsilon_i} \text{ with }  \; \mrm{E}_{\mc{F}_{\varepsilon_i}}(\varepsilon_{i,t}) = 0, \mrm{Var}_{\mc{F}_{\varepsilon_i}}(\varepsilon_{i,t})  = \sigma^2_i,  \\
\t{\varepsilon}_{i} &\simiid  \mc{F}_{\t{\varepsilon}} \text{ with }\mrm{E}_{\mc{F}_{\t{\varepsilon}}}(\t{\varepsilon}_{i})=0, \mrm{Var}_{\mc{F}_{\t{\varepsilon}}}(\t{\varepsilon}_{i})=\sigma^2_{\alpha}, \\
&\eta_i \indep \mathbf{\phi}_i \indep \mathbf{\theta}_i \indep 
%\tilde{\mathbf{\phi}}_i \indep \tilde{\mathbf{\theta}}_i \indep 
\mathbf{\delta}_i \indep \varepsilon_{i,t} \indep \tilde\varepsilon_{i,t}.
\end{align*}
The model \eqref{model} with the above random effects structure is a generalization of both model formulations in \cite{lin2021minimizing}. \textbf{Need to carefully show}. In this formulation $f(t)$ represents either a permanent or transient structural change to the time series that results from the shock.

We further define the parameter sets
\begin{align}
\begin{array}{l}
 \;\, \Theta = \{(\eta_i, \mathbf{\phi}_i, \mathbf{\theta}_i, \mathbf{\delta}_i, \alpha_i, \mbf{x}_{i,t}, y_{i,t-1})\colon    t= 1, \ldots, T_i, i = 2, \ldots, n +1\} \\
   \Theta_1 = \{(\eta_i, \mathbf{\phi}_i, \mathbf{\theta}_i, \mathbf{\delta}_i, \alpha_i, \mbf{x}_{i,t}, y_{i,t-1})\colon  t= 1, \ldots, T_i, i = 1\}
\end{array}\label{parameter} 
\end{align}


\vspace*{0.5cm}\noindent\textbf{Alternative model formulation} 

\vspace*{0.5cm} We now describe the assumed autoregressive models with random effects for which post-shock aggregated estimators are provided. The model $\mc{M}$ is defined as
\begin{align}
\mc{M} \colon \begin{array}{l}
  y_{i,t} =\eta_i + \sum_{j=1}^{q_1}\phi_{i,j}y_{i, t-j} + \sum_{j=0}^{q_2-1}\theta_{i,j+1}'\mbf{x}_{i,t-j} + f(\mathcal{F}_{i,t},\alpha_i)D_{i,t} + \varepsilon_{i,t},\\[.2cm]
  \; f(\mc{F}_{i,t},\alpha_i) = \alpha_i +  \sum_{j=1}^{q_{1}}\t\phi_{i,j}y_{i, t-j} + \sum_{j=0}^{q_2-1}\t\theta_{i,j+1}'\mbf{x}_{i,t-j}, \\[.2cm]
  \; \alpha_i = \mu_{\alpha} + \delta_i'\mbf{x}_{i, T_i^*+1} + \t{\varepsilon}_{i},
  %\sum_{j=1}^{q_3}\delta_{i,j}'\mbf{x}_{i, T_i^*-j+1}+ \t{\varepsilon}_{i}, 
\end{array}\label{model-gen}
\end{align}
where $g(t)$ is a known or estimable bounded continuous function which does not cross zero and $\lim_{t\to\infty}g(t) = a \in \R$. Let 
$\mathbf{\phi}_i = (\phi_{i,1},\ldots,\phi_{i,q_1})'$, 
$\mathbf{\theta}_i = (\theta_{i,1},\ldots,\theta_{i,q_2})'$, 
$\tilde{\mathbf{\phi}}_i = (\t\phi_{i,1},\ldots,\t\phi_{i,q_{1}})'$, 
$\tilde{\mathbf{\theta}}_i = (\t\theta_{i,1},\ldots,\t\theta_{i, q_{2}})'$, 
$\mathbf{\delta}_i = (\delta_{i,1},\ldots,\delta_{i,p})'$, 
and suppose that the regression coefficients in \eqref{model-gen} have the following hierarchical random effects structure: 
\begin{align*}
  \eta_i &\simiid \mc{F}_{\eta} \text{ with }  \; \mrm{E}_{\mc{F}_{\eta}}(\eta_i) = 0, \mrm{Var}_{\mc{F}_{\eta}}(\eta_i)  = \sigma^2_{\eta}, \\
  \mathbf{\phi}_i &\simiid \mc{F}_{\mathbf{\phi}} \text{ where } |\phi_{i,j}| < 1, \\
  \mathbf{\theta}_i &\simiid \mc{F}_{\mathbf{\theta}} \text{ with }  \; \mrm{E}_{\mc{F}_{\mathbf{\theta}}}(\theta_i) = \mu_{\mathbf{\theta}}, \mrm{Var}_{\mc{F}_{\mathbf{\theta}}}(\mathbf{\theta}_i)  = \Sigma^2_{\mathbf{\theta}}, \\
  \mathbf{\delta}_i &\simiid  \mc{F}_{\mathbf{\delta}} \text{ with } \mrm{E}_{\mc{F}_{\mathbf{\delta}}}(\mathbf{\delta}_i)=\mu_{\mathbf{\delta}}, \mrm{Var}_{\mc{F}_{\mathbf{\delta}}}(\mathbf{\delta}_i)=\Sigma_{\mathbf{\delta}}, \\
\varepsilon_{i,t} & \simiid  \mc{F}_{\varepsilon_i} \text{ with }  \; \mrm{E}_{\mc{F}_{\varepsilon_i}}(\varepsilon_{i,t}) = 0, \mrm{Var}_{\mc{F}_{\varepsilon_i}}(\varepsilon_{i,t})  = \sigma^2_i,  \\
\t{\varepsilon}_{i} &\simiid  \mc{F}_{\t{\varepsilon}} \text{ with }\mrm{E}_{\mc{F}_{\t{\varepsilon}}}(\t{\varepsilon}_{i})=0, \mrm{Var}_{\mc{F}_{\t{\varepsilon}}}(\t{\varepsilon}_{i})=\sigma^2_{\alpha}, \\
  \tilde{\mathbf{\phi}}_{i,j} &\overset{ind}{\sim} \mathcal{F}_{\tilde{\mathbf{\phi}}}(\x_{i,T_i^*+1}) \; \text{where} \; |\tilde{\mathbf{\phi}}_{i,j}| < 1,  \\
  \tilde{\mathbf{\theta}}_{i,j} &= \theta_{i,j} + \gamma_{i,j}, j = 1,\ldots, q_{2}, \; \text{where} \; \gamma_{i,j} \simiid \mathcal{F}_{\gamma} \; \text{with} \; \mrm{E}_{\mathcal{F}_{\gamma}}(\gamma_i) = \beta_o + \beta\mbf{x}_{i,T_i^*+1}, \mrm{Var}_{\mathcal{F}_{\gamma}}(\gamma_i) = \Sigma^2_\gamma,  \\  
 % \t q_{i,k} &\overset{ind}{\sim} \mathcal{F}_k(\x_{i,T_i^*}), \; k = 1,2, \\
&\eta_i \indep \mathbf{\phi}_i \indep \mathbf{\theta}_i \indep 
\tilde{\mathbf{\phi}}_i \indep \lambda_{i,j} \indep \gamma_i \indep \mathbf{\delta}_i \indep \varepsilon_{i,t} \indep \tilde\varepsilon_{i,t},
\end{align*}
where the distribution $\mathcal{F}_{\tilde{\mathbf{\phi}}}(\x_{i,T_i^*+1})$ exists between -1 and 1 and $\mrm{E}(\mathcal{F}_{\tilde{\mathbf{\phi}}}(\x_{i,T_i^*+1})) - \mrm{E}(\mathcal{F}_{\tilde{\mathbf{\phi}}}(\x_{j,T_i^*+1})) \to 0$ as $\|\x_{i,T_i^*+1} - \x_{j,T_i^*+1}\| \to 0$.
%the distribution $\mathcal{F}_k(\x_{i,T_i^*})$ is a discrete distribution conditional on $\x_{i,T_i^*}$, $\theta_{i,j} = 0$ for any $q_1 < j \leq \t q_{i,1}$, and $\phi_{i,j} = 0$ for any $q_2 < j \leq \t q_{i,2}$. 
The model \eqref{model-gen} with the above random effects structure is a generalization of both model formulations in \cite{lin2021minimizing}. \textbf{Need to carefully show}. Note that for model \eqref{model-gen} to be of use for post-shock forecasting, the variation in $\mathcal{F}_{\tilde{\mathbf{\phi}}}$ needs to be small relative to the signal captured in $\x_{i,T_i^*}$, and $\sigma^2_\alpha$ and $\Sigma^2_\gamma$ needs to be small relative to $\mu_\alpha + \delta_i'\x_{i,T_i^*}$ and $\beta_o + \beta\mbf{x}_{i,T_i^*+1}$ respectively. 

We see that model \eqref{model-gen} with its accompanying random effects structure is flexible enough to capture changing structural dynamics as well as a mean-shift. These dynamic changes depend heavily on the value of $\mbf{x}_{i,T_i^*+1}$. Two series $i,j$ with small $\|\mbf{x}_{i,T_i^*+1} - \mbf{x}_{j,T_i^*+1}\|_2$ are expected to experience similar structural changes. This makes distance based weighting an attractive avenue.








\subsection{Forecasting and testing for shock persistence}
\label{forecast}

\noindent\textbf{Note}: Our forecast needs to be written with respect to our general model. Specifics can be given when we conduct our numerical examples.
\vspace*{0.5cm}

In our post-shock setting we consider the following candidate forecasts: 
\begin{align*}
  &\text{Forecast 1}: \\
  &\text{Forecast 2}: 
\end{align*}
We want to determine which forecast is appropriate over a horizon while the methods in \cite{lin2021minimizing} were only appropriate in the nowcasting setting in which prediction was only focused on the response immediately following the shock.


\vspace*{0.5cm}\noindent\textbf{Note}: We need to explain what the voting method is, possibly in algorithmic format. Also note that the p-values that we obtain are computed using a bootstrap procedure. Perhaps an additional proposition that states the performance of these bootstrap p-values would further guarantee reliability. 

\begin{prop}
  Let $p_i \sim \mc{D}$ be independent sequence of p-values for $i = 1, \ldots, n+1$ and some distribution $\mc{D}$, where $p_1$ is the p-value of the time series of interest. Let  $\alpha$ denote the significance level. If $\P(p_1 \leq \alpha) \neq 0.5$, with probability one, the expected misclassification rate for voting in prevalence testing is
  \begin{align*}
    \begin{cases}
    1- \P(p_1 \leq \alpha) & \text{ if } \P(p_1 \leq \alpha) > 0.5 \\
    \P(p_1 \leq \alpha) & \text{ if } \P(p_1 \leq \alpha) < 0.5 
  \end{cases} .
  \end{align*}
\end{prop}

\begin{proof}
 Since $\P(p_1 \leq \alpha)\in \reals$, by Strong Law of Large Numbers,
\begin{align*}
  \frac{1}{n}\sum_{i=2}^{n+1}I(p_i \leq  \alpha)  
   \stackrel{a.s.}{\rightarrow}  \P(p_i \leq \alpha) = \P(p_1 \leq \alpha),
\end{align*}
which follows from the fact that $p_i$ are i.i.d. Define
\begin{align*}
  f \colon [0,1] \mapsto \{0,1\} 
  \text{ with }
  f(x) = I(x \geq 0.5).
\end{align*}
Let $C(f)$ denote the continuity set of $f$. Suppose that $\P(p_1 \leq  \alpha) \neq 0.5$. In this case, notice that 
\begin{align*}
  \P(\P(p_1 \leq  \alpha) \in C(f)) =1.
\end{align*}
By Slutsky's Theorem, we have
\begin{align*}
  I\left\{\frac{1}{n}\sum_{i=2}^{n+1}I(p_i \leq  \alpha) \geq 0.5\right\}
  \stackrel{a.s.}{\rightarrow} 
  I\{ \P(p_1 \leq  \alpha) \geq 0.5\}.
\end{align*}
Moreover, note that
\begin{align*}
\E \left\{ |I\{ \P(p_1 \leq  \alpha) \geq 0.5\}
  - I( p_1 \leq  \alpha) |\right\}
  & = \begin{cases}
    1- \P(p_1 \leq \alpha) & \text{ if } \P(p_1 \leq \alpha) > 0.5 \\
    \P(p_1 \leq \alpha) & \text{ if } \P(p_1 \leq \alpha) < 0.5 
  \end{cases} \\
  & \leq  0.5.
\end{align*}
That implies that with probability one, 
\begin{align*}
  \E \left\{ \left|I\left\{\frac{1}{n}\sum_{i=2}^{n+1}I(p_i \leq  \alpha) \geq 0.5\right\}
  - I( p_1 \leq  \alpha) \right|\right\}
  = \begin{cases}
    1- \P(p_1 \leq \alpha) & \text{ if } \P(p_1 \leq \alpha) > 0.5 \\
    \P(p_1 \leq \alpha) & \text{ if } \P(p_1 \leq \alpha) < 0.5 
  \end{cases}.
\end{align*}
That is, with probability one, the expected misclassification rate is as above.
\end{proof}

\begin{remark}
  Since indicator functions are bounded in $\mc{L}^2$, by Chebyshev-Rachman Strong Law of Large Numbers, the independence assumption can be relaxed to be that those p-values are uncorrelated.
\end{remark}

\section{Simulation Setup}
\label{simulation}

Let $n$ denote the donor pool size, $p$ denote the number of covariates used, $H$ denote the number of horizon used, $T_i$ denote the length of time series to be evaluated for time series $i$, $K_i$ denote the training sample size used for each  forecasting  time series $i$, $T_i^*$ denote the time point just before the realization of the shock for time series $i$ for $i = 1, \ldots, n+1$.


In this setting $n$, $p$, and $H$ are pre-determined. $T_i, K_i \sim \mrm{Gamma}(15, 10)$.  The total sample size for $i$th time series is $T_i + K_i + H$. $T_i^*$ is randomly sampled from $\ceil{\frac{1}{4}T_i}+1$ to $\ceil{\frac{3}{4} T_i} + K_i+ H$. If $T_i, K_i < 90$, we force them to be 90. The adopted model for the data is as below:
\begin{align*}
  y_{i,t} &= \eta_i + \phi_i y_{i,t-1} + \mbf{x}_{i,t} \bs{\beta}_i + \alpha_i I(t > T_i^*) + \varepsilon_{i,t},\\
  \alpha_i &= \mu_{\alpha} + \mbf{x}_{i,T_i^*+1}\bs{\gamma}_i + \tilde{\varepsilon}_{i},
\end{align*}
where
\begin{align*}
  \phi_i & \sim \text{ indep. }  U(0,1) \\
  \eta_i & \sim \text{ indep. }  \mc{N}(0,1) \\
  \varepsilon_{i,t} & \sim \text{ indep. } \mc{N}(0, \sigma^2)\\
  \tilde{\varepsilon}_i & \sim \text{ indep. } \mc{N}(0, \sigma_{\alpha}^2)
  \\
  \bs{\gamma}_i & \sim \text{ indep. } \mc{N}(\mu_{\gamma}\bs{1}_p, \sigma_{\gamma}^2 \mbf{I}_p) \\
  \bs{\beta}_i & \sim \text{ indep. }  \mc{N}(\bs{0}_p, \mbf{I}_p).
\end{align*}
Moreover, the elements of $\mathbf{x}_{i,t}$ are independently distributed as $\mrm{Gamma}(1,\delta)$.

Note that $K_i$ is training sample size for time series $i$. Consider
\begin{align*}
  K_i & \sim \ceil{\mrm{Gamma}(a_{K}, b_K)}\\
   T_i & \sim \ceil{\mrm{Gamma}(a_{T}, b_T)} \\
  T_i^* &\equiv \max\{T_i+1, \ceil{0.5 \cdot(T_i+K_i+H)}\},
\end{align*}

$K_i+H+T_i^* > T_i+K_i+H$

 Then, we consider the following simulation setup
\begin{verbatim}
  ns <- c(5, 10, 20, 40)
  Tscale <- Kscale <- 1 / 2 # b_T, b_K 
  K.T.shape <- c(200, 400, 800, 1600) # for K_i and T_i
  mu.gamma.delta <- 2 # mean for parameter vector of shock
  sigma.delta.gamma <- 0.1 # sd for parameter vector of shock
  sigma.alpha <- 0.05 # sd for shock noise  
  sigma <- 0.1 # sd for response noise
  mu.alpha <- 50 # intercept for shock (relatively large)
  H <- 8 
  ell <- 4
  scale <- 2 # scale for covariates that follow Gamma distribution
\end{verbatim}

\begin{align*}
  y_{i,t} &= \eta_i + \phi_i y_{i,t-1} + \mbf{x}_{i,t} \bs{\beta}_i + \xi_i\cdot  I(t > T_i^*) + \varepsilon_{i,t},\\
  \xi_i &= \alpha_i \cdot e^{-(t-T_i^*-1)} \\
  \alpha_i &= \mu_{\alpha} + \mbf{x}_{i,T_i^*+1}\bs{\gamma}_i + \tilde{\varepsilon}_{i},
\end{align*}









\bibliographystyle{plainnat}
\bibliography{../synthetic-prediction-notes}

	
\end{document}


